{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(13) #TODO Check if this is used for sgd\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Reshape, Lambda\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.preprocessing import sequence\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors as nn\n",
    "from matplotlib import pylab\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT Modify the lines in this cell\n",
    "path = 'alice.txt'#'analogy_alice.txt'\n",
    "corpus = open(path).readlines()[0:700]\n",
    "\n",
    "corpus = [sentence for sentence in corpus if sentence.count(\" \") >= 2]\n",
    "\n",
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'+\"'\")\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "corpus = tokenizer.texts_to_sequences(corpus)\n",
    "nb_samples = sum(len(s) for s in corpus)\n",
    "V = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Is this something they need to change?\n",
    "dim = 100\n",
    "window_size = 2 #use this window size for Skipgram, CBOW, and the model with the additional hidden layer\n",
    "window_size_corpus = 4 #use this window size for the co-occurrence matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "### Co-occurrence Matrix\n",
    "Use the provided code to load the \"Alice in Wonderland\" text document. \n",
    "1. Implement the word-word co-occurrence matrix for “Alice in Wonderland”\n",
    "2. Normalize the words such that every value lies within a range of 0 and 1\n",
    "3. Compute the cosine distance between the given words:\n",
    "    - Alice \n",
    "    - Dinah\n",
    "    - Rabbit\n",
    "4. List the 5 closest words to 'Alice'. Discuss the results.\n",
    "5. Discuss what the main drawbacks are of a term-term co-occurence matrix solutions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 \n",
    "### Implement the word-word co-occurrence matrix for “Alice in Wonderland”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 0. 8. ... 0. 0. 0.]\n",
      " [1. 8. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse, numpy\n",
    "\n",
    "\n",
    "vocabulary={}\n",
    "data=[]\n",
    "row=[]\n",
    "col=[]\n",
    "for sentence in corpus:\n",
    "    for pos,word in enumerate(sentence):\n",
    "        i=vocabulary.setdefault(word,len(vocabulary))\n",
    "        start=max(0,pos-window_size_corpus)\n",
    "        end=min(len(sentence),pos+window_size_corpus+1)\n",
    "        for pos2 in range(start,end):\n",
    "            if pos2==pos: \n",
    "                continue\n",
    "            j=vocabulary.setdefault(sentence[pos2],len(vocabulary))\n",
    "            if(j!=i):\n",
    "                data.append(1.); row.append(i); col.append(j);\n",
    "            \n",
    "cooccurrence_matrix=scipy.sparse.coo_matrix((data,(row,col)))\n",
    "#print(cooccurrence_matrix.T * cooccurrence_matrix)\n",
    "print(cooccurrence_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 \n",
    "### Normalize the words such that every value lies within a range of 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.0625     0.0625     ... 0.         0.         0.        ]\n",
      " [0.00105485 0.         0.00843882 ... 0.         0.         0.        ]\n",
      " [0.00381679 0.03053435 0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#We use TF for normalization\n",
    "\n",
    "cooc=cooccurrence_matrix.toarray()\n",
    "tf_cooc=numpy.zeros((V-1, V-1))\n",
    "for i, sentence in enumerate(cooc):\n",
    "    sumf=0\n",
    "    for wordf in sentence:\n",
    "        sumf+=wordf\n",
    "    for j,wordf in enumerate(sentence):\n",
    "        if(sumf>0):\n",
    "            tf_cooc[i][j]=cooc[i][j]/sumf\n",
    "        else:\n",
    "            continue\n",
    "print(tf_cooc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 \n",
    "### Compute the cosine distance between the given words: Alice, Dinah, Rabbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "87\n",
      "63\n",
      "Cosine similarity of Alice and Dinah: 0.48967327730053256\n",
      "Cosine similarity of Alice and Rabbit: 0.08862667920586557\n",
      "Cosine similarity of Dinah and Rabbit: 0.1396996890567782\n"
     ]
    }
   ],
   "source": [
    "#find cosine similarity to Alice, Dinah and Rabbit\n",
    "import math\n",
    "def cos_sim(a,b):\n",
    "    sum_c=0;len_c=len(a);sum_as=0;sum_bs=0;\n",
    "    for ii in range(len_c):\n",
    "        sum_c=sum_c+(a[ii]*b[ii])\n",
    "        sum_as=sum_as+(a[ii]*a[ii])\n",
    "        sum_bs=sum_bs+(b[ii]*b[ii])\n",
    "    return sum_c/(math.sqrt(sum_as)*(math.sqrt(sum_bs)))\n",
    "\n",
    "\n",
    "print(tokenizer.word_index['alice'])  #11-1=10, since word_index starting at index 1\n",
    "print(tokenizer.word_index['dinah'])  #87-1=86\n",
    "print(tokenizer.word_index['rabbit']) #63-1=62\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#print(cosine_similarity(tf_cooc[10:11], tf_cooc[86:87]))\n",
    "print(\"Cosine similarity of Alice and Dinah: {}\".format(cos_sim(tf_cooc[10],tf_cooc[86])))                 \n",
    "#print(cosine_similarity(tf_cooc[10:11], tf_cooc[62:63]))\n",
    "print(\"Cosine similarity of Alice and Rabbit: {}\".format(cos_sim(tf_cooc[10],tf_cooc[62])))\n",
    "#print(cosine_similarity(tf_cooc[86:87], tf_cooc[62:63]))\n",
    "print(\"Cosine similarity of Dinah and Rabbit: {}\".format(cos_sim(tf_cooc[62],tf_cooc[86])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4\n",
    "### List the 5 closest words to 'Alice'. Discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closest word= t, had, question, say, to\n",
      "Cosine similarity of Alice and t: 0.7033898864296415\n",
      "Cosine similarity of Alice and had: 0.6995182846911174\n",
      "Cosine similarity of Alice and question: 0.6726422527548841\n",
      "Cosine similarity of Alice and say: 0.6685274041392557\n",
      "Cosine similarity of Alice and to: 0.6544770424322105\n"
     ]
    }
   ],
   "source": [
    "#find the closest words to Alice\n",
    "maxid=0\n",
    "maxval=0\n",
    "simi=np.zeros(V-1)\n",
    "for i in range(V-1):\n",
    "    simi[i]=cosine_similarity(tf_cooc[10:11], tf_cooc[i:i+1])[0][0]\n",
    "indices=simi.argsort()[-6:][::-1]\n",
    "print(\"closest word= {}, {}, {}, {}, {}\".format(list(tokenizer.word_index)[indices[1]],list(tokenizer.word_index)[indices[2]],list(tokenizer.word_index)[indices[3]],list(tokenizer.word_index)[indices[4]],list(tokenizer.word_index)[indices[5]]))            \n",
    "for i in range(1,6):\n",
    "    print(\"Cosine similarity of Alice and {}: {}\".format(list(tokenizer.word_index)[indices[i]],cosine_similarity(tf_cooc[10:11], tf_cooc[indices[i]:indices[i]+1])[0][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5\n",
    "### Discuss what the main drawbacks are of a term-term co-occurence matrix solutions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save your all the vector representations of your word embeddings in this way\n",
    "#Change when necessary the sizes of the vocabulary/embedding dimension\n",
    "\n",
    "f = open('vectors_co_occurrence.txt',\"w\")\n",
    "f.write(\" \".join([str(V-1),str(V-1)]))\n",
    "f.write(\"\\n\")\n",
    "\n",
    "#vectors = your word co-occurrence matrix\n",
    "vectors = tf_cooc\n",
    "for word, i in tokenizer.word_index.items():    \n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i-1,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reopen your file as follows\n",
    "\n",
    "co_occurrence = KeyedVectors.load_word2vec_format('./vectors_co_occurrence.txt', binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "### Word embeddings\n",
    "Build embeddings with a keras implementation where the embedding vector is of length 50, 150 and 300. Use the Alice in Wonderland text book for training.\n",
    "1. Using the CBOW model\n",
    "2. Using Skipgram model\n",
    "3. Add extra hidden dense layer to CBow and Skipgram implementations. Choose an activation function for that layer and justify your answer.\n",
    "4. Analyze the four different word embeddings\n",
    "    - Implement your own function to perform the analogy task with. Do not use existing libraries for this task such as Gensim. Your function should be able to answer whether an anaology as in the example given in the pdf-file is true.\n",
    "    - Compare the performance on the analogy task between the word embeddings that you have trained in 2.1, 2.2 and 2.3.  \n",
    "    - Visualize your results and interpret your results\n",
    "5. Use the word co-occurence matrix from Question 1. Compare the performance on the analogy task with the performance of your trained word embeddings.  \n",
    "6. Discuss:\n",
    "    - What are the main advantages of CBOW and Skipgram?\n",
    "    - What is the advantage of negative sampling?\n",
    "    - What are the main drawbacks of CBOW and Skipgram?\n",
    "7. Load pre-trained embeddings on large corpuses (see the pdf file). You only have to consider the word embeddings with an embedding size of 300\n",
    "    - Compare performance on the analogy task with your own trained embeddings from \"Alice in Wonderland\". You can limit yourself to the vocabulary of Alice in Wonderland. Visualize the pre-trained word embeddings and compare these with the results of your own trained word embeddings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6559, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare data for cbow\n",
    "import math\n",
    "reversed_index = {v:k for k,v in tokenizer.word_index.items()}\n",
    "\n",
    "def prep_cbow_data(corpus=corpus,window_size=window_size,V=V):\n",
    "    flat = [word for line in corpus for word in line]\n",
    "    vectors = []\n",
    "    L = len(flat)\n",
    "    start = int(window_size)\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(start,L-start):\n",
    "        context_before = flat[i-start:i]\n",
    "        target = np.zeros(V,dtype=int)\n",
    "        target[flat[i]-1] = 1\n",
    "        context_after = flat[i+1:i+1+start]\n",
    "        context = context_before + context_after\n",
    "        #onehot_context = []\n",
    "        #for word in context:\n",
    "        #    vector = np.zeros(V,dtype=int)\n",
    "        #    vector[word-1] = 1\n",
    "        #    onehot_context.append(vector)\n",
    "            \n",
    "        if len(context) == 4:\n",
    "            #onehot_context = np.asarray(onehot_context)\n",
    "            x.append(context)\n",
    "            y.append(target)\n",
    "        \n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    return x,y\n",
    "\n",
    "\n",
    "prep_cbow_data()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size X: 6559,size Y:6559\n",
      "(6559, 4) (6559, 1183)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(input_dim=1183, output_dim=100, input_length=4, embeddings_initializer=\"glorot_uniform\")`\n",
      "  \n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1183, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#create CBOW model\n",
    "from keras.layers import Flatten\n",
    "X,Y = prep_cbow_data()\n",
    "features = len(X)\n",
    "print(\"size X: {},size Y:{}\".format(len(X),len(Y)))\n",
    "print(X.shape,Y.shape)\n",
    "cbow = Sequential()\n",
    "cbow.add(Embedding(input_dim=V, output_dim=dim, init='glorot_uniform',input_length=4))\n",
    "cbow.add(Flatten())\n",
    "cbow.add(Dense(V, init='glorot_uniform', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function\n",
    "cbow.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5903 samples, validate on 656 samples\n",
      "Epoch 1/100\n",
      "5903/5903 [==============================] - 3s 547us/step - loss: 7.0495 - val_loss: 7.0279\n",
      "Epoch 2/100\n",
      "5903/5903 [==============================] - 3s 496us/step - loss: 6.9876 - val_loss: 6.9825\n",
      "Epoch 3/100\n",
      "5903/5903 [==============================] - 3s 485us/step - loss: 6.9145 - val_loss: 6.9132\n",
      "Epoch 4/100\n",
      "5903/5903 [==============================] - 3s 488us/step - loss: 6.8049 - val_loss: 6.7977\n",
      "Epoch 5/100\n",
      "5903/5903 [==============================] - 3s 480us/step - loss: 6.6370 - val_loss: 6.6216\n",
      "Epoch 6/100\n",
      "5903/5903 [==============================] - 3s 470us/step - loss: 6.4109 - val_loss: 6.4074\n",
      "Epoch 7/100\n",
      "5903/5903 [==============================] - 3s 453us/step - loss: 6.1725 - val_loss: 6.2239\n",
      "Epoch 8/100\n",
      "5903/5903 [==============================] - 3s 464us/step - loss: 5.9754 - val_loss: 6.0881\n",
      "Epoch 9/100\n",
      "5903/5903 [==============================] - 3s 457us/step - loss: 5.8161 - val_loss: 5.9828\n",
      "Epoch 10/100\n",
      "5903/5903 [==============================] - 3s 466us/step - loss: 5.6796 - val_loss: 5.8917\n",
      "Epoch 11/100\n",
      "5903/5903 [==============================] - 3s 482us/step - loss: 5.5570 - val_loss: 5.8114\n",
      "Epoch 12/100\n",
      "5903/5903 [==============================] - 3s 473us/step - loss: 5.4442 - val_loss: 5.7403\n",
      "Epoch 13/100\n",
      "5903/5903 [==============================] - 3s 478us/step - loss: 5.3385 - val_loss: 5.6753\n",
      "Epoch 14/100\n",
      "5903/5903 [==============================] - 3s 469us/step - loss: 5.2390 - val_loss: 5.6169\n",
      "Epoch 15/100\n",
      "5903/5903 [==============================] - 3s 475us/step - loss: 5.1443 - val_loss: 5.5632\n",
      "Epoch 16/100\n",
      "5903/5903 [==============================] - 3s 476us/step - loss: 5.0538 - val_loss: 5.5149\n",
      "Epoch 17/100\n",
      "5903/5903 [==============================] - 3s 467us/step - loss: 4.9665 - val_loss: 5.4677\n",
      "Epoch 18/100\n",
      "5903/5903 [==============================] - 3s 473us/step - loss: 4.8824 - val_loss: 5.4241\n",
      "Epoch 19/100\n",
      "5903/5903 [==============================] - 3s 472us/step - loss: 4.8022 - val_loss: 5.3846\n",
      "Epoch 20/100\n",
      "5903/5903 [==============================] - 3s 474us/step - loss: 4.7246 - val_loss: 5.3489\n",
      "Epoch 21/100\n",
      "5903/5903 [==============================] - 3s 487us/step - loss: 4.6496 - val_loss: 5.3148\n",
      "Epoch 22/100\n",
      "5903/5903 [==============================] - 3s 524us/step - loss: 4.5766 - val_loss: 5.2840\n",
      "Epoch 23/100\n",
      "5903/5903 [==============================] - 3s 506us/step - loss: 4.5054 - val_loss: 5.2552\n",
      "Epoch 24/100\n",
      "5903/5903 [==============================] - 3s 509us/step - loss: 4.4365 - val_loss: 5.2268\n",
      "Epoch 25/100\n",
      "5903/5903 [==============================] - 3s 520us/step - loss: 4.3692 - val_loss: 5.2011\n",
      "Epoch 26/100\n",
      "5903/5903 [==============================] - 3s 502us/step - loss: 4.3031 - val_loss: 5.1779\n",
      "Epoch 27/100\n",
      "5903/5903 [==============================] - 3s 514us/step - loss: 4.2391 - val_loss: 5.1539\n",
      "Epoch 28/100\n",
      "5903/5903 [==============================] - 3s 501us/step - loss: 4.1764 - val_loss: 5.1340\n",
      "Epoch 29/100\n",
      "5903/5903 [==============================] - 3s 521us/step - loss: 4.1147 - val_loss: 5.1111\n",
      "Epoch 30/100\n",
      "5903/5903 [==============================] - 3s 517us/step - loss: 4.0545 - val_loss: 5.0939\n",
      "Epoch 31/100\n",
      "5903/5903 [==============================] - 3s 516us/step - loss: 3.9958 - val_loss: 5.0774\n",
      "Epoch 32/100\n",
      "5903/5903 [==============================] - 3s 512us/step - loss: 3.9370 - val_loss: 5.0615\n",
      "Epoch 33/100\n",
      "5903/5903 [==============================] - 3s 502us/step - loss: 3.8795 - val_loss: 5.0446\n",
      "Epoch 34/100\n",
      "5903/5903 [==============================] - 3s 508us/step - loss: 3.8226 - val_loss: 5.0320\n",
      "Epoch 35/100\n",
      "5903/5903 [==============================] - 3s 514us/step - loss: 3.7672 - val_loss: 5.0181\n",
      "Epoch 36/100\n",
      "5903/5903 [==============================] - 3s 500us/step - loss: 3.7129 - val_loss: 5.0026\n",
      "Epoch 37/100\n",
      "5903/5903 [==============================] - 3s 515us/step - loss: 3.6593 - val_loss: 4.9881\n",
      "Epoch 38/100\n",
      "5903/5903 [==============================] - 3s 499us/step - loss: 3.6065 - val_loss: 4.9766\n",
      "Epoch 39/100\n",
      "5903/5903 [==============================] - 3s 514us/step - loss: 3.5535 - val_loss: 4.9656\n",
      "Epoch 40/100\n",
      "5903/5903 [==============================] - 3s 509us/step - loss: 3.5024 - val_loss: 4.9569\n",
      "Epoch 41/100\n",
      "5903/5903 [==============================] - 3s 505us/step - loss: 3.4515 - val_loss: 4.9470\n",
      "Epoch 42/100\n",
      "5903/5903 [==============================] - 3s 508us/step - loss: 3.4017 - val_loss: 4.9332\n",
      "Epoch 43/100\n",
      "5903/5903 [==============================] - 3s 505us/step - loss: 3.3526 - val_loss: 4.9240\n",
      "Epoch 44/100\n",
      "5903/5903 [==============================] - 3s 509us/step - loss: 3.3048 - val_loss: 4.9146\n",
      "Epoch 45/100\n",
      "5903/5903 [==============================] - 3s 519us/step - loss: 3.2574 - val_loss: 4.9087\n",
      "Epoch 46/100\n",
      "5903/5903 [==============================] - 3s 503us/step - loss: 3.2104 - val_loss: 4.9015\n",
      "Epoch 47/100\n",
      "5903/5903 [==============================] - 3s 512us/step - loss: 3.1638 - val_loss: 4.8949\n",
      "Epoch 48/100\n",
      "5903/5903 [==============================] - 3s 505us/step - loss: 3.1182 - val_loss: 4.8887\n",
      "Epoch 49/100\n",
      "5903/5903 [==============================] - 3s 515us/step - loss: 3.0731 - val_loss: 4.8816\n",
      "Epoch 50/100\n",
      "5903/5903 [==============================] - 3s 513us/step - loss: 3.0292 - val_loss: 4.8751\n",
      "Epoch 51/100\n",
      "5903/5903 [==============================] - 3s 516us/step - loss: 2.9854 - val_loss: 4.8706\n",
      "Epoch 52/100\n",
      "5903/5903 [==============================] - 3s 511us/step - loss: 2.9428 - val_loss: 4.8660\n",
      "Epoch 53/100\n",
      "5903/5903 [==============================] - 3s 510us/step - loss: 2.8997 - val_loss: 4.8603\n",
      "Epoch 54/100\n",
      "5903/5903 [==============================] - 3s 520us/step - loss: 2.8585 - val_loss: 4.8569\n",
      "Epoch 55/100\n",
      "5903/5903 [==============================] - 3s 516us/step - loss: 2.8173 - val_loss: 4.8546\n",
      "Epoch 56/100\n",
      "5903/5903 [==============================] - 3s 501us/step - loss: 2.7764 - val_loss: 4.8481\n",
      "Epoch 57/100\n",
      "5903/5903 [==============================] - 3s 510us/step - loss: 2.7371 - val_loss: 4.8446\n",
      "Epoch 58/100\n",
      "5903/5903 [==============================] - 3s 505us/step - loss: 2.6966 - val_loss: 4.8403\n",
      "Epoch 59/100\n",
      "5903/5903 [==============================] - 3s 506us/step - loss: 2.6579 - val_loss: 4.8409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1baf76451d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "from keras import callbacks\n",
    "epochs=100\n",
    "earlyStopping=callbacks.EarlyStopping(monitor='val_loss',min_delta=0.001, patience=0, verbose=0, mode='auto')\n",
    "\n",
    "cbow.fit(X,Y,epochs=epochs,validation_split=0.1, callbacks=[earlyStopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 \n",
    "## Using the Skipgram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data for Skipgram\n",
    "def generate_data_skipgram(corpus, window_size, V):\n",
    "    maxlen = window_size*2\n",
    "    all_in = []\n",
    "    all_out = []\n",
    "    for words in corpus:\n",
    "        L = len(words)\n",
    "        for index, word in enumerate(words):\n",
    "            p = index - window_size\n",
    "            n = index + window_size + 1\n",
    "                    \n",
    "            in_words = []\n",
    "            labels = []\n",
    "            for i in range(p, n):\n",
    "                if i != index and 0 <= i < L:\n",
    "                    in_words.append([word])\n",
    "                    labels.append(words[i])\n",
    "            if in_words != []:\n",
    "                all_in.append(np.array(in_words,dtype=np.int32))\n",
    "                all_out.append(np_utils.to_categorical(labels, V))\n",
    "    return (all_in,all_out)\n",
    "\n",
    "#get x and y's for data\n",
    "x,y = generate_data_skipgram(corpus,window_size,V)\n",
    "\n",
    "#save the preprocessed data of Skipgram\n",
    "f = open('data_skipgram.txt' ,'w')\n",
    "\n",
    "for input,outcome  in zip(x,y):\n",
    "    input = np.concatenate(input)\n",
    "    f.write(\" \".join(map(str, list(input))))\n",
    "    f.write(\",\")\n",
    "    outcome = np.concatenate(outcome)\n",
    "    f.write(\" \".join(map(str,list(outcome))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "#load the preprocessed Skipgram data\n",
    "def generate_data_skipgram_from_file():\n",
    "    f = open('data_skipgram.txt' ,'r')\n",
    "    for row in f:\n",
    "        inputs,outputs = row.split(\",\")\n",
    "        inputs = np.fromstring(inputs, dtype=int, sep=' ')\n",
    "        inputs = np.asarray(np.split(inputs, len(inputs)))\n",
    "        outputs = np.fromstring(outputs, dtype=float, sep=' ')\n",
    "        outputs = np.asarray(np.split(outputs, len(inputs)))\n",
    "        yield (inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Skipgram model\n",
    "\n",
    "dim1=50\n",
    "dim2=150\n",
    "dim3=300\n",
    "skipgram_50 = Sequential()\n",
    "skipgram_50.add(Embedding(input_dim=V, output_dim=dim1, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram_50.add(Reshape((dim1, )))\n",
    "skipgram_50.add(Dense(input_dim=dim1, units=V, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "skipgram_150 = Sequential()\n",
    "skipgram_150.add(Embedding(input_dim=V, output_dim=dim2, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram_150.add(Reshape((dim2, )))\n",
    "skipgram_150.add(Dense(input_dim=dim2, units=V, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "skipgram_300 = Sequential()\n",
    "skipgram_300.add(Embedding(input_dim=V, output_dim=dim3, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram_300.add(Reshape((dim3, )))\n",
    "skipgram_300.add(Dense(input_dim=dim3, units=V, kernel_initializer='uniform', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function for Skipgram\n",
    "skipgram_50.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
    "skipgram_150.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
    "skipgram_300.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 42019.0201215744\n",
      "1 38379.62837553024\n",
      "2 39003.5622587204\n",
      "3 39509.36110877991\n",
      "4 39705.85113596916\n",
      "5 39885.63010597229\n",
      "6 40046.92625975609\n",
      "7 40210.36398935318\n",
      "8 40391.53400826454\n",
      "9 40586.17857551575\n",
      "0 42003.86192703247\n",
      "1 38329.2822098732\n",
      "2 38850.55951523781\n",
      "3 39214.83134794235\n",
      "4 39390.2365026474\n",
      "5 39541.21982002258\n",
      "6 39695.80431985855\n",
      "7 39864.555876255035\n",
      "8 40036.627875089645\n",
      "9 40212.43623352051\n",
      "0 41972.32948112488\n",
      "1 38263.37252306938\n",
      "2 38669.966866493225\n",
      "3 38963.96811294556\n",
      "4 39128.82766032219\n",
      "5 39276.19422340393\n",
      "6 39422.713296175\n",
      "7 39560.45543265343\n",
      "8 39694.1005204916\n",
      "9 39825.880415678024\n"
     ]
    }
   ],
   "source": [
    "#train Skipgram model\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += skipgram_50.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)\n",
    "    \n",
    "f = open('vectors_skipgram_50.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim1)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = skipgram_50.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += skipgram_150.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)\n",
    "    \n",
    "f = open('vectors_skipgram_150.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim2)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = skipgram_150.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += skipgram_300.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)\n",
    "    \n",
    "f = open('vectors_skipgram_300.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim3)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = skipgram_300.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3\n",
    "### Add extra hidden dense layer to CBow and Skipgram implementations. Choose an activation function for that layer and justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(input_dim=1183, output_dim=100, input_length=4, embeddings_initializer=\"glorot_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1183, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#create CBOW model with additional dense layer\n",
    "cbow2 = Sequential()\n",
    "cbow2.add(Embedding(input_dim=V, output_dim=dim, init='glorot_uniform',input_length=4))\n",
    "cbow2.add(Flatten())\n",
    "cbow2.add(Dense(V,activation='relu'))\n",
    "cbow2.add(Dense(V, init='glorot_uniform', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function for CBOW + dense\n",
    "cbow2.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5903 samples, validate on 656 samples\n",
      "Epoch 1/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 6.7766 - val_loss: 6.1094\n",
      "Epoch 2/100\n",
      "5903/5903 [==============================] - 9s 1ms/step - loss: 5.8327 - val_loss: 5.7606\n",
      "Epoch 3/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 5.5145 - val_loss: 5.5747\n",
      "Epoch 4/100\n",
      "5903/5903 [==============================] - 8s 1ms/step - loss: 5.2639 - val_loss: 5.4150\n",
      "Epoch 5/100\n",
      "5903/5903 [==============================] - 8s 1ms/step - loss: 5.0215 - val_loss: 5.2781\n",
      "Epoch 6/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 4.7894 - val_loss: 5.1477\n",
      "Epoch 7/100\n",
      "5903/5903 [==============================] - 11s 2ms/step - loss: 4.5724 - val_loss: 5.0567\n",
      "Epoch 8/100\n",
      "5903/5903 [==============================] - 10s 2ms/step - loss: 4.3716 - val_loss: 4.9879\n",
      "Epoch 9/100\n",
      "5903/5903 [==============================] - 10s 2ms/step - loss: 4.1812 - val_loss: 4.9395\n",
      "Epoch 10/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 3.9998 - val_loss: 4.8841\n",
      "Epoch 11/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 3.8235 - val_loss: 4.8715\n",
      "Epoch 12/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 3.6504 - val_loss: 4.8396\n",
      "Epoch 13/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 3.4827 - val_loss: 4.8171\n",
      "Epoch 14/100\n",
      "5903/5903 [==============================] - 10s 2ms/step - loss: 3.3142 - val_loss: 4.8193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bafacd8668>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model for CBOW + dense\n",
    "epochs=100\n",
    "\n",
    "earlyStopping=callbacks.EarlyStopping(monitor='val_loss',min_delta=0.001, patience=0, verbose=0, mode='auto')\n",
    "\n",
    "cbow2.fit(X,Y,epochs=epochs,validation_split=0.1, callbacks=[earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Skipgram with additional dense layer\n",
    "\n",
    "#create Skipgram model\n",
    "\n",
    "skipgram_50_dense = Sequential()\n",
    "skipgram_50_dense.add(Embedding(input_dim=V, output_dim=dim1, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram_50_dense.add(Reshape((dim1, )))\n",
    "skipgram_50_dense.add(Dense(V,activation='relu'))\n",
    "skipgram_50_dense.add(Dense(input_dim=dim1, units=V, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "skipgram_150_dense = Sequential()\n",
    "skipgram_150_dense.add(Embedding(input_dim=V, output_dim=dim2, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram_150_dense.add(Reshape((dim2, )))\n",
    "skipgram_150_dense.add(Dense(V,activation='relu'))\n",
    "skipgram_150_dense.add(Dense(input_dim=dim2, units=V, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "skipgram_300_dense = Sequential()\n",
    "skipgram_300_dense.add(Embedding(input_dim=V, output_dim=dim3, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram_300_dense.add(Reshape((dim3, )))\n",
    "skipgram_300_dense.add(Dense(V,activation='relu'))\n",
    "skipgram_300_dense.add(Dense(input_dim=dim3, units=V, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "#skipgram2 = Sequential()\n",
    "#skipgram2.add(Embedding(input_dim=V, output_dim=dim, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "#skipgram2.add(Reshape((dim, )))\n",
    "#skipgram2.add(Dense(input_dim=dim, units=V, kernel_initializer='uniform', activation='softmax'))\n",
    "#skipgram2.add(Dense(input_dim=dim, units=V, kernel_initializer='uniform', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function for Skipgram + dense\n",
    "skipgram_50_dense.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
    "skipgram_150_dense.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
    "skipgram_300_dense.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 39444.32987213135\n",
      "1 38264.48951482773\n",
      "2 37948.66480302811\n",
      "3 37769.99622249603\n",
      "4 37750.78943347931\n",
      "5 37725.23108911514\n",
      "6 37674.930666565895\n",
      "7 37620.79466640949\n",
      "8 37566.527002334595\n",
      "9 37519.70512115955\n",
      "0 39471.03422307968\n",
      "1 38220.93018221855\n",
      "2 37718.286794900894\n",
      "3 37538.61131024361\n",
      "4 37493.13153910637\n",
      "5 37456.600872159004\n",
      "6 37402.676347732544\n",
      "7 37335.5792144537\n",
      "8 37265.79830777645\n",
      "9 37196.82523834705\n",
      "0 39445.47623085976\n",
      "1 38082.24569654465\n",
      "2 37592.96987724304\n",
      "3 37330.86567401886\n",
      "4 37259.75267124176\n",
      "5 37224.620362997055\n",
      "6 37161.21744906902\n",
      "7 37086.09090960026\n",
      "8 37002.261269927025\n",
      "9 36925.072355270386\n"
     ]
    }
   ],
   "source": [
    "#train model for Skipgram + dense\n",
    "#train Skipgram model\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += skipgram_50_dense.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)\n",
    "    \n",
    "f = open('vectors_skipgram_50_dense.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim1)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = skipgram_50_dense.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += skipgram_150_dense.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)\n",
    "    \n",
    "f = open('vectors_skipgram_150_dense.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim2)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = skipgram_150_dense.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += skipgram_300_dense.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)\n",
    "    \n",
    "f = open('vectors_skipgram_300_dense.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim3)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = skipgram_300_dense.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "skipgram_50.save('skipgram_50.h5')\n",
    "skipgram_150.save('skipgram_150.h5')\n",
    "skipgram_300.save('skipgram_300.h5')\n",
    "skipgram_50_dense.save('skipgram_50_dense.h5')\n",
    "skipgram_150_dense.save('skipgram_150_dense.h5')\n",
    "skipgram_300_dense.save('skipgram_300_dense.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "explain activation layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4\n",
    "### Analyze the four different word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement your own analogy function\n",
    "\n",
    "key_cbow_50 ={}\n",
    "key_cbow_150 ={}\n",
    "key_cbow_300 ={}\n",
    "key_cbow_50_dense ={}\n",
    "key_cbow_150_dense ={}\n",
    "key_cbow_300_dense ={}\n",
    "key_skipgram_50 ={}\n",
    "key_skipgram_150 ={}\n",
    "key_skipgram_300 ={}\n",
    "key_skipgram_50_dense ={}\n",
    "key_skipgram_150_dense ={}\n",
    "key_skipgram_300_dense ={}\n",
    "\n",
    "embed_cbow_50 =[]\n",
    "embed_cbow_150 =[]\n",
    "embed_cbow_300 =[]\n",
    "embed_cbow_50_dense =[]\n",
    "embed_cbow_150_dense =[]\n",
    "embed_cbow_300_dense =[]\n",
    "embed_skipgram_50 =[]\n",
    "embed_skipgram_150 =[]\n",
    "embed_skipgram_300 =[]\n",
    "embed_skipgram_50_dense =[]\n",
    "embed_skipgram_150_dense =[]\n",
    "embed_skipgram_300_dense =[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_from_file(a):\n",
    "    f = open(a ,'r')\n",
    "    key_dict={}\n",
    "    vect=[]\n",
    "    for row in f:\n",
    "        dimention=0\n",
    "        inp = row.split(\"\\n\")[0].split(\" \")\n",
    "        if(len(inp)==2):\n",
    "            dimention=inp[1]\n",
    "        else:\n",
    "            key_dict.update({inp[0]:len(key_dict)})\n",
    "            vect.append(np.asarray(inp[1:],dtype=float))\n",
    "    return (vect,key_dict)\n",
    "\n",
    "(embed_cbow_50,key_cbow_50)=load_from_file('vectors_cbow_50.txt')\n",
    "(embed_cbow_150,key_cbow_150)=load_from_file('vectors_cbow_150.txt')\n",
    "(embed_cbow_300,key_cbow_300)=load_from_file('vectors_cbow_300.txt')\n",
    "(embed_cbow_50_dense,key_cbow_50_dense)=load_from_file('vectors_cbow_50_dense.txt')\n",
    "(embed_cbow_150_dense,key_cbow_150_dense)=load_from_file('vectors_cbow_150_dense.txt')\n",
    "(embed_cbow_300_dense,key_cbow_300_dense)=load_from_file('vectors_cbow_300_dense.txt')\n",
    "(embed_skipgram_50,key_skipgram_50)=load_from_file('vectors_skipgram_50.txt')\n",
    "(embed_skipgram_150,key_skipgram_150)=load_from_file('vectors_skipgram_150.txt')\n",
    "(embed_skipgram_300,key_skipgram_300)=load_from_file('vectors_skipgram_300.txt')\n",
    "(embed_skipgram_50_dense,key_skipgram_50_dense)=load_from_file('vectors_skipgram_50_dense.txt')\n",
    "(embed_skipgram_150_dense,key_skipgram_150_dense)=load_from_file('vectors_skipgram_150_dense.txt')\n",
    "(embed_skipgram_300_dense,key_skipgram_300_dense)=load_from_file('vectors_skipgram_300_dense.txt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08582410447347387"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator \n",
    "def load_analogy():\n",
    "    f = open('analogy_alice.txt' ,'r')\n",
    "    analogy_list=[]\n",
    "    for row in f:\n",
    "        a = row.split(\"\\n\")[0].split(\" \")\n",
    "        analogy_list.append(np.asarray(a))\n",
    "    return analogy_list\n",
    "\n",
    "def analogy_check(analogy_list,embed_matrix,dictionary):\n",
    "    v=[[],[],[],[]]\n",
    "    for i in range(4):\n",
    "        if(analogy_list[i] in dictionary):\n",
    "            v[i]=embed_matrix[dictionary[analogy_list[i]]-1]\n",
    "        else:\n",
    "            v[i]=np.zeros(150)\n",
    "    #print(dictionary)\n",
    "    #return abs(cos_sim(v[0],v[1])-cos_sim(v[2],v[3]))\n",
    "    return cos_sim( list(map(operator.sub, list(map(sum, zip(v[0],v[1]))), v[2])),v[3])\n",
    "\n",
    "analogy_list=load_analogy()\n",
    "#print(analogy_list[0])\n",
    "#analogy_check([\"go\",\"going\",\"look\",\"looking\"],embed_skipgram_150, tokenizer.word_index )\n",
    "analogy_check([\"say\",\"saying\",\"sit\",\"sitting\"],cooccurrence_matrix.toarray(), tokenizer.word_index )\n",
    "analogy_check([\"sudden\",\"suddenly\",\"usual\",\"usually\"],embed_skipgram_300_dense, tokenizer.word_index )\n",
    "#analogy_check([\"fancy\",\"fancying\",\"alice\",\"rabbit\"],embed_skipgram_150, tokenizer.word_index )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read model from tim\n",
    "\n",
    "from keras.models import load_model\n",
    "cbow_50 = load_model('cbow50.h5')\n",
    "cbow_150 = load_model('cbow150.h5')\n",
    "cbow_300 = load_model('cbow300.h5')\n",
    "cbow_50_dense = load_model('cbow_extended_50.h5')\n",
    "cbow_150_dense = load_model('cbow_extended_150.h5')\n",
    "cbow_300_dense = load_model('cbow_extended_300.h5')\n",
    "\n",
    "f = open('vectors_cbow_50.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim1)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = cbow_50.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open('vectors_cbow_150.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim2)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = cbow_150.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open('vectors_cbow_300.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim3)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = cbow_300.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open('vectors_cbow_50_dense.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim1)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = cbow_50_dense.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open('vectors_cbow_150_dense.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim2)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = cbow_150_dense.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open('vectors_cbow_300_dense.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim3)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = cbow_300_dense.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Visualization results trained word embeddings\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5\n",
    "### Use the word co-occurence matrix from Question 1. Compare the performance on the analogy task with the performance of your trained word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation results of the visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results of the trained word embeddings with the word-word co-occurrence matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 \n",
    "### Discussion of the advantages of CBOW and Skipgram, the advantages of negative sampling and drawbacks of CBOW and Skipgram\n",
    "\n",
    "CBOW tries to predict a word by context, it sees the context and maximizes the probability of the target word.\n",
    "This means CBOW is good at predicting frequent words. To train CBOW a reasonably low amount of data is sufficient.\n",
    "The drawback of CBOW is that whilst it will preform well at predicting frequent words it will have low accuracy for less frequent words.\n",
    "this is because some words compete in the sense that they are a valid target for the same context.\n",
    "The more frequent word will then be predicted.\n",
    "\n",
    "In negative sampling we choose random words to pair with the target and have an output of 0. \n",
    "The updating of the weights is then performed on these K samples, which reduces the computational requirements.\n",
    "The model does not need all observations but simply only the K sampled pairs (context + target).\n",
    "\n",
    "Skip gram is designed to predict context. It sees the target and tries to find the context around the word. \n",
    "Skip gram is rather well suited even for rare words. Thake the example delightfull, it will try to predict something like yesterday was a day.\n",
    "Whilst if CBOw would have gotten this context delightfull would have never been predicted it would have chosen more frequent words like good.\n",
    "The drawback for skip gram is that it requires a large amount of data to train. This is because if we for example look at the delightfull word it will have context.\n",
    "Similar nice will also have a context, delightfull day and nice day are 2 independant sets. In cbow this use of nice and delightfull would be competing since the context day has both \n",
    "delightfull and nice as targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7\n",
    "### Load pre-trained embeddings on large corpuses (see the pdf file). You only have to consider the word embeddings with an embedding size of 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pretrained word embeddings of word2vec\n",
    "\n",
    "path_word2vec = \"tes\\GoogleNews-vectors-negative300.bin\"\n",
    "\n",
    "word2vec = KeyedVectors.load_word2vec_format(path_word2vec, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pretraind word embeddings of Glove\n",
    "import gensim\n",
    "#path = \"tes\\glove.6B\\glove.6B.300d_converted.txt\"\n",
    "path = \"tes\\glove.6B.300d.txt\"\n",
    "\n",
    "#convert GloVe into word2vec format\n",
    "gensim.scripts.glove2word2vec.get_glove_info(path)\n",
    "gensim.scripts.glove2word2vec.glove2word2vec(path, \"glove_converted.txt\")\n",
    "\n",
    "glove = KeyedVectors.load_word2vec_format(\"glove_converted.txt\", binary=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v: sudden, suddenly, usual, usually: 0.22255026056670402\n",
      "glove: sudden, suddenly, usual, usually: 0.3100777731068751\n",
      "cbow: sudden, suddenly, usual, usually: -0.07675966522933991\n",
      "cbow_dense: sudden, suddenly, usual, usually: 0.021816142041618355\n",
      "skipgram: sudden, suddenly, usual, usually: 0.013981381463225495\n",
      "skipgram_dense: sudden, suddenly, usual, usually: -0.08582410447347387\n",
      "\n",
      "w2v: bad, worse, good, better: 0.6724906513772779\n",
      "glove: bad, worse, good, better: 0.6565830036364912\n",
      "cbow: bad, worse, good, better: -0.14211218867763775\n",
      "cbow_dense: bad, worse, good, better: -0.06851437505368992\n",
      "skipgram: bad, worse, good, better: -0.05229406240425803\n",
      "skipgram_dense: bad, worse, good, better: 0.0010391543210957021\n",
      "\n",
      "w2v: go, going, look, looking: 0.4437767197062708\n",
      "glove: go, going, look, looking: 0.6695781772903449\n",
      "cbow: go, going, look, looking: 0.0013563966233273222\n",
      "cbow_dense: go, going, look, looking: 0.16969527138432886\n",
      "skipgram: go, going, look, looking: 0.0857564110649774\n",
      "skipgram_dense: go, going, look, looking: 0.03098357758763984\n",
      "\n",
      "w2v: he, she, his, her: 0.661601926269319\n",
      "glove: he, she, his, her: 0.7343965200095653\n",
      "cbow: he, she, his, her: 0.14181520782518023\n",
      "cbow_dense: he, she, his, her: 0.06405350025790807\n",
      "skipgram: he, she, his, her: 0.05539611965867066\n",
      "skipgram_dense: he, she, his, her: 0.047066524315540086\n",
      "\n",
      "w2v: brother, sister, his, her: 0.29478371779476814\n",
      "glove: brother, sister, his, her: 0.565070276491166\n",
      "cbow: brother, sister, his, her: 0.1738845887364074\n",
      "cbow_dense: brother, sister, his, her: 0.15306492585478185\n",
      "skipgram: brother, sister, his, her: -0.05641767468527157\n",
      "skipgram_dense: brother, sister, his, her: -0.009200589532626787\n",
      "\n",
      "w2v: listen, listening, look, looking: 0.21896109979844153\n",
      "glove: listen, listening, look, looking: 0.4071841107300849\n",
      "cbow: listen, listening, look, looking: 0.00960132291661633\n",
      "cbow_dense: listen, listening, look, looking: 0.11961182797045093\n",
      "skipgram: listen, listening, look, looking: -0.0841335857178494\n",
      "skipgram_dense: listen, listening, look, looking: -0.037008750133731456\n",
      "\n",
      "w2v: saying, said, thinking, thought: 0.40956290213903407\n",
      "glove: saying, said, thinking, thought: 0.49768632598408674\n",
      "cbow: saying, said, thinking, thought: 0.33954839323186276\n",
      "cbow_dense: saying, said, thinking, thought: 0.1291448144807512\n",
      "skipgram: saying, said, thinking, thought: 0.3259387717229089\n",
      "skipgram_dense: saying, said, thinking, thought: -0.022102505774773195\n",
      "\n",
      "w2v: bird, birds, cat, cats: 0.548314343723498\n",
      "glove: bird, birds, cat, cats: 0.48856988240789534\n",
      "cbow: bird, birds, cat, cats: -0.21468265880268259\n",
      "cbow_dense: bird, birds, cat, cats: -0.10054438635684715\n",
      "skipgram: bird, birds, cat, cats: 0.03250104634631262\n",
      "skipgram_dense: bird, birds, cat, cats: 0.11074620778124797\n",
      "\n",
      "w2v: good, better, old, older: 0.21694786651491343\n",
      "glove: good, better, old, older: 0.40961181661362545\n",
      "cbow: good, better, old, older: 0.04180303804268945\n",
      "cbow_dense: good, better, old, older: 0.05047850869217344\n",
      "skipgram: good, better, old, older: 0.08390944033445641\n",
      "skipgram_dense: good, better, old, older: -0.014284331275707515\n",
      "\n",
      "w2v: good, better, quick, quicker: 0.5330237925619995\n",
      "glove: good, better, quick, quicker: 0.5328881245927063\n",
      "cbow: good, better, quick, quicker: 0.043084136200568085\n",
      "cbow_dense: good, better, quick, quicker: 0.08780310156990714\n",
      "skipgram: good, better, quick, quicker: -0.0672776369563426\n",
      "skipgram_dense: good, better, quick, quicker: 0.028810861971552044\n",
      "\n",
      "w2v: large, largest, good, best: 0.21683160333463167\n",
      "glove: large, largest, good, best: 0.2652648164246623\n",
      "cbow: large, largest, good, best: 0.31235314624380967\n",
      "cbow_dense: large, largest, good, best: 0.06919605281969435\n",
      "skipgram: large, largest, good, best: -0.006536230294100379\n",
      "skipgram_dense: large, largest, good, best: 0.022095812827602777\n",
      "\n",
      "w2v: falling, fell, knowing, knew: 0.14287526113350987\n",
      "glove: falling, fell, knowing, knew: 0.15409427727346053\n",
      "cbow: falling, fell, knowing, knew: -0.07905697790725436\n",
      "cbow_dense: falling, fell, knowing, knew: -0.1048865932317624\n",
      "skipgram: falling, fell, knowing, knew: 0.013853888594661638\n",
      "skipgram_dense: falling, fell, knowing, knew: 0.024131281276904854\n",
      "\n",
      "w2v: walk, walking, think, thinking: 0.25107561442774934\n",
      "glove: walk, walking, think, thinking: 0.4035633827468627\n",
      "cbow: walk, walking, think, thinking: -0.013221233663537528\n",
      "cbow_dense: walk, walking, think, thinking: -0.009731531377755356\n",
      "skipgram: walk, walking, think, thinking: 0.09443912798901292\n",
      "skipgram_dense: walk, walking, think, thinking: 0.0017553334445679046\n",
      "\n",
      "w2v: child, children, cat, cats: 0.36624447596308296\n",
      "glove: child, children, cat, cats: 0.28044855781310063\n",
      "cbow: child, children, cat, cats: -0.2576635618221906\n",
      "cbow_dense: child, children, cat, cats: -0.0630106301661655\n",
      "skipgram: child, children, cat, cats: 0.08883936307509875\n",
      "skipgram_dense: child, children, cat, cats: -0.026278953768836256\n",
      "\n",
      "w2v: dog, dogs, eye, eyes: 0.13321162577935888\n",
      "glove: dog, dogs, eye, eyes: 0.3071176163860798\n",
      "cbow: dog, dogs, eye, eyes: -0.07113528677106216\n",
      "cbow_dense: dog, dogs, eye, eyes: -0.08522655447996517\n",
      "skipgram: dog, dogs, eye, eyes: 0.07650736551249597\n",
      "skipgram_dense: dog, dogs, eye, eyes: 0.045406220394282076\n",
      "\n",
      "w2v: hand, hands, rat, rats: 0.04862699542761563\n",
      "glove: hand, hands, rat, rats: 0.05072466972752036\n",
      "cbow: hand, hands, rat, rats: 0.1932542609051188\n",
      "cbow_dense: hand, hands, rat, rats: -0.15502528932785348\n",
      "skipgram: hand, hands, rat, rats: 0.03946198477425701\n",
      "skipgram_dense: hand, hands, rat, rats: -0.07919303696947005\n",
      "\n",
      "w2v: eat, eats, find, finds: 0.2830192036624857\n",
      "glove: eat, eats, find, finds: 0.30765008316898457\n",
      "cbow: eat, eats, find, finds: 0.1406046690404185\n",
      "cbow_dense: eat, eats, find, finds: 0.0219764605368637\n",
      "skipgram: eat, eats, find, finds: -0.01920813874990434\n",
      "skipgram_dense: eat, eats, find, finds: 0.02862671211042982\n",
      "\n",
      "w2v: find, finds, say, says: 0.38303518154481636\n",
      "glove: find, finds, say, says: 0.4858085924624003\n",
      "cbow: find, finds, say, says: -0.10766476872833465\n",
      "cbow_dense: find, finds, say, says: -0.0819073553800007\n",
      "skipgram: find, finds, say, says: -0.08034059519651741\n",
      "skipgram_dense: find, finds, say, says: 0.041517536625278816\n",
      "\n",
      "w2v: old, older, good, better: 0.21694786651491343\n",
      "glove: old, older, good, better: 0.40961181661362545\n",
      "cbow: old, older, good, better: -0.03153937056499282\n",
      "cbow_dense: old, older, good, better: 0.06568098484014025\n",
      "skipgram: old, older, good, better: -0.023182690867631403\n",
      "skipgram_dense: old, older, good, better: 0.03750692335347313\n",
      "\n",
      "w2v: large, larger, quick, quicker: 0.22521266715730429\n",
      "glove: large, larger, quick, quicker: 0.22567543578240246\n",
      "cbow: large, larger, quick, quicker: -0.018327700770753793\n",
      "cbow_dense: large, larger, quick, quicker: -0.049348306302746295\n",
      "skipgram: large, larger, quick, quicker: 0.014788514009054106\n",
      "skipgram_dense: large, larger, quick, quicker: 0.02371671053988241\n",
      "\n",
      "w2v: go, going, listen, listening: 0.23913213804946878\n",
      "glove: go, going, listen, listening: 0.42662491131551733\n",
      "cbow: go, going, listen, listening: -0.05352097746896414\n",
      "cbow_dense: go, going, listen, listening: -0.14896358119691314\n",
      "skipgram: go, going, listen, listening: 0.10172302696406732\n",
      "skipgram_dense: go, going, listen, listening: 0.03722928802883272\n",
      "\n",
      "w2v: run, running, walk, walking: 0.4228847541114353\n",
      "glove: run, running, walk, walking: 0.47095163467027384\n",
      "cbow: run, running, walk, walking: -0.0028142046713905233\n",
      "cbow_dense: run, running, walk, walking: 0.08147060418902584\n",
      "skipgram: run, running, walk, walking: -0.007724702519940744\n",
      "skipgram_dense: run, running, walk, walking: 0.02603747460367717\n",
      "\n",
      "w2v: run, running, think, thinking: 0.24565625385619846\n",
      "glove: run, running, think, thinking: 0.3926802350946642\n",
      "cbow: run, running, think, thinking: -0.006785781141912233\n",
      "cbow_dense: run, running, think, thinking: 0.05699287127087976\n",
      "skipgram: run, running, think, thinking: 0.060924769391190445\n",
      "skipgram_dense: run, running, think, thinking: 0.03230106826210846\n",
      "\n",
      "w2v: say, saying, sit, sitting: 0.19387733146836375\n",
      "glove: say, saying, sit, sitting: 0.33033972016602986\n",
      "cbow: say, saying, sit, sitting: -0.035323962797726406\n",
      "cbow_dense: say, saying, sit, sitting: 0.10109881160563665\n",
      "skipgram: say, saying, sit, sitting: 0.04378602995374177\n",
      "skipgram_dense: say, saying, sit, sitting: 0.03827250222830714\n",
      "\n",
      "w2v: alice, she, rabbit, he: 0.4352757480653299\n",
      "glove: alice, she, rabbit, he: 0.4769463106145698\n",
      "cbow: alice, she, rabbit, he: 0.02158846341550625\n",
      "cbow_dense: alice, she, rabbit, he: 0.0959762805982485\n",
      "skipgram: alice, she, rabbit, he: 0.08717707473555629\n",
      "skipgram_dense: alice, she, rabbit, he: 0.12265448691108558\n",
      "\n",
      "w2v: alice, her, rabbit, him: 0.4179929072878149\n",
      "glove: alice, her, rabbit, him: 0.4330083526998539\n",
      "cbow: alice, her, rabbit, him: 0.04790479808956305\n",
      "cbow_dense: alice, her, rabbit, him: 0.09920782186208495\n",
      "skipgram: alice, her, rabbit, him: 0.01711302802717834\n",
      "skipgram_dense: alice, her, rabbit, him: -0.009536472808953146\n",
      "\n",
      "w2v: alice, girl, rabbit, sir: 0.391360154857756\n",
      "glove: alice, girl, rabbit, sir: 0.3090358756196289\n",
      "cbow: alice, girl, rabbit, sir: 0.020245237921716373\n",
      "cbow_dense: alice, girl, rabbit, sir: 0.03404486457448577\n",
      "skipgram: alice, girl, rabbit, sir: -0.015589099372999526\n",
      "skipgram_dense: alice, girl, rabbit, sir: 0.17267874308297823\n",
      "\n",
      "w2v: his, her, he, she: 0.661601926269319\n",
      "glove: his, her, he, she: 0.7343965200095653\n",
      "cbow: his, her, he, she: 0.023657427031521093\n",
      "cbow_dense: his, her, he, she: -0.1228006092516608\n",
      "skipgram: his, her, he, she: -0.023710586771567784\n",
      "skipgram_dense: his, her, he, she: 0.0641726993931325\n",
      "\n",
      "w2v: long, longer, quick, quicker: 0.27729260342003326\n",
      "glove: long, longer, quick, quicker: 0.3099571305282724\n",
      "cbow: long, longer, quick, quicker: 0.0943593590121146\n",
      "cbow_dense: long, longer, quick, quicker: 0.07346261607150895\n",
      "skipgram: long, longer, quick, quicker: 0.0115626943979101\n",
      "skipgram_dense: long, longer, quick, quicker: 0.056064160828123114\n",
      "\n",
      "w2v: long, longer, small, smaller: 0.2388453687212515\n",
      "glove: long, longer, small, smaller: 0.45009013669954157\n",
      "cbow: long, longer, small, smaller: 0.06089632592231342\n",
      "cbow_dense: long, longer, small, smaller: 0.13468641151074714\n",
      "skipgram: long, longer, small, smaller: 0.0528596179085847\n",
      "skipgram_dense: long, longer, small, smaller: -0.033260428707802096\n",
      "\n",
      "w2v: long, longer, bad, worse: 0.2819685717087468\n",
      "glove: long, longer, bad, worse: 0.40626429575998596\n",
      "cbow: long, longer, bad, worse: 0.27068072880154254\n",
      "cbow_dense: long, longer, bad, worse: 0.17876813435616165\n",
      "skipgram: long, longer, bad, worse: -0.06755097366498111\n",
      "skipgram_dense: long, longer, bad, worse: 0.035440468745773696\n",
      "\n",
      "w2v: go, going, look, looking: 0.4437767197062708\n",
      "glove: go, going, look, looking: 0.6695781772903449\n",
      "cbow: go, going, look, looking: 0.0013563966233273222\n",
      "cbow_dense: go, going, look, looking: 0.16969527138432886\n",
      "skipgram: go, going, look, looking: 0.0857564110649774\n",
      "skipgram_dense: go, going, look, looking: 0.03098357758763984\n",
      "\n",
      "w2v: listen, listening, look, looking: 0.21896109979844153\n",
      "glove: listen, listening, look, looking: 0.4071841107300849\n",
      "cbow: listen, listening, look, looking: 0.00960132291661633\n",
      "cbow_dense: listen, listening, look, looking: 0.11961182797045093\n",
      "skipgram: listen, listening, look, looking: -0.0841335857178494\n",
      "skipgram_dense: listen, listening, look, looking: -0.037008750133731456\n",
      "\n",
      "w2v: swim, swimming, sit, sitting: 0.15879369259853693\n",
      "glove: swim, swimming, sit, sitting: 0.24853629762099705\n",
      "cbow: swim, swimming, sit, sitting: 0.08881370361878012\n",
      "cbow_dense: swim, swimming, sit, sitting: 0.10508880049784433\n",
      "skipgram: swim, swimming, sit, sitting: 0.035596227610360805\n",
      "skipgram_dense: swim, swimming, sit, sitting: -0.0007167028681988707\n",
      "\n",
      "w2v: run, running, listen, listening: 0.09999018014940893\n",
      "glove: run, running, listen, listening: 0.15729225189857585\n",
      "cbow: run, running, listen, listening: -0.03861840452743019\n",
      "cbow_dense: run, running, listen, listening: 0.035063353384430895\n",
      "skipgram: run, running, listen, listening: 0.020743869849819133\n",
      "skipgram_dense: run, running, listen, listening: 0.07100698165185709\n",
      "\n",
      "w2v: think, thinking, read, reading: 0.3014273799197356\n",
      "glove: think, thinking, read, reading: 0.411297884485633\n",
      "cbow: think, thinking, read, reading: 0.019524453048346102\n",
      "cbow_dense: think, thinking, read, reading: -0.04085618348009827\n",
      "skipgram: think, thinking, read, reading: 0.05569960656005628\n",
      "skipgram_dense: think, thinking, read, reading: 0.01165496543557438\n",
      "\n",
      "w2v: up, down, close, far: 0.31230518986077627\n",
      "glove: up, down, close, far: 0.6523693175355175\n",
      "cbow: up, down, close, far: -0.05967624532666053\n",
      "cbow_dense: up, down, close, far: -0.014005814944815826\n",
      "skipgram: up, down, close, far: 0.10219964024800547\n",
      "skipgram_dense: up, down, close, far: -0.03616082031316734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#w2v and glove analogy performance\n",
    "w2vanalogylist=[]\n",
    "gloveanalogylist=[]\n",
    "cbowanalogylist=[]\n",
    "cbowdenseanalogylist=[]\n",
    "skipgramanalogylist=[]\n",
    "skipgramdenseanalogylist=[]\n",
    "\n",
    "for analogy in analogy_list:\n",
    "    if(analogy[0] in tokenizer.word_index and analogy[1] in tokenizer.word_index and analogy[2] in tokenizer.word_index and analogy[3] in tokenizer.word_index):\n",
    "        try:\n",
    "            w2vanalogy=word2vec.n_similarity([analogy[0],analogy[1]],[analogy[2],analogy[3]])\n",
    "            gloveanalogy=glove.n_similarity([analogy[0],analogy[1]],[analogy[2],analogy[3]])\n",
    "            cbowanalogy=analogy_check(analogy,embed_cbow_300, tokenizer.word_index )\n",
    "            cbowdenseanalogy=analogy_check(analogy,embed_cbow_300_dense, tokenizer.word_index )\n",
    "            skipgramanalogy=analogy_check(analogy,embed_skipgram_300, tokenizer.word_index )\n",
    "            skipgramdenseanalogy=analogy_check(analogy,embed_skipgram_300_dense, tokenizer.word_index )\n",
    "            \n",
    "            print(\"w2v: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],w2vanalogy))\n",
    "            print(\"glove: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],gloveanalogy))\n",
    "            print(\"cbow: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbowanalogy))\n",
    "            print(\"cbow_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbowdenseanalogy))\n",
    "            print(\"skipgram: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgramanalogy))\n",
    "            print(\"skipgram_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgramdenseanalogy))\n",
    "            \n",
    "            \n",
    "            w2vanalogylist.append(w2vanalogy)\n",
    "            gloveanalogylist.append(gloveanalogy)\n",
    "            cbowanalogylist.append(cbowanalogy)\n",
    "            cbowdenseanalogylist.append(cbowdenseanalogy)\n",
    "            skipgramanalogylist.append(skipgramanalogy)\n",
    "            skipgramdenseanalogylist.append(skipgramdenseanalogy)\n",
    "            \n",
    "            \n",
    "            print()\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatch in lengths between labels and vectors\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-707a506be446>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0membedlist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membed_skipgram_300\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0manalogy_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mdraw_word_vecs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedlist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0manalogy_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manalogy_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-707a506be446>\u001b[0m in \u001b[0;36mdraw_word_vecs\u001b[1;34m(X, strings)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mmaxt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmint\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquiver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmaxt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmaxt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmaxt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmaxt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mangles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'xy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_units\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'xy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;31m#for val in X_embedded[i]:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;31m#print(val/maxt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x248bded1080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize the pre-trained word embeddings\n",
    "import matplotlib.pyplot as plt\n",
    "def draw_word_vecs(X,strings):\n",
    "    col = ['r','b','g','y']\n",
    "    if len(X)!= len(strings):\n",
    "        print(\"mismatch in lengths between labels and vectors\")\n",
    "        \n",
    "    X_embedded = TSNE(n_components=4,method='exact').fit_transform(X)\n",
    "    maxt = np.amax(X_embedded)\n",
    "    mint = np.amin(X_embedded)\n",
    "    #print(maxt,mint)\n",
    "    maxt = max(maxt,mint*-1)\n",
    "    for i in range(len(X_embedded)):\n",
    "        plt.quiver(X_embedded[i][0]/maxt,X_embedded[i][1]/maxt,X_embedded[i][2]/maxt,X_embedded[i][3]/maxt,angles='xy', scale_units='xy',color=col[i], scale=1,label=strings[i])\n",
    "        #for val in X_embedded[i]:\n",
    "            #print(val/maxt)\n",
    "    #print(X_embedded)\n",
    "    plt.ylim(-1.2,1.2)\n",
    "    plt.xlim(-1.2,1.2)\n",
    "    plt.show()\n",
    "    \n",
    "embedlist=[]\n",
    "for i in range(4):\n",
    "    embedlist.append(word2vec[analogy_list[1][i]])\n",
    "    embedlist.append(embed_skipgram_300[tokenizer.word_index[analogy_list[1][i]]-1])\n",
    "len(embedlist)\n",
    "draw_word_vecs(embedlist,analogy_list[1])    \n",
    "print(analogy_list[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison performance with your own trained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'pleasanter' in tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
