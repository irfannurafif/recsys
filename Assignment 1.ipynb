{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "Irfan Nur Afif\n",
    "\n",
    "Timothy Aerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(13) #TODO Check if this is used for sgd\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Reshape, Lambda\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.preprocessing import sequence\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors as nn\n",
    "from matplotlib import pylab\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT Modify the lines in this cell\n",
    "path = 'alice.txt'#'analogy_alice.txt'\n",
    "corpus = open(path).readlines()[0:700]\n",
    "\n",
    "corpus = [sentence for sentence in corpus if sentence.count(\" \") >= 2]\n",
    "\n",
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'+\"'\")\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "corpus = tokenizer.texts_to_sequences(corpus)\n",
    "nb_samples = sum(len(s) for s in corpus)\n",
    "V = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Is this something they need to change?\n",
    "dim = 100\n",
    "window_size = 2 #use this window size for Skipgram, CBOW, and the model with the additional hidden layer\n",
    "window_size_corpus = 4 #use this window size for the co-occurrence matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "### Co-occurrence Matrix\n",
    "Use the provided code to load the \"Alice in Wonderland\" text document. \n",
    "1. Implement the word-word co-occurrence matrix for “Alice in Wonderland”\n",
    "2. Normalize the words such that every value lies within a range of 0 and 1\n",
    "3. Compute the cosine distance between the given words:\n",
    "    - Alice \n",
    "    - Dinah\n",
    "    - Rabbit\n",
    "4. List the 5 closest words to 'Alice'. Discuss the results.\n",
    "5. Discuss what the main drawbacks are of a term-term co-occurence matrix solutions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 \n",
    "### Implement the word-word co-occurrence matrix for “Alice in Wonderland”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 0. 8. ... 0. 0. 0.]\n",
      " [1. 8. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse, numpy\n",
    "\n",
    "\n",
    "vocabulary={}\n",
    "data=[]\n",
    "row=[]\n",
    "col=[]\n",
    "for sentence in corpus:\n",
    "    for pos,word in enumerate(sentence):\n",
    "        i=vocabulary.setdefault(word,len(vocabulary))\n",
    "        start=max(0,pos-window_size_corpus)\n",
    "        end=min(len(sentence),pos+window_size_corpus+1)\n",
    "        for pos2 in range(start,end):\n",
    "            if pos2==pos: \n",
    "                continue\n",
    "            j=vocabulary.setdefault(sentence[pos2],len(vocabulary))\n",
    "            if(j!=i):\n",
    "                data.append(1.); row.append(i); col.append(j);\n",
    "            \n",
    "cooccurrence_matrix=scipy.sparse.coo_matrix((data,(row,col)))\n",
    "#print(cooccurrence_matrix.T * cooccurrence_matrix)\n",
    "print(cooccurrence_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 \n",
    "### Normalize the words such that every value lies within a range of 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.0625     0.0625     ... 0.         0.         0.        ]\n",
      " [0.00105485 0.         0.00843882 ... 0.         0.         0.        ]\n",
      " [0.00381679 0.03053435 0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#We use TF for normalization\n",
    "\n",
    "cooc=cooccurrence_matrix.toarray()\n",
    "tf_cooc=numpy.zeros((V-1, V-1))\n",
    "for i, sentence in enumerate(cooc):\n",
    "    sumf=0\n",
    "    for wordf in sentence:\n",
    "        sumf+=wordf\n",
    "    for j,wordf in enumerate(sentence):\n",
    "        if(sumf>0):\n",
    "            tf_cooc[i][j]=cooc[i][j]/sumf\n",
    "        else:\n",
    "            continue\n",
    "print(tf_cooc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 \n",
    "### Compute the cosine distance between the given words: Alice, Dinah, Rabbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "87\n",
      "63\n",
      "Cosine similarity of Alice and Dinah: 0.48967327730053256\n",
      "Cosine similarity of Alice and Rabbit: 0.08862667920586557\n",
      "Cosine similarity of Dinah and Rabbit: 0.13969968905677818\n"
     ]
    }
   ],
   "source": [
    "#find cosine similarity to Alice, Dinah and Rabbit\n",
    "import math\n",
    "def cos_sim(a,b):\n",
    "    return cosine_similarity([a],[b])[0][0]\n",
    "    #sum_c=0;len_c=len(a);sum_as=0;sum_bs=0;\n",
    "    #for ii in range(len_c):\n",
    "    #    sum_c=sum_c+(a[ii]*b[ii])\n",
    "    #    sum_as=sum_as+(a[ii]*a[ii])\n",
    "    #    sum_bs=sum_bs+(b[ii]*b[ii])\n",
    "    #if(sum_as==0 and sum_bs==0):\n",
    "    #    return 1\n",
    "    #else:\n",
    "    #    return sum_c/(math.sqrt(sum_as)*(math.sqrt(sum_bs)))\n",
    "\n",
    "\n",
    "print(tokenizer.word_index['alice'])  #11-1=10, since word_index starting at index 1\n",
    "print(tokenizer.word_index['dinah'])  #87-1=86\n",
    "print(tokenizer.word_index['rabbit']) #63-1=62\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#print(cosine_similarity(tf_cooc[10:11], tf_cooc[86:87]))\n",
    "print(\"Cosine similarity of Alice and Dinah: {}\".format(cos_sim(tf_cooc[10],tf_cooc[86])))                 \n",
    "#print(cosine_similarity(tf_cooc[10:11], tf_cooc[62:63]))\n",
    "print(\"Cosine similarity of Alice and Rabbit: {}\".format(cos_sim(tf_cooc[10],tf_cooc[62])))\n",
    "#print(cosine_similarity(tf_cooc[86:87], tf_cooc[62:63]))\n",
    "print(\"Cosine similarity of Dinah and Rabbit: {}\".format(cos_sim(tf_cooc[62],tf_cooc[86])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4\n",
    "### List the 5 closest words to 'Alice'. Discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closest word= t, had, question, say, to\n",
      "Cosine similarity of Alice and t: 0.7033898864296415\n",
      "Cosine similarity of Alice and had: 0.6995182846911174\n",
      "Cosine similarity of Alice and question: 0.6726422527548841\n",
      "Cosine similarity of Alice and say: 0.6685274041392557\n",
      "Cosine similarity of Alice and to: 0.6544770424322105\n"
     ]
    }
   ],
   "source": [
    "#find the closest words to Alice\n",
    "maxid=0\n",
    "maxval=0\n",
    "simi=np.zeros(V-1)\n",
    "for i in range(V-1):\n",
    "    simi[i]=cosine_similarity(tf_cooc[10:11], tf_cooc[i:i+1])[0][0]\n",
    "indices=simi.argsort()[-6:][::-1]\n",
    "print(\"closest word= {}, {}, {}, {}, {}\".format(list(tokenizer.word_index)[indices[1]],list(tokenizer.word_index)[indices[2]],list(tokenizer.word_index)[indices[3]],list(tokenizer.word_index)[indices[4]],list(tokenizer.word_index)[indices[5]]))            \n",
    "for i in range(1,6):\n",
    "    print(\"Cosine similarity of Alice and {}: {}\".format(list(tokenizer.word_index)[indices[i]],cosine_similarity(tf_cooc[10:11], tf_cooc[indices[i]:indices[i]+1])[0][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closest words from alice are mainly verbs (had, question, say) and preposition (such as to). This is expected since a sentence usually have subject then followed by verb and sometimes preposition. In this case, Alice is mostly appear as subject in the text. The most frequent one is 't' because it is an abbreviation of 'not'. Usually the sentence goes like \"Alice doesn't ...\" or \"Alice wouldn't...\" and the 't' in this case was parsed into a word. Thus it is not surpising it becomes the closest word to Alice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5\n",
    "### Discuss what the main drawbacks are of a term-term co-occurence matrix solutions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main drawbacks of co-occurance matrix is the resulting matrix is sparse (contains a lot of 0 values). This is not an efficient representation since it costs a lot of memory (VxV, where V is the number of unique word) to store a lot of 0 values. Moreover, if we add a new word to corpus, then the amount of table value that will be added is $V^2-(V-1)^2$ which is a lot for big number of V. The resulting matrix also storing the same values on the upper and lower side of main diagonal, which is somewhat redundant.  Lastly the frequency of occurrence can be skewed and non discriminative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save your all the vector representations of your word embeddings in this way\n",
    "#Change when necessary the sizes of the vocabulary/embedding dimension\n",
    "\n",
    "f = open('vectors_co_occurrence.txt',\"w\")\n",
    "f.write(\" \".join([str(V-1),str(V-1)]))\n",
    "f.write(\"\\n\")\n",
    "\n",
    "#vectors = your word co-occurrence matrix\n",
    "vectors = tf_cooc\n",
    "for word, i in tokenizer.word_index.items():    \n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i-1,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reopen your file as follows\n",
    "\n",
    "co_occurrence = KeyedVectors.load_word2vec_format('./vectors_co_occurrence.txt', binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "### Word embeddings\n",
    "Build embeddings with a keras implementation where the embedding vector is of length 50, 150 and 300. Use the Alice in Wonderland text book for training.\n",
    "1. Using the CBOW model\n",
    "2. Using Skipgram model\n",
    "3. Add extra hidden dense layer to CBow and Skipgram implementations. Choose an activation function for that layer and justify your answer.\n",
    "4. Analyze the four different word embeddings\n",
    "    - Implement your own function to perform the analogy task with. Do not use existing libraries for this task such as Gensim. Your function should be able to answer whether an anaology as in the example given in the pdf-file is true.\n",
    "    - Compare the performance on the analogy task between the word embeddings that you have trained in 2.1, 2.2 and 2.3.  \n",
    "    - Visualize your results and interpret your results\n",
    "5. Use the word co-occurence matrix from Question 1. Compare the performance on the analogy task with the performance of your trained word embeddings.  \n",
    "6. Discuss:\n",
    "    - What are the main advantages of CBOW and Skipgram?\n",
    "    - What is the advantage of negative sampling?\n",
    "    - What are the main drawbacks of CBOW and Skipgram?\n",
    "7. Load pre-trained embeddings on large corpuses (see the pdf file). You only have to consider the word embeddings with an embedding size of 300\n",
    "    - Compare performance on the analogy task with your own trained embeddings from \"Alice in Wonderland\". You can limit yourself to the vocabulary of Alice in Wonderland. Visualize the pre-trained word embeddings and compare these with the results of your own trained word embeddings. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1\n",
    "### Using the CBOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17896, 4)\n",
      "(17896, 2557)\n",
      "2557\n"
     ]
    }
   ],
   "source": [
    "#prepare data for cbow\n",
    "path = 'alice.txt'\n",
    "corpus = open(path).readlines()\n",
    "corpus = [sentence for sentence in corpus if sentence.count(\" \") >= 2]\n",
    "\n",
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'+\"'\")\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "corpus = tokenizer.texts_to_sequences(corpus)\n",
    "nb_samples = sum(len(s) for s in corpus)\n",
    "V = len(tokenizer.word_index) + 1\n",
    "\n",
    "def prep_cbow_data(corpus=corpus,window_size=window_size,V=V):\n",
    "    x = []\n",
    "    y = []\n",
    "    w = window_size\n",
    "    for sentence in corpus:\n",
    "        word_length = len(sentence)\n",
    "        if word_length >4:\n",
    "            start = w\n",
    "            for i in range(w,word_length-w):\n",
    "                context_before = sentence[i-w:i]\n",
    "                target = np.zeros(V,dtype=int)\n",
    "                target[sentence[i]] = 1\n",
    "                context_after = sentence[i+1:i+1+start]\n",
    "                context = context_before + context_after\n",
    "                if len(context) == 4:\n",
    "                    #onehot_context = np.asarray(onehot_context)\n",
    "                    x.append(context)\n",
    "                    y.append(target)\n",
    "        else:\n",
    "            pass\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    return x,y\n",
    "\n",
    "print(prep_cbow_data()[0].shape)\n",
    "print(prep_cbow_data()[1].shape)\n",
    "print(V)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 4, 50)             127850    \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2557)              513957    \n",
      "=================================================================\n",
      "Total params: 641,807\n",
      "Trainable params: 641,807\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 4, 150)            383550    \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2557)              1536757   \n",
      "=================================================================\n",
      "Total params: 1,920,307\n",
      "Trainable params: 1,920,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 4, 300)            767100    \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2557)              3070957   \n",
      "=================================================================\n",
      "Total params: 3,838,057\n",
      "Trainable params: 3,838,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(input_dim=2557, output_dim=50, input_length=4, embeddings_initializer=\"glorot_uniform\")`\n",
      "  \n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2557, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(input_dim=2557, output_dim=150, input_length=4, embeddings_initializer=\"glorot_uniform\")`\n",
      "  \n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2557, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")`\n",
      "  app.launch_new_instance()\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(input_dim=2557, output_dim=300, input_length=4, embeddings_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2557, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")`\n"
     ]
    }
   ],
   "source": [
    "#create CBOW model\n",
    "from keras.layers import Flatten\n",
    "#X,Y = prep_cbow_data()\n",
    "#features = len(X)\n",
    "#print(\"size X: {},size Y:{}\".format(len(X),len(Y)))\n",
    "#print(X.shape,Y.shape)\n",
    "cbow_50 = Sequential(name=\"cbow50\")\n",
    "cbow_50.add(Embedding(input_dim=V, output_dim=50, init='glorot_uniform',input_length=4))\n",
    "cbow_50.add(Flatten())\n",
    "cbow_50.add(Dense(V, init='glorot_uniform', activation='softmax'))\n",
    "\n",
    "cbow_50.summary()\n",
    "cbow_150 = Sequential(name=\"cbow150\")\n",
    "cbow_150.add(Embedding(input_dim=V, output_dim=150, init='glorot_uniform',input_length=4))\n",
    "cbow_150.add(Flatten())\n",
    "cbow_150.add(Dense(V, init='glorot_uniform', activation='softmax'))\n",
    "cbow_150.summary()\n",
    "\n",
    "cbow_300 = Sequential(name=\"cbow300\")\n",
    "cbow_300.add(Embedding(input_dim=V, output_dim=300, init='glorot_uniform',input_length=4))\n",
    "cbow_300.add(Flatten())\n",
    "cbow_300.add(Dense(V, init='glorot_uniform', activation='softmax'))\n",
    "cbow_300.summary()\n",
    "\n",
    "cbow_models = [cbow_50,cbow_150,cbow_300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function\n",
    "for cbow in cbow_models:\n",
    "    cbow.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cbow50\n",
      "Train on 16404 samples, validate on 1492 samples\n",
      "Epoch 1/100\n",
      "16404/16404 [==============================] - 6s 340us/step - loss: 7.8331 - val_loss: 7.8205\n",
      "Epoch 2/100\n",
      "16404/16404 [==============================] - 5s 294us/step - loss: 7.8028 - val_loss: 7.7908\n",
      "Epoch 3/100\n",
      "16404/16404 [==============================] - 5s 295us/step - loss: 7.7638 - val_loss: 7.7437\n",
      "Epoch 4/100\n",
      "16404/16404 [==============================] - 5s 295us/step - loss: 7.6958 - val_loss: 7.6447\n",
      "Epoch 5/100\n",
      "16404/16404 [==============================] - 5s 295us/step - loss: 7.5512 - val_loss: 7.4205\n",
      "Epoch 6/100\n",
      "16404/16404 [==============================] - 5s 296us/step - loss: 7.2535 - val_loss: 7.0241\n",
      "Epoch 7/100\n",
      "16404/16404 [==============================] - 5s 296us/step - loss: 6.8873 - val_loss: 6.7400\n",
      "Epoch 8/100\n",
      "16404/16404 [==============================] - 5s 297us/step - loss: 6.6217 - val_loss: 6.5538\n",
      "Epoch 9/100\n",
      "16404/16404 [==============================] - 5s 297us/step - loss: 6.4229 - val_loss: 6.4112\n",
      "Epoch 10/100\n",
      "16404/16404 [==============================] - 5s 297us/step - loss: 6.2597 - val_loss: 6.2930\n",
      "Epoch 11/100\n",
      "16404/16404 [==============================] - 5s 297us/step - loss: 6.1194 - val_loss: 6.1929\n",
      "Epoch 12/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 5.9962 - val_loss: 6.1085\n",
      "Epoch 13/100\n",
      "16404/16404 [==============================] - 5s 298us/step - loss: 5.8862 - val_loss: 6.0352\n",
      "Epoch 14/100\n",
      "16404/16404 [==============================] - 5s 298us/step - loss: 5.7871 - val_loss: 5.9719\n",
      "Epoch 15/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 5.6966 - val_loss: 5.9140\n",
      "Epoch 16/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 5.6131 - val_loss: 5.8622\n",
      "Epoch 17/100\n",
      "16404/16404 [==============================] - 5s 298us/step - loss: 5.5355 - val_loss: 5.8150\n",
      "Epoch 18/100\n",
      "16404/16404 [==============================] - 5s 297us/step - loss: 5.4627 - val_loss: 5.7726\n",
      "Epoch 19/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 5.3941 - val_loss: 5.7321\n",
      "Epoch 20/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 5.3291 - val_loss: 5.6944\n",
      "Epoch 21/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 5.2676 - val_loss: 5.6595\n",
      "Epoch 22/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 5.2091 - val_loss: 5.6265\n",
      "Epoch 23/100\n",
      "16404/16404 [==============================] - 5s 305us/step - loss: 5.1533 - val_loss: 5.5959\n",
      "Epoch 24/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 5.0998 - val_loss: 5.5668\n",
      "Epoch 25/100\n",
      "16404/16404 [==============================] - 5s 315us/step - loss: 5.0485 - val_loss: 5.5392\n",
      "Epoch 26/100\n",
      "16404/16404 [==============================] - 5s 303us/step - loss: 4.9992 - val_loss: 5.5128\n",
      "Epoch 27/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 4.9516 - val_loss: 5.4877\n",
      "Epoch 28/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.9057 - val_loss: 5.4635\n",
      "Epoch 29/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 4.8613 - val_loss: 5.4411\n",
      "Epoch 30/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 4.8185 - val_loss: 5.4197\n",
      "Epoch 31/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.7769 - val_loss: 5.3987\n",
      "Epoch 32/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 4.7367 - val_loss: 5.3794\n",
      "Epoch 33/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.6974 - val_loss: 5.3602\n",
      "Epoch 34/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.6592 - val_loss: 5.3423\n",
      "Epoch 35/100\n",
      "16404/16404 [==============================] - 5s 304us/step - loss: 4.6221 - val_loss: 5.3248\n",
      "Epoch 36/100\n",
      "16404/16404 [==============================] - 5s 305us/step - loss: 4.5859 - val_loss: 5.3073\n",
      "Epoch 37/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.5506 - val_loss: 5.2914\n",
      "Epoch 38/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 4.5162 - val_loss: 5.2754\n",
      "Epoch 39/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.4825 - val_loss: 5.2599\n",
      "Epoch 40/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 4.4495 - val_loss: 5.2460\n",
      "Epoch 41/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 4.4172 - val_loss: 5.2323\n",
      "Epoch 42/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 4.3856 - val_loss: 5.2192\n",
      "Epoch 43/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 4.3547 - val_loss: 5.2062\n",
      "Epoch 44/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 4.3242 - val_loss: 5.1924\n",
      "Epoch 45/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 4.2944 - val_loss: 5.1807\n",
      "Epoch 46/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 4.2651 - val_loss: 5.1688\n",
      "Epoch 47/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.2363 - val_loss: 5.1577\n",
      "Epoch 48/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.2079 - val_loss: 5.1460\n",
      "Epoch 49/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.1800 - val_loss: 5.1364\n",
      "Epoch 50/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.1525 - val_loss: 5.1269\n",
      "Epoch 51/100\n",
      "16404/16404 [==============================] - 5s 303us/step - loss: 4.1255 - val_loss: 5.1175\n",
      "Epoch 52/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.0989 - val_loss: 5.1071\n",
      "Epoch 53/100\n",
      "16404/16404 [==============================] - 5s 303us/step - loss: 4.0726 - val_loss: 5.0992\n",
      "Epoch 54/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 4.0467 - val_loss: 5.0903\n",
      "Epoch 55/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 4.0212 - val_loss: 5.0810\n",
      "Epoch 56/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 3.9960 - val_loss: 5.0736\n",
      "Epoch 57/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 3.9712 - val_loss: 5.0666\n",
      "Epoch 58/100\n",
      "16404/16404 [==============================] - 5s 303us/step - loss: 3.9465 - val_loss: 5.0595\n",
      "Epoch 59/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 3.9224 - val_loss: 5.0524\n",
      "Epoch 60/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 3.8984 - val_loss: 5.0454\n",
      "Epoch 61/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 3.8747 - val_loss: 5.0387\n",
      "Epoch 62/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 3.8513 - val_loss: 5.0318\n",
      "Epoch 63/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 3.8282 - val_loss: 5.0259\n",
      "Epoch 64/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 3.8052 - val_loss: 5.0201\n",
      "Epoch 65/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 3.7827 - val_loss: 5.0151\n",
      "Epoch 66/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 3.7602 - val_loss: 5.0089\n",
      "Epoch 67/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 3.7381 - val_loss: 5.0043\n",
      "Epoch 68/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 3.7161 - val_loss: 4.9988\n",
      "Epoch 69/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 3.6945 - val_loss: 4.9943\n",
      "Epoch 70/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 3.6729 - val_loss: 4.9904\n",
      "Epoch 71/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 3.6516 - val_loss: 4.9864\n",
      "Epoch 72/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 3.6304 - val_loss: 4.9834\n",
      "Epoch 73/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 3.6095 - val_loss: 4.9807\n",
      "Epoch 74/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 3.5886 - val_loss: 4.9765\n",
      "Epoch 75/100\n",
      "16404/16404 [==============================] - 5s 315us/step - loss: 3.5681 - val_loss: 4.9729\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16404/16404 [==============================] - 5s 294us/step - loss: 3.5477 - val_loss: 4.9687\n",
      "Epoch 77/100\n",
      "16404/16404 [==============================] - 5s 293us/step - loss: 3.5274 - val_loss: 4.9644\n",
      "Epoch 78/100\n",
      "16404/16404 [==============================] - 5s 294us/step - loss: 3.5073 - val_loss: 4.9626\n",
      "Epoch 79/100\n",
      "16404/16404 [==============================] - 5s 294us/step - loss: 3.4875 - val_loss: 4.9581\n",
      "Epoch 80/100\n",
      "16404/16404 [==============================] - 5s 296us/step - loss: 3.4677 - val_loss: 4.9551\n",
      "Epoch 81/100\n",
      "16404/16404 [==============================] - 5s 294us/step - loss: 3.4482 - val_loss: 4.9530\n",
      "Epoch 82/100\n",
      "16404/16404 [==============================] - 5s 295us/step - loss: 3.4287 - val_loss: 4.9502\n",
      "Epoch 83/100\n",
      "16404/16404 [==============================] - 5s 294us/step - loss: 3.4095 - val_loss: 4.9482\n",
      "Epoch 84/100\n",
      "16404/16404 [==============================] - 5s 295us/step - loss: 3.3903 - val_loss: 4.9464\n",
      "Epoch 85/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 3.3713 - val_loss: 4.9436\n",
      "Epoch 86/100\n",
      "16404/16404 [==============================] - 5s 294us/step - loss: 3.3524 - val_loss: 4.9412\n",
      "Epoch 87/100\n",
      "16404/16404 [==============================] - 5s 296us/step - loss: 3.3336 - val_loss: 4.9400\n",
      "Epoch 88/100\n",
      "16404/16404 [==============================] - 5s 295us/step - loss: 3.3150 - val_loss: 4.9365\n",
      "Epoch 89/100\n",
      "16404/16404 [==============================] - 5s 295us/step - loss: 3.2964 - val_loss: 4.9345\n",
      "Epoch 90/100\n",
      "16404/16404 [==============================] - 5s 295us/step - loss: 3.2779 - val_loss: 4.9340\n",
      "Running cbow150\n",
      "Train on 16404 samples, validate on 1492 samples\n",
      "Epoch 1/100\n",
      "16404/16404 [==============================] - 8s 474us/step - loss: 7.8289 - val_loss: 7.8105\n",
      "Epoch 2/100\n",
      "16404/16404 [==============================] - 7s 455us/step - loss: 7.7838 - val_loss: 7.7597\n",
      "Epoch 3/100\n",
      "16404/16404 [==============================] - 7s 454us/step - loss: 7.7090 - val_loss: 7.6509\n",
      "Epoch 4/100\n",
      "16404/16404 [==============================] - 7s 457us/step - loss: 7.5418 - val_loss: 7.3802\n",
      "Epoch 5/100\n",
      "16404/16404 [==============================] - 7s 454us/step - loss: 7.1741 - val_loss: 6.9076\n",
      "Epoch 6/100\n",
      "16404/16404 [==============================] - 8s 460us/step - loss: 6.7454 - val_loss: 6.5931\n",
      "Epoch 7/100\n",
      "16404/16404 [==============================] - 7s 454us/step - loss: 6.4313 - val_loss: 6.3760\n",
      "Epoch 8/100\n",
      "16404/16404 [==============================] - 7s 451us/step - loss: 6.1890 - val_loss: 6.2081\n",
      "Epoch 9/100\n",
      "16404/16404 [==============================] - 7s 453us/step - loss: 5.9903 - val_loss: 6.0740\n",
      "Epoch 10/100\n",
      "16404/16404 [==============================] - 7s 453us/step - loss: 5.8213 - val_loss: 5.9657\n",
      "Epoch 11/100\n",
      "16404/16404 [==============================] - 7s 453us/step - loss: 5.6741 - val_loss: 5.8748\n",
      "Epoch 12/100\n",
      "16404/16404 [==============================] - 7s 453us/step - loss: 5.5432 - val_loss: 5.7962\n",
      "Epoch 13/100\n",
      "16404/16404 [==============================] - 8s 458us/step - loss: 5.4247 - val_loss: 5.7273\n",
      "Epoch 14/100\n",
      "16404/16404 [==============================] - 7s 455us/step - loss: 5.3167 - val_loss: 5.6671\n",
      "Epoch 15/100\n",
      "16404/16404 [==============================] - 7s 454us/step - loss: 5.2174 - val_loss: 5.6118\n",
      "Epoch 16/100\n",
      "16404/16404 [==============================] - 7s 453us/step - loss: 5.1253 - val_loss: 5.5596\n",
      "Epoch 17/100\n",
      "16404/16404 [==============================] - 7s 454us/step - loss: 5.0392 - val_loss: 5.5127\n",
      "Epoch 18/100\n",
      "16404/16404 [==============================] - 7s 455us/step - loss: 4.9586 - val_loss: 5.4707\n",
      "Epoch 19/100\n",
      "16404/16404 [==============================] - 7s 453us/step - loss: 4.8822 - val_loss: 5.4316\n",
      "Epoch 20/100\n",
      "16404/16404 [==============================] - 7s 454us/step - loss: 4.8101 - val_loss: 5.3958\n",
      "Epoch 21/100\n",
      "16404/16404 [==============================] - 7s 455us/step - loss: 4.7419 - val_loss: 5.3614\n",
      "Epoch 22/100\n",
      "16404/16404 [==============================] - 7s 455us/step - loss: 4.6765 - val_loss: 5.3298\n",
      "Epoch 23/100\n",
      "16404/16404 [==============================] - 7s 455us/step - loss: 4.6141 - val_loss: 5.3031\n",
      "Epoch 24/100\n",
      "16404/16404 [==============================] - 7s 454us/step - loss: 4.5540 - val_loss: 5.2739\n",
      "Epoch 25/100\n",
      "16404/16404 [==============================] - 7s 452us/step - loss: 4.4962 - val_loss: 5.2485\n",
      "Epoch 26/100\n",
      "16404/16404 [==============================] - 7s 456us/step - loss: 4.4406 - val_loss: 5.2216\n",
      "Epoch 27/100\n",
      "16404/16404 [==============================] - 7s 456us/step - loss: 4.3869 - val_loss: 5.1998\n",
      "Epoch 28/100\n",
      "16404/16404 [==============================] - 7s 455us/step - loss: 4.3347 - val_loss: 5.1782\n",
      "Epoch 29/100\n",
      "16404/16404 [==============================] - 8s 459us/step - loss: 4.2842 - val_loss: 5.1586\n",
      "Epoch 30/100\n",
      "16404/16404 [==============================] - 7s 456us/step - loss: 4.2352 - val_loss: 5.1385\n",
      "Epoch 31/100\n",
      "16404/16404 [==============================] - 7s 454us/step - loss: 4.1875 - val_loss: 5.1200\n",
      "Epoch 32/100\n",
      "16404/16404 [==============================] - 8s 458us/step - loss: 4.1409 - val_loss: 5.1042\n",
      "Epoch 33/100\n",
      "16404/16404 [==============================] - 7s 454us/step - loss: 4.0954 - val_loss: 5.0889\n",
      "Epoch 34/100\n",
      "16404/16404 [==============================] - 7s 457us/step - loss: 4.0510 - val_loss: 5.0720\n",
      "Epoch 35/100\n",
      "16404/16404 [==============================] - 7s 455us/step - loss: 4.0076 - val_loss: 5.0589\n",
      "Epoch 36/100\n",
      "16404/16404 [==============================] - 7s 456us/step - loss: 3.9649 - val_loss: 5.0441\n",
      "Epoch 37/100\n",
      "16404/16404 [==============================] - 7s 456us/step - loss: 3.9233 - val_loss: 5.0317\n",
      "Epoch 38/100\n",
      "16404/16404 [==============================] - 7s 456us/step - loss: 3.8822 - val_loss: 5.0209\n",
      "Epoch 39/100\n",
      "16404/16404 [==============================] - 7s 457us/step - loss: 3.8420 - val_loss: 5.0129\n",
      "Epoch 40/100\n",
      "16404/16404 [==============================] - 8s 459us/step - loss: 3.8025 - val_loss: 4.9975\n",
      "Epoch 41/100\n",
      "16404/16404 [==============================] - 7s 456us/step - loss: 3.7636 - val_loss: 4.9891\n",
      "Epoch 42/100\n",
      "16404/16404 [==============================] - 8s 458us/step - loss: 3.7254 - val_loss: 4.9806\n",
      "Epoch 43/100\n",
      "16404/16404 [==============================] - 7s 457us/step - loss: 3.6875 - val_loss: 4.9733\n",
      "Epoch 44/100\n",
      "16404/16404 [==============================] - 8s 463us/step - loss: 3.6505 - val_loss: 4.9634\n",
      "Epoch 45/100\n",
      "16404/16404 [==============================] - 8s 460us/step - loss: 3.6136 - val_loss: 4.9567\n",
      "Epoch 46/100\n",
      "16404/16404 [==============================] - 8s 457us/step - loss: 3.5771 - val_loss: 4.9474\n",
      "Epoch 47/100\n",
      "16404/16404 [==============================] - 7s 454us/step - loss: 3.5414 - val_loss: 4.9409\n",
      "Epoch 48/100\n",
      "16404/16404 [==============================] - 8s 458us/step - loss: 3.5058 - val_loss: 4.9346\n",
      "Epoch 49/100\n",
      "16404/16404 [==============================] - 8s 457us/step - loss: 3.4709 - val_loss: 4.9299\n",
      "Epoch 50/100\n",
      "16404/16404 [==============================] - 8s 460us/step - loss: 3.4361 - val_loss: 4.9231\n",
      "Epoch 51/100\n",
      "16404/16404 [==============================] - 7s 456us/step - loss: 3.4019 - val_loss: 4.9184\n",
      "Epoch 52/100\n",
      "16404/16404 [==============================] - 8s 460us/step - loss: 3.3679 - val_loss: 4.9115\n",
      "Epoch 53/100\n",
      "16404/16404 [==============================] - 8s 457us/step - loss: 3.3344 - val_loss: 4.9089\n",
      "Epoch 54/100\n",
      "16404/16404 [==============================] - 8s 460us/step - loss: 3.3011 - val_loss: 4.9038\n",
      "Epoch 55/100\n",
      "16404/16404 [==============================] - 8s 460us/step - loss: 3.2680 - val_loss: 4.9032\n",
      "Running cbow300\n",
      "Train on 16404 samples, validate on 1492 samples\n",
      "Epoch 1/100\n",
      "16404/16404 [==============================] - 11s 693us/step - loss: 7.8236 - val_loss: 7.7991\n",
      "Epoch 2/100\n",
      "16404/16404 [==============================] - 11s 677us/step - loss: 7.7593 - val_loss: 7.7175\n",
      "Epoch 3/100\n",
      "16404/16404 [==============================] - 11s 677us/step - loss: 7.6295 - val_loss: 7.5086\n",
      "Epoch 4/100\n",
      "16404/16404 [==============================] - 11s 680us/step - loss: 7.3109 - val_loss: 7.0307\n",
      "Epoch 5/100\n",
      "16404/16404 [==============================] - 11s 680us/step - loss: 6.8238 - val_loss: 6.6302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "16404/16404 [==============================] - 11s 669us/step - loss: 6.4301 - val_loss: 6.3627\n",
      "Epoch 7/100\n",
      "16404/16404 [==============================] - 11s 673us/step - loss: 6.1293 - val_loss: 6.1634\n",
      "Epoch 8/100\n",
      "16404/16404 [==============================] - 11s 671us/step - loss: 5.8904 - val_loss: 6.0110\n",
      "Epoch 9/100\n",
      "16404/16404 [==============================] - 11s 673us/step - loss: 5.6911 - val_loss: 5.8874\n",
      "Epoch 10/100\n",
      "16404/16404 [==============================] - 11s 674us/step - loss: 5.5191 - val_loss: 5.7851\n",
      "Epoch 11/100\n",
      "16404/16404 [==============================] - 11s 673us/step - loss: 5.3677 - val_loss: 5.6999\n",
      "Epoch 12/100\n",
      "16404/16404 [==============================] - 11s 674us/step - loss: 5.2318 - val_loss: 5.6226\n",
      "Epoch 13/100\n",
      "16404/16404 [==============================] - 11s 674us/step - loss: 5.1090 - val_loss: 5.5536\n",
      "Epoch 14/100\n",
      "16404/16404 [==============================] - 11s 672us/step - loss: 4.9963 - val_loss: 5.4946\n",
      "Epoch 15/100\n",
      "16404/16404 [==============================] - 11s 676us/step - loss: 4.8925 - val_loss: 5.4398\n",
      "Epoch 16/100\n",
      "16404/16404 [==============================] - 11s 674us/step - loss: 4.7953 - val_loss: 5.3893\n",
      "Epoch 17/100\n",
      "16404/16404 [==============================] - 11s 673us/step - loss: 4.7048 - val_loss: 5.3450\n",
      "Epoch 18/100\n",
      "16404/16404 [==============================] - 11s 670us/step - loss: 4.6198 - val_loss: 5.3043\n",
      "Epoch 19/100\n",
      "16404/16404 [==============================] - 11s 679us/step - loss: 4.5394 - val_loss: 5.2669\n",
      "Epoch 20/100\n",
      "16404/16404 [==============================] - 11s 673us/step - loss: 4.4629 - val_loss: 5.2296\n",
      "Epoch 21/100\n",
      "16404/16404 [==============================] - 11s 675us/step - loss: 4.3901 - val_loss: 5.1984\n",
      "Epoch 22/100\n",
      "16404/16404 [==============================] - 11s 672us/step - loss: 4.3202 - val_loss: 5.1692\n",
      "Epoch 23/100\n",
      "16404/16404 [==============================] - 11s 673us/step - loss: 4.2531 - val_loss: 5.1407\n",
      "Epoch 24/100\n",
      "16404/16404 [==============================] - 11s 670us/step - loss: 4.1884 - val_loss: 5.1168\n",
      "Epoch 25/100\n",
      "16404/16404 [==============================] - 11s 671us/step - loss: 4.1260 - val_loss: 5.0924\n",
      "Epoch 26/100\n",
      "16404/16404 [==============================] - 11s 678us/step - loss: 4.0654 - val_loss: 5.0715\n",
      "Epoch 27/100\n",
      "16404/16404 [==============================] - 11s 669us/step - loss: 4.0067 - val_loss: 5.0493\n",
      "Epoch 28/100\n",
      "16404/16404 [==============================] - 11s 678us/step - loss: 3.9497 - val_loss: 5.0318\n",
      "Epoch 29/100\n",
      "16404/16404 [==============================] - 11s 671us/step - loss: 3.8939 - val_loss: 5.0144\n",
      "Epoch 30/100\n",
      "16404/16404 [==============================] - 11s 671us/step - loss: 3.8395 - val_loss: 4.9980\n",
      "Epoch 31/100\n",
      "16404/16404 [==============================] - 11s 675us/step - loss: 3.7864 - val_loss: 4.9838\n",
      "Epoch 32/100\n",
      "16404/16404 [==============================] - 11s 675us/step - loss: 3.7341 - val_loss: 4.9695\n",
      "Epoch 33/100\n",
      "16404/16404 [==============================] - 11s 670us/step - loss: 3.6830 - val_loss: 4.9555\n",
      "Epoch 34/100\n",
      "16404/16404 [==============================] - 11s 676us/step - loss: 3.6327 - val_loss: 4.9468\n",
      "Epoch 35/100\n",
      "16404/16404 [==============================] - 11s 673us/step - loss: 3.5833 - val_loss: 4.9354\n",
      "Epoch 36/100\n",
      "16404/16404 [==============================] - 11s 674us/step - loss: 3.5344 - val_loss: 4.9252\n",
      "Epoch 37/100\n",
      "16404/16404 [==============================] - 11s 677us/step - loss: 3.4866 - val_loss: 4.9145\n",
      "Epoch 38/100\n",
      "16404/16404 [==============================] - 11s 675us/step - loss: 3.4392 - val_loss: 4.9057\n",
      "Epoch 39/100\n",
      "16404/16404 [==============================] - 11s 672us/step - loss: 3.3924 - val_loss: 4.8979\n",
      "Epoch 40/100\n",
      "16404/16404 [==============================] - 11s 676us/step - loss: 3.3465 - val_loss: 4.8914\n",
      "Epoch 41/100\n",
      "16404/16404 [==============================] - 11s 673us/step - loss: 3.3006 - val_loss: 4.8814\n",
      "Epoch 42/100\n",
      "16404/16404 [==============================] - 11s 673us/step - loss: 3.2556 - val_loss: 4.8760\n",
      "Epoch 43/100\n",
      "16404/16404 [==============================] - 11s 674us/step - loss: 3.2112 - val_loss: 4.8712\n",
      "Epoch 44/100\n",
      "16404/16404 [==============================] - 11s 670us/step - loss: 3.1668 - val_loss: 4.8662\n",
      "Epoch 45/100\n",
      "16404/16404 [==============================] - 11s 668us/step - loss: 3.1235 - val_loss: 4.8602\n",
      "Epoch 46/100\n",
      "16404/16404 [==============================] - 11s 676us/step - loss: 3.0802 - val_loss: 4.8550\n",
      "Epoch 47/100\n",
      "16404/16404 [==============================] - 11s 679us/step - loss: 3.0375 - val_loss: 4.8518\n",
      "Epoch 48/100\n",
      "16404/16404 [==============================] - 11s 675us/step - loss: 2.9954 - val_loss: 4.8480\n",
      "Epoch 49/100\n",
      "16404/16404 [==============================] - 11s 683us/step - loss: 2.9533 - val_loss: 4.8435\n",
      "Epoch 50/100\n",
      "16404/16404 [==============================] - 11s 675us/step - loss: 2.9122 - val_loss: 4.8373\n",
      "Epoch 51/100\n",
      "16404/16404 [==============================] - 11s 675us/step - loss: 2.8711 - val_loss: 4.8377\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "from keras import callbacks\n",
    "X,Y = prep_cbow_data()\n",
    "epochs=100\n",
    "b_size = 250\n",
    "earlyStopping=callbacks.EarlyStopping(monitor='val_loss',min_delta=0.001, patience=0, verbose=0, mode='auto')\n",
    "trained_models = []\n",
    "for cbow in cbow_models:\n",
    "    print(\"Running {}\".format(cbow.name))\n",
    "    cbow.fit(X,Y,batch_size=b_size,epochs=epochs,validation_split=1/12, callbacks=[earlyStopping])\n",
    "    cbow.save(cbow.name+\".h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in trained_models:\n",
    "    model.save(model.name +'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 \n",
    "## Using the Skipgram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data for Skipgram\n",
    "def generate_data_skipgram(corpus, window_size, V):\n",
    "    maxlen = window_size*2\n",
    "    all_in = []\n",
    "    all_out = []\n",
    "    for words in corpus:\n",
    "        L = len(words)\n",
    "        for index, word in enumerate(words):\n",
    "            p = index - window_size\n",
    "            n = index + window_size + 1\n",
    "                    \n",
    "            in_words = []\n",
    "            labels = []\n",
    "            for i in range(p, n):\n",
    "                if i != index and 0 <= i < L:\n",
    "                    in_words.append([word])\n",
    "                    labels.append(words[i])\n",
    "            if in_words != []:\n",
    "                all_in.append(np.array(in_words,dtype=np.int32))\n",
    "                all_out.append(np_utils.to_categorical(labels, V))\n",
    "    return (all_in,all_out)\n",
    "\n",
    "#get x and y's for data\n",
    "x,y = generate_data_skipgram(corpus,window_size,V)\n",
    "\n",
    "#save the preprocessed data of Skipgram\n",
    "f = open('data_skipgram.txt' ,'w')\n",
    "\n",
    "for input,outcome  in zip(x,y):\n",
    "    input = np.concatenate(input)\n",
    "    f.write(\" \".join(map(str, list(input))))\n",
    "    f.write(\",\")\n",
    "    outcome = np.concatenate(outcome)\n",
    "    f.write(\" \".join(map(str,list(outcome))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "#load the preprocessed Skipgram data\n",
    "def generate_data_skipgram_from_file():\n",
    "    f = open('data_skipgram.txt' ,'r')\n",
    "    for row in f:\n",
    "        inputs,outputs = row.split(\",\")\n",
    "        inputs = np.fromstring(inputs, dtype=int, sep=' ')\n",
    "        inputs = np.asarray(np.split(inputs, len(inputs)))\n",
    "        outputs = np.fromstring(outputs, dtype=float, sep=' ')\n",
    "        outputs = np.asarray(np.split(outputs, len(inputs)))\n",
    "        yield (inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Skipgram model\n",
    "\n",
    "dim1=50\n",
    "dim2=150\n",
    "dim3=300\n",
    "skipgram_50 = Sequential()\n",
    "skipgram_50.add(Embedding(input_dim=V, output_dim=dim1, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram_50.add(Reshape((dim1, )))\n",
    "skipgram_50.add(Dense(input_dim=dim1, units=V, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "skipgram_150 = Sequential()\n",
    "skipgram_150.add(Embedding(input_dim=V, output_dim=dim2, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram_150.add(Reshape((dim2, )))\n",
    "skipgram_150.add(Dense(input_dim=dim2, units=V, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "skipgram_300 = Sequential()\n",
    "skipgram_300.add(Embedding(input_dim=V, output_dim=dim3, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram_300.add(Reshape((dim3, )))\n",
    "skipgram_300.add(Dense(input_dim=dim3, units=V, kernel_initializer='uniform', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function for Skipgram\n",
    "skipgram_50.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
    "skipgram_150.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
    "skipgram_300.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 42020.850971221924\n",
      "1 38379.24893140793\n",
      "2 39009.6740334034\n",
      "3 39515.18972373009\n",
      "4 39694.606760025024\n",
      "5 39879.188750982285\n",
      "6 40052.81768655777\n",
      "7 40222.94297456741\n",
      "8 40406.03855037689\n",
      "9 40601.82211446762\n",
      "0 41999.72671556473\n",
      "1 38329.860137462616\n",
      "2 38863.99836754799\n",
      "3 39224.9512283802\n",
      "4 39388.4169280529\n",
      "5 39532.090304374695\n",
      "6 39681.889948129654\n",
      "7 39846.23095178604\n",
      "8 40013.75022268295\n",
      "9 40184.366864323616\n",
      "0 41972.11958169937\n",
      "1 38265.37358021736\n",
      "2 38667.456391334534\n",
      "3 38952.51325392723\n",
      "4 39107.2551445961\n",
      "5 39254.421288490295\n",
      "6 39401.511434555054\n",
      "7 39544.53228521347\n",
      "8 39688.97990846634\n",
      "9 39832.670347929\n"
     ]
    }
   ],
   "source": [
    "#train Skipgram model\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += skipgram_50.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)\n",
    "    \n",
    "f = open('vectors_skipgram_50.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim1)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = skipgram_50.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += skipgram_150.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)\n",
    "    \n",
    "f = open('vectors_skipgram_150.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim2)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = skipgram_150.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += skipgram_300.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)\n",
    "    \n",
    "f = open('vectors_skipgram_300.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim3)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = skipgram_300.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3\n",
    "### Add extra hidden dense layer to CBow and Skipgram implementations. Choose an activation function for that layer and justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(input_dim=1183, output_dim=100, input_length=4, embeddings_initializer=\"glorot_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1183, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#create CBOW model with additional dense layer\n",
    "dims = [50,150,300]\n",
    "extended_models = []\n",
    "for dim in dims:\n",
    "    cbow = Sequential(name=\"cbow_extended_\"+str(dim))\n",
    "    cbow.add(Embedding(input_dim=V, output_dim=dim, init='glorot_uniform',input_length=4))\n",
    "    cbow.add(Flatten())\n",
    "    cbow.add(Dense(V,activation='relu',name=\"dense1\"))\n",
    "    cbow.add(Dense(V, init='glorot_uniform', activation='softmax'))\n",
    "    extended_models.append(cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function for CBOW + dense\n",
    "for model in extended_models:\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5903 samples, validate on 656 samples\n",
      "Epoch 1/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 6.7766 - val_loss: 6.1094\n",
      "Epoch 2/100\n",
      "5903/5903 [==============================] - 9s 1ms/step - loss: 5.8327 - val_loss: 5.7606\n",
      "Epoch 3/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 5.5145 - val_loss: 5.5747\n",
      "Epoch 4/100\n",
      "5903/5903 [==============================] - 8s 1ms/step - loss: 5.2639 - val_loss: 5.4150\n",
      "Epoch 5/100\n",
      "5903/5903 [==============================] - 8s 1ms/step - loss: 5.0215 - val_loss: 5.2781\n",
      "Epoch 6/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 4.7894 - val_loss: 5.1477\n",
      "Epoch 7/100\n",
      "5903/5903 [==============================] - 11s 2ms/step - loss: 4.5724 - val_loss: 5.0567\n",
      "Epoch 8/100\n",
      "5903/5903 [==============================] - 10s 2ms/step - loss: 4.3716 - val_loss: 4.9879\n",
      "Epoch 9/100\n",
      "5903/5903 [==============================] - 10s 2ms/step - loss: 4.1812 - val_loss: 4.9395\n",
      "Epoch 10/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 3.9998 - val_loss: 4.8841\n",
      "Epoch 11/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 3.8235 - val_loss: 4.8715\n",
      "Epoch 12/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 3.6504 - val_loss: 4.8396\n",
      "Epoch 13/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 3.4827 - val_loss: 4.8171\n",
      "Epoch 14/100\n",
      "5903/5903 [==============================] - 10s 2ms/step - loss: 3.3142 - val_loss: 4.8193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bafacd8668>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model for CBOW + dense\n",
    "from keras import callbacks\n",
    "X,Y = prep_cbow_data()\n",
    "features = len(X)\n",
    "print(\"size X: {},size Y:{}\".format(len(X),len(Y)))\n",
    "print(X.shape,Y.shape)\n",
    "epochs=50\n",
    "for model in extended_models:\n",
    "    earlyStopping=callbacks.EarlyStopping(monitor='val_loss', patience=2, verbose=0, mode='auto')\n",
    "    print(\"training {}\".format(model.name))\n",
    "    model.fit(X,Y,epochs=epochs,validation_split=0.1, callbacks=[earlyStopping])\n",
    "    model.save(model.name+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Skipgram with additional dense layer\n",
    "\n",
    "#create Skipgram model\n",
    "\n",
    "skipgram_50_dense = Sequential()\n",
    "skipgram_50_dense.add(Embedding(input_dim=V, output_dim=dim1, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram_50_dense.add(Reshape((dim1, )))\n",
    "skipgram_50_dense.add(Dense(V,activation='relu'))\n",
    "skipgram_50_dense.add(Dense(input_dim=dim1, units=V, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "skipgram_150_dense = Sequential()\n",
    "skipgram_150_dense.add(Embedding(input_dim=V, output_dim=dim2, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram_150_dense.add(Reshape((dim2, )))\n",
    "skipgram_150_dense.add(Dense(V,activation='relu'))\n",
    "skipgram_150_dense.add(Dense(input_dim=dim2, units=V, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "skipgram_300_dense = Sequential()\n",
    "skipgram_300_dense.add(Embedding(input_dim=V, output_dim=dim3, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram_300_dense.add(Reshape((dim3, )))\n",
    "skipgram_300_dense.add(Dense(V,activation='relu'))\n",
    "skipgram_300_dense.add(Dense(input_dim=dim3, units=V, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "#skipgram2 = Sequential()\n",
    "#skipgram2.add(Embedding(input_dim=V, output_dim=dim, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "#skipgram2.add(Reshape((dim, )))\n",
    "#skipgram2.add(Dense(input_dim=dim, units=V, kernel_initializer='uniform', activation='softmax'))\n",
    "#skipgram2.add(Dense(input_dim=dim, units=V, kernel_initializer='uniform', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function for Skipgram + dense\n",
    "skipgram_50_dense.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
    "skipgram_150_dense.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
    "skipgram_300_dense.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 39444.32987213135\n",
      "1 38264.48951482773\n",
      "2 37948.66480302811\n",
      "3 37769.99622249603\n",
      "4 37750.78943347931\n",
      "5 37725.23108911514\n",
      "6 37674.930666565895\n",
      "7 37620.79466640949\n",
      "8 37566.527002334595\n",
      "9 37519.70512115955\n",
      "0 39471.03422307968\n",
      "1 38220.93018221855\n",
      "2 37718.286794900894\n",
      "3 37538.61131024361\n",
      "4 37493.13153910637\n",
      "5 37456.600872159004\n",
      "6 37402.676347732544\n",
      "7 37335.5792144537\n",
      "8 37265.79830777645\n",
      "9 37196.82523834705\n",
      "0 39445.47623085976\n",
      "1 38082.24569654465\n",
      "2 37592.96987724304\n",
      "3 37330.86567401886\n",
      "4 37259.75267124176\n",
      "5 37224.620362997055\n",
      "6 37161.21744906902\n",
      "7 37086.09090960026\n",
      "8 37002.261269927025\n",
      "9 36925.072355270386\n"
     ]
    }
   ],
   "source": [
    "#train model for Skipgram + dense\n",
    "#train Skipgram model\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += skipgram_50_dense.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)\n",
    "    \n",
    "f = open('vectors_skipgram_50_dense.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim1)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = skipgram_50_dense.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += skipgram_150_dense.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)\n",
    "    \n",
    "f = open('vectors_skipgram_150_dense.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim2)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = skipgram_150_dense.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += skipgram_300_dense.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)\n",
    "    \n",
    "f = open('vectors_skipgram_300_dense.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim3)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = skipgram_300_dense.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "skipgram_50.save('skipgram_50.h5')\n",
    "skipgram_150.save('skipgram_150.h5')\n",
    "skipgram_300.save('skipgram_300.h5')\n",
    "skipgram_50_dense.save('skipgram_50_dense.h5')\n",
    "skipgram_150_dense.save('skipgram_150_dense.h5')\n",
    "skipgram_300_dense.save('skipgram_300_dense.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "explain activation layer\n",
    "\n",
    "We add an extra hidden dense layer just before the final dense layer. We use ReLU activation function since it is the simplest non-linear activation function that is commonly used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4\n",
    "### Analyze the four different word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement your own analogy function\n",
    "\n",
    "key_cbow_50 ={}\n",
    "key_cbow_150 ={}\n",
    "key_cbow_300 ={}\n",
    "key_cbow_50_dense ={}\n",
    "key_cbow_150_dense ={}\n",
    "key_cbow_300_dense ={}\n",
    "key_skipgram_50 ={}\n",
    "key_skipgram_150 ={}\n",
    "key_skipgram_300 ={}\n",
    "key_skipgram_50_dense ={}\n",
    "key_skipgram_150_dense ={}\n",
    "key_skipgram_300_dense ={}\n",
    "\n",
    "embed_cbow_50 =[]\n",
    "embed_cbow_150 =[]\n",
    "embed_cbow_300 =[]\n",
    "embed_cbow_50_dense =[]\n",
    "embed_cbow_150_dense =[]\n",
    "embed_cbow_300_dense =[]\n",
    "embed_skipgram_50 =[]\n",
    "embed_skipgram_150 =[]\n",
    "embed_skipgram_300 =[]\n",
    "embed_skipgram_50_dense =[]\n",
    "embed_skipgram_150_dense =[]\n",
    "embed_skipgram_300_dense =[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_from_file(a):\n",
    "    f = open(a ,'r')\n",
    "    key_dict={}\n",
    "    vect=[]\n",
    "    for row in f:\n",
    "        dimention=0\n",
    "        inp = row.split(\"\\n\")[0].split(\" \")\n",
    "        if(len(inp)==2):\n",
    "            dimention=inp[1]\n",
    "        else:\n",
    "            key_dict.update({inp[0]:len(key_dict)})\n",
    "            vect.append(np.asarray(inp[1:],dtype=float))\n",
    "    return (vect,key_dict)\n",
    "\n",
    "(embed_cbow_50,key_cbow_50)=load_from_file('vectors_cbow_50.txt')\n",
    "(embed_cbow_150,key_cbow_150)=load_from_file('vectors_cbow_150.txt')\n",
    "(embed_cbow_300,key_cbow_300)=load_from_file('vectors_cbow_300.txt')\n",
    "(embed_cbow_50_dense,key_cbow_50_dense)=load_from_file('vectors_cbow_50_dense.txt')\n",
    "(embed_cbow_150_dense,key_cbow_150_dense)=load_from_file('vectors_cbow_150_dense.txt')\n",
    "(embed_cbow_300_dense,key_cbow_300_dense)=load_from_file('vectors_cbow_300_dense.txt')\n",
    "(embed_skipgram_50,key_skipgram_50)=load_from_file('vectors_skipgram_50.txt')\n",
    "(embed_skipgram_150,key_skipgram_150)=load_from_file('vectors_skipgram_150.txt')\n",
    "(embed_skipgram_300,key_skipgram_300)=load_from_file('vectors_skipgram_300.txt')\n",
    "(embed_skipgram_50_dense,key_skipgram_50_dense)=load_from_file('vectors_skipgram_50_dense.txt')\n",
    "(embed_skipgram_150_dense,key_skipgram_150_dense)=load_from_file('vectors_skipgram_150_dense.txt')\n",
    "(embed_skipgram_300_dense,key_skipgram_300_dense)=load_from_file('vectors_skipgram_300_dense.txt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3108869698881552\n",
      "0.3173297559423709\n",
      "0.0379434827632857\n"
     ]
    }
   ],
   "source": [
    "import operator \n",
    "def load_analogy():\n",
    "    f = open('analogy_alice.txt' ,'r')\n",
    "    analogy_list=[]\n",
    "    for row in f:\n",
    "        a = row.split(\"\\n\")[0].split(\" \")\n",
    "        analogy_list.append(np.asarray(a))\n",
    "    return analogy_list\n",
    "\n",
    "def analogy_check(analogy_list,embed_matrix,dictionary):\n",
    "    v=[[],[],[],[]]\n",
    "    for i in range(4):\n",
    "        if(analogy_list[i] in dictionary):\n",
    "            v[i]=embed_matrix[dictionary[analogy_list[i]]-1]\n",
    "        else:\n",
    "            v[i]=np.zeros(len(embed_matrix[0]))\n",
    "    #print(dictionary)\n",
    "    #return abs(cos_sim(v[0],v[2])-cos_sim(v[1],v[3]))\n",
    "    #return 1-abs(cos_sim(v[0],v[1])-cos_sim(v[2],v[3]))\n",
    "    #return cos_sim( list(map(sum, zip(list(map(operator.sub, v[0],v[1]))), v[2])),v[3])\n",
    "    #return abs(cos_sim(v[0]-v[2]+v[1],v[3]))\n",
    "    return abs(cos_sim( (v[0]+v[1]),(v[2]+v[3])))\n",
    "\n",
    "\n",
    "analogy_list=load_analogy()\n",
    "#print(analogy_list[0])\n",
    "print(analogy_check([\"go\",\"going\",\"look\",\"looking\"],embed_skipgram_150, tokenizer.word_index ))\n",
    "print(analogy_check([\"say\",\"saying\",\"sit\",\"sitting\"],cooccurrence_matrix.toarray(), tokenizer.word_index ))\n",
    "print(analogy_check([\"sudden\",\"suddenly\",\"usual\",\"usually\"],embed_skipgram_300_dense, tokenizer.word_index ))\n",
    "#print(analogy_check([\"king\",\"queen\",\"man\",\"woman\"],embed_cbow_50, tokenizer.word_index ))\n",
    "\n",
    "#analogy_check([\"fancy\",\"fancying\",\"alice\",\"rabbit\"],embed_skipgram_150, tokenizer.word_index )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"king\" in tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read model from tim\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "dim1=50\n",
    "dim2=150\n",
    "dim3=300\n",
    "cbow_50 = load_model('cbow50.h5')\n",
    "cbow_150 = load_model('cbow150.h5')\n",
    "cbow_300 = load_model('cbow300.h5')\n",
    "cbow_50_dense = load_model('cbow_extended_50.h5')\n",
    "cbow_150_dense = load_model('cbow_extended_150.h5')\n",
    "cbow_300_dense = load_model('cbow_extended_300.h5')\n",
    "\n",
    "f = open('vectors_cbow_50.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim1)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = cbow_50.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open('vectors_cbow_150.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim2)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = cbow_150.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open('vectors_cbow_300.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim3)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = cbow_300.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open('vectors_cbow_50_dense.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim1)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = cbow_50_dense.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open('vectors_cbow_150_dense.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim2)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = cbow_150_dense.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open('vectors_cbow_300_dense.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim3)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = cbow_300_dense.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbow_50: sudden, suddenly, usual, usually: 0.2145599465610109\n",
      "cbow_150: sudden, suddenly, usual, usually: 0.16464666681544313\n",
      "cbow_300: sudden, suddenly, usual, usually: 0.04262983580543956\n",
      "cbow_50_dense: sudden, suddenly, usual, usually: 0.024934976086477847\n",
      "cbow_150_dense: sudden, suddenly, usual, usually: 0.06584301080295592\n",
      "cbow_300_dense: sudden, suddenly, usual, usually: 0.057512587300851306\n",
      "skipgram_50: sudden, suddenly, usual, usually: 0.051247048932523284\n",
      "skipgram_150: sudden, suddenly, usual, usually: 0.11488630353144216\n",
      "skipgram_300: sudden, suddenly, usual, usually: 0.025398620492292738\n",
      "skipgram_50_dense: sudden, suddenly, usual, usually: 0.11550091531896342\n",
      "skipgram_150_dense: sudden, suddenly, usual, usually: 0.09122986493247628\n",
      "skipgram_300_dense: sudden, suddenly, usual, usually: 0.0379434827632857\n",
      "\n",
      "cbow_50: bad, worse, good, better: 0.007139452508570647\n",
      "cbow_150: bad, worse, good, better: 0.04960375886754415\n",
      "cbow_300: bad, worse, good, better: 0.08364212988123694\n",
      "cbow_50_dense: bad, worse, good, better: 0.026874943420956886\n",
      "cbow_150_dense: bad, worse, good, better: 0.12296815517749676\n",
      "cbow_300_dense: bad, worse, good, better: 0.022567480791767187\n",
      "skipgram_50: bad, worse, good, better: 0.14242828767090374\n",
      "skipgram_150: bad, worse, good, better: 0.06110748320636268\n",
      "skipgram_300: bad, worse, good, better: 0.014283902125049552\n",
      "skipgram_50_dense: bad, worse, good, better: 0.07730987059232503\n",
      "skipgram_150_dense: bad, worse, good, better: 0.11583589719793469\n",
      "skipgram_300_dense: bad, worse, good, better: 0.06542767465641082\n",
      "\n",
      "cbow_50: go, going, look, looking: 0.04482878540457188\n",
      "cbow_150: go, going, look, looking: 0.13521208123901596\n",
      "cbow_300: go, going, look, looking: 0.11739576262876612\n",
      "cbow_50_dense: go, going, look, looking: 0.2275989682841857\n",
      "cbow_150_dense: go, going, look, looking: 0.08095648478867602\n",
      "cbow_300_dense: go, going, look, looking: 0.014954370905789528\n",
      "skipgram_50: go, going, look, looking: 0.04897776970140745\n",
      "skipgram_150: go, going, look, looking: 0.3108869698881552\n",
      "skipgram_300: go, going, look, looking: 0.1897161720304399\n",
      "skipgram_50_dense: go, going, look, looking: 0.14061684371374158\n",
      "skipgram_150_dense: go, going, look, looking: 0.14720249473774485\n",
      "skipgram_300_dense: go, going, look, looking: 0.002864495321771528\n",
      "\n",
      "cbow_50: he, she, his, her: 0.08099932963910215\n",
      "cbow_150: he, she, his, her: 0.03569783846020872\n",
      "cbow_300: he, she, his, her: 0.022474709476888687\n",
      "cbow_50_dense: he, she, his, her: 0.25305776920456663\n",
      "cbow_150_dense: he, she, his, her: 0.05257730241374489\n",
      "cbow_300_dense: he, she, his, her: 0.12253203367780965\n",
      "skipgram_50: he, she, his, her: 0.5350455025860693\n",
      "skipgram_150: he, she, his, her: 0.4214261528756635\n",
      "skipgram_300: he, she, his, her: 0.1928937824570437\n",
      "skipgram_50_dense: he, she, his, her: 0.2154861486119754\n",
      "skipgram_150_dense: he, she, his, her: 0.14655767256694316\n",
      "skipgram_300_dense: he, she, his, her: 0.1511302407262479\n",
      "\n",
      "cbow_50: brother, sister, his, her: 0.3216747204943751\n",
      "cbow_150: brother, sister, his, her: 0.23105893917756617\n",
      "cbow_300: brother, sister, his, her: 0.07589060484117083\n",
      "cbow_50_dense: brother, sister, his, her: 0.08839213138780096\n",
      "cbow_150_dense: brother, sister, his, her: 0.03201457747498062\n",
      "cbow_300_dense: brother, sister, his, her: 0.010614877330893632\n",
      "skipgram_50: brother, sister, his, her: 0.08925583606036332\n",
      "skipgram_150: brother, sister, his, her: 0.11066786236035159\n",
      "skipgram_300: brother, sister, his, her: 0.15242621645498913\n",
      "skipgram_50_dense: brother, sister, his, her: 0.16731238470239565\n",
      "skipgram_150_dense: brother, sister, his, her: 0.1600951228220338\n",
      "skipgram_300_dense: brother, sister, his, her: 0.10670694926142113\n",
      "\n",
      "cbow_50: listen, listening, look, looking: 0.3802069701610734\n",
      "cbow_150: listen, listening, look, looking: 0.36921053308958424\n",
      "cbow_300: listen, listening, look, looking: 0.23802999618462123\n",
      "cbow_50_dense: listen, listening, look, looking: 0.03956834867672034\n",
      "cbow_150_dense: listen, listening, look, looking: 0.025226025836383444\n",
      "cbow_300_dense: listen, listening, look, looking: 0.08170528413458206\n",
      "skipgram_50: listen, listening, look, looking: 0.21922497121328843\n",
      "skipgram_150: listen, listening, look, looking: 0.11884336654412271\n",
      "skipgram_300: listen, listening, look, looking: 0.012053642266116044\n",
      "skipgram_50_dense: listen, listening, look, looking: 0.3328211143150717\n",
      "skipgram_150_dense: listen, listening, look, looking: 0.0595487007636639\n",
      "skipgram_300_dense: listen, listening, look, looking: 0.0406596642434014\n",
      "\n",
      "cbow_50: saying, said, thinking, thought: 0.3083834417108346\n",
      "cbow_150: saying, said, thinking, thought: 0.30258397528363445\n",
      "cbow_300: saying, said, thinking, thought: 0.3385169623849108\n",
      "cbow_50_dense: saying, said, thinking, thought: 0.27146892652097987\n",
      "cbow_150_dense: saying, said, thinking, thought: 0.26399041172107607\n",
      "cbow_300_dense: saying, said, thinking, thought: 0.12383424063284779\n",
      "skipgram_50: saying, said, thinking, thought: 0.565914284020611\n",
      "skipgram_150: saying, said, thinking, thought: 0.3787360042101855\n",
      "skipgram_300: saying, said, thinking, thought: 0.30719562937336314\n",
      "skipgram_50_dense: saying, said, thinking, thought: 0.032715337214361935\n",
      "skipgram_150_dense: saying, said, thinking, thought: 0.03265436792557913\n",
      "skipgram_300_dense: saying, said, thinking, thought: 0.08585073444779104\n",
      "\n",
      "cbow_50: bird, birds, cat, cats: 0.25155843706819225\n",
      "cbow_150: bird, birds, cat, cats: 0.11949157172847855\n",
      "cbow_300: bird, birds, cat, cats: 0.1781694964528609\n",
      "cbow_50_dense: bird, birds, cat, cats: 0.2320395959316713\n",
      "cbow_150_dense: bird, birds, cat, cats: 0.0884316106458272\n",
      "cbow_300_dense: bird, birds, cat, cats: 0.14467242053834647\n",
      "skipgram_50: bird, birds, cat, cats: 0.4165848617676572\n",
      "skipgram_150: bird, birds, cat, cats: 0.12949779747079\n",
      "skipgram_300: bird, birds, cat, cats: 0.12433095616959039\n",
      "skipgram_50_dense: bird, birds, cat, cats: 0.012887874151781279\n",
      "skipgram_150_dense: bird, birds, cat, cats: 0.07353652983537766\n",
      "skipgram_300_dense: bird, birds, cat, cats: 0.05631322940932175\n",
      "\n",
      "cbow_50: good, better, old, older: 0.28356033517821916\n",
      "cbow_150: good, better, old, older: 0.3367662060157432\n",
      "cbow_300: good, better, old, older: 0.24294226160000545\n",
      "cbow_50_dense: good, better, old, older: 0.12562361925379575\n",
      "cbow_150_dense: good, better, old, older: 0.10944203217062437\n",
      "cbow_300_dense: good, better, old, older: 0.18656535061624072\n",
      "skipgram_50: good, better, old, older: 0.006747658278795679\n",
      "skipgram_150: good, better, old, older: 0.2613328446046628\n",
      "skipgram_300: good, better, old, older: 0.16584128942361212\n",
      "skipgram_50_dense: good, better, old, older: 0.006715441594898397\n",
      "skipgram_150_dense: good, better, old, older: 0.05311411308035306\n",
      "skipgram_300_dense: good, better, old, older: 0.05186729010261828\n",
      "\n",
      "cbow_50: good, better, quick, quicker: 0.12513511819856912\n",
      "cbow_150: good, better, quick, quicker: 0.10664919624378821\n",
      "cbow_300: good, better, quick, quicker: 0.03208647290314115\n",
      "cbow_50_dense: good, better, quick, quicker: 0.12567182118934672\n",
      "cbow_150_dense: good, better, quick, quicker: 0.06164886348505986\n",
      "cbow_300_dense: good, better, quick, quicker: 0.051326262550663464\n",
      "skipgram_50: good, better, quick, quicker: 0.037811205524927546\n",
      "skipgram_150: good, better, quick, quicker: 0.011419143924304096\n",
      "skipgram_300: good, better, quick, quicker: 0.026034704557969784\n",
      "skipgram_50_dense: good, better, quick, quicker: 0.033102714983078194\n",
      "skipgram_150_dense: good, better, quick, quicker: 0.03085308262693412\n",
      "skipgram_300_dense: good, better, quick, quicker: 0.0796093389770551\n",
      "\n",
      "cbow_50: large, largest, good, best: 0.055252841538935865\n",
      "cbow_150: large, largest, good, best: 0.14962042649321572\n",
      "cbow_300: large, largest, good, best: 0.13627840091820803\n",
      "cbow_50_dense: large, largest, good, best: 0.1395942175402173\n",
      "cbow_150_dense: large, largest, good, best: 0.11470696113616369\n",
      "cbow_300_dense: large, largest, good, best: 0.05309922636686337\n",
      "skipgram_50: large, largest, good, best: 0.0076305093982703895\n",
      "skipgram_150: large, largest, good, best: 0.1707115412567479\n",
      "skipgram_300: large, largest, good, best: 0.1725711060097743\n",
      "skipgram_50_dense: large, largest, good, best: 0.12473340544962884\n",
      "skipgram_150_dense: large, largest, good, best: 0.06615579167947909\n",
      "skipgram_300_dense: large, largest, good, best: 0.053627787932685286\n",
      "\n",
      "cbow_50: falling, fell, knowing, knew: 0.34969637290903044\n",
      "cbow_150: falling, fell, knowing, knew: 0.16103343892183927\n",
      "cbow_300: falling, fell, knowing, knew: 0.01912836021160874\n",
      "cbow_50_dense: falling, fell, knowing, knew: 0.018394198007298426\n",
      "cbow_150_dense: falling, fell, knowing, knew: 0.05989618949756096\n",
      "cbow_300_dense: falling, fell, knowing, knew: 0.037205425222480805\n",
      "skipgram_50: falling, fell, knowing, knew: 0.06791467768999672\n",
      "skipgram_150: falling, fell, knowing, knew: 0.09136214862017362\n",
      "skipgram_300: falling, fell, knowing, knew: 0.01463649822550943\n",
      "skipgram_50_dense: falling, fell, knowing, knew: 0.16193351261122524\n",
      "skipgram_150_dense: falling, fell, knowing, knew: 0.03656470212890241\n",
      "skipgram_300_dense: falling, fell, knowing, knew: 0.03872969424142178\n",
      "\n",
      "cbow_50: walk, walking, think, thinking: 0.23305398188264462\n",
      "cbow_150: walk, walking, think, thinking: 0.16217284732039994\n",
      "cbow_300: walk, walking, think, thinking: 0.1371422823556235\n",
      "cbow_50_dense: walk, walking, think, thinking: 0.441744421903988\n",
      "cbow_150_dense: walk, walking, think, thinking: 0.27691568613316025\n",
      "cbow_300_dense: walk, walking, think, thinking: 0.25241882965411033\n",
      "skipgram_50: walk, walking, think, thinking: 0.1326619778939263\n",
      "skipgram_150: walk, walking, think, thinking: 0.1950671462577301\n",
      "skipgram_300: walk, walking, think, thinking: 0.05063676675719801\n",
      "skipgram_50_dense: walk, walking, think, thinking: 0.11086919505279523\n",
      "skipgram_150_dense: walk, walking, think, thinking: 0.039340863036024035\n",
      "skipgram_300_dense: walk, walking, think, thinking: 0.020751693251079326\n",
      "\n",
      "cbow_50: child, children, cat, cats: 0.5761045501314452\n",
      "cbow_150: child, children, cat, cats: 0.6283387407761182\n",
      "cbow_300: child, children, cat, cats: 0.4224878099785585\n",
      "cbow_50_dense: child, children, cat, cats: 0.13089713945022188\n",
      "cbow_150_dense: child, children, cat, cats: 0.31170060389105086\n",
      "cbow_300_dense: child, children, cat, cats: 0.15971883179637444\n",
      "skipgram_50: child, children, cat, cats: 0.18690841970146993\n",
      "skipgram_150: child, children, cat, cats: 0.15727020501279124\n",
      "skipgram_300: child, children, cat, cats: 0.1633643593580084\n",
      "skipgram_50_dense: child, children, cat, cats: 0.11475457926841195\n",
      "skipgram_150_dense: child, children, cat, cats: 0.07555755343684083\n",
      "skipgram_300_dense: child, children, cat, cats: 0.08558659954598827\n",
      "\n",
      "cbow_50: dog, dogs, eye, eyes: 0.048068004590513976\n",
      "cbow_150: dog, dogs, eye, eyes: 0.18301195503900555\n",
      "cbow_300: dog, dogs, eye, eyes: 0.08293971404713851\n",
      "cbow_50_dense: dog, dogs, eye, eyes: 0.009944152990215106\n",
      "cbow_150_dense: dog, dogs, eye, eyes: 0.00018806916728422024\n",
      "cbow_300_dense: dog, dogs, eye, eyes: 0.04959143883742041\n",
      "skipgram_50: dog, dogs, eye, eyes: 0.5401933619978343\n",
      "skipgram_150: dog, dogs, eye, eyes: 0.011997018957234177\n",
      "skipgram_300: dog, dogs, eye, eyes: 0.036955218552049134\n",
      "skipgram_50_dense: dog, dogs, eye, eyes: 0.014302918123874776\n",
      "skipgram_150_dense: dog, dogs, eye, eyes: 0.04161267376478868\n",
      "skipgram_300_dense: dog, dogs, eye, eyes: 0.09854696917931136\n",
      "\n",
      "cbow_50: hand, hands, rat, rats: 0.20928379513093132\n",
      "cbow_150: hand, hands, rat, rats: 0.08922689088034921\n",
      "cbow_300: hand, hands, rat, rats: 0.06167524716738153\n",
      "cbow_50_dense: hand, hands, rat, rats: 0.2241956513486761\n",
      "cbow_150_dense: hand, hands, rat, rats: 0.08479348857676028\n",
      "cbow_300_dense: hand, hands, rat, rats: 0.21763028239299223\n",
      "skipgram_50: hand, hands, rat, rats: 0.029477426759401692\n",
      "skipgram_150: hand, hands, rat, rats: 0.13241202071518388\n",
      "skipgram_300: hand, hands, rat, rats: 0.056338820916069676\n",
      "skipgram_50_dense: hand, hands, rat, rats: 0.000745369944340421\n",
      "skipgram_150_dense: hand, hands, rat, rats: 0.18282660345720494\n",
      "skipgram_300_dense: hand, hands, rat, rats: 0.07454463081175015\n",
      "\n",
      "cbow_50: eat, eats, find, finds: 0.6344386909160316\n",
      "cbow_150: eat, eats, find, finds: 0.6230622716693793\n",
      "cbow_300: eat, eats, find, finds: 0.38332741252697833\n",
      "cbow_50_dense: eat, eats, find, finds: 0.11014595751932027\n",
      "cbow_150_dense: eat, eats, find, finds: 0.022188421800295247\n",
      "cbow_300_dense: eat, eats, find, finds: 0.02799474581397439\n",
      "skipgram_50: eat, eats, find, finds: 0.26850222986801453\n",
      "skipgram_150: eat, eats, find, finds: 0.08289657352440934\n",
      "skipgram_300: eat, eats, find, finds: 0.1310917767169901\n",
      "skipgram_50_dense: eat, eats, find, finds: 0.022223655143363493\n",
      "skipgram_150_dense: eat, eats, find, finds: 0.04586212657365139\n",
      "skipgram_300_dense: eat, eats, find, finds: 0.004353422652560424\n",
      "\n",
      "cbow_50: find, finds, say, says: 0.19636398876648298\n",
      "cbow_150: find, finds, say, says: 0.3493458745768275\n",
      "cbow_300: find, finds, say, says: 0.4225110412871306\n",
      "cbow_50_dense: find, finds, say, says: 0.10255216118966275\n",
      "cbow_150_dense: find, finds, say, says: 0.04139482654371349\n",
      "cbow_300_dense: find, finds, say, says: 0.09204581834643971\n",
      "skipgram_50: find, finds, say, says: 0.02189051838308856\n",
      "skipgram_150: find, finds, say, says: 0.11727715537439058\n",
      "skipgram_300: find, finds, say, says: 0.1485523068621352\n",
      "skipgram_50_dense: find, finds, say, says: 0.21955934322292522\n",
      "skipgram_150_dense: find, finds, say, says: 0.02131875144526285\n",
      "skipgram_300_dense: find, finds, say, says: 0.024942033757297807\n",
      "\n",
      "cbow_50: old, older, good, better: 0.28356033517821916\n",
      "cbow_150: old, older, good, better: 0.3367662060157432\n",
      "cbow_300: old, older, good, better: 0.24294226160000545\n",
      "cbow_50_dense: old, older, good, better: 0.12562361925379575\n",
      "cbow_150_dense: old, older, good, better: 0.10944203217062437\n",
      "cbow_300_dense: old, older, good, better: 0.18656535061624072\n",
      "skipgram_50: old, older, good, better: 0.006747658278795679\n",
      "skipgram_150: old, older, good, better: 0.2613328446046628\n",
      "skipgram_300: old, older, good, better: 0.16584128942361212\n",
      "skipgram_50_dense: old, older, good, better: 0.006715441594898397\n",
      "skipgram_150_dense: old, older, good, better: 0.05311411308035306\n",
      "skipgram_300_dense: old, older, good, better: 0.05186729010261828\n",
      "\n",
      "cbow_50: large, larger, quick, quicker: 0.15041247724164664\n",
      "cbow_150: large, larger, quick, quicker: 0.23806847996439426\n",
      "cbow_300: large, larger, quick, quicker: 0.04205617897711103\n",
      "cbow_50_dense: large, larger, quick, quicker: 0.14810958793009651\n",
      "cbow_150_dense: large, larger, quick, quicker: 0.12186104289525825\n",
      "cbow_300_dense: large, larger, quick, quicker: 0.09311372510784723\n",
      "skipgram_50: large, larger, quick, quicker: 0.08552472433803812\n",
      "skipgram_150: large, larger, quick, quicker: 0.12424542939530621\n",
      "skipgram_300: large, larger, quick, quicker: 0.06756714447400183\n",
      "skipgram_50_dense: large, larger, quick, quicker: 0.12221104436704669\n",
      "skipgram_150_dense: large, larger, quick, quicker: 0.053115179996420764\n",
      "skipgram_300_dense: large, larger, quick, quicker: 0.06817445995579048\n",
      "\n",
      "cbow_50: go, going, listen, listening: 0.004348558915977116\n",
      "cbow_150: go, going, listen, listening: 0.04591844648923439\n",
      "cbow_300: go, going, listen, listening: 0.028175657728302012\n",
      "cbow_50_dense: go, going, listen, listening: 0.019190198412343568\n",
      "cbow_150_dense: go, going, listen, listening: 0.13541379022058453\n",
      "cbow_300_dense: go, going, listen, listening: 0.08877512926435754\n",
      "skipgram_50: go, going, listen, listening: 0.05539435165038242\n",
      "skipgram_150: go, going, listen, listening: 0.03247324062648229\n",
      "skipgram_300: go, going, listen, listening: 0.15185486231081524\n",
      "skipgram_50_dense: go, going, listen, listening: 0.14996689018468176\n",
      "skipgram_150_dense: go, going, listen, listening: 0.04243841588618983\n",
      "skipgram_300_dense: go, going, listen, listening: 0.010873228635317379\n",
      "\n",
      "cbow_50: run, running, walk, walking: 0.43239444601331156\n",
      "cbow_150: run, running, walk, walking: 0.17316018462778576\n",
      "cbow_300: run, running, walk, walking: 0.06752979323171769\n",
      "cbow_50_dense: run, running, walk, walking: 0.19041077959930008\n",
      "cbow_150_dense: run, running, walk, walking: 0.08575569090759745\n",
      "cbow_300_dense: run, running, walk, walking: 0.13319373973395193\n",
      "skipgram_50: run, running, walk, walking: 0.05440431387771808\n",
      "skipgram_150: run, running, walk, walking: 0.08192690911244668\n",
      "skipgram_300: run, running, walk, walking: 0.10293102828061876\n",
      "skipgram_50_dense: run, running, walk, walking: 0.10158365041561519\n",
      "skipgram_150_dense: run, running, walk, walking: 0.03850630114665086\n",
      "skipgram_300_dense: run, running, walk, walking: 0.036897706755464\n",
      "\n",
      "cbow_50: run, running, think, thinking: 0.12738615012738252\n",
      "cbow_150: run, running, think, thinking: 0.1885880627853949\n",
      "cbow_300: run, running, think, thinking: 0.13662853663187174\n",
      "cbow_50_dense: run, running, think, thinking: 0.09327913484627907\n",
      "cbow_150_dense: run, running, think, thinking: 0.09934669415267226\n",
      "cbow_300_dense: run, running, think, thinking: 0.013760378794701674\n",
      "skipgram_50: run, running, think, thinking: 0.0266290831646828\n",
      "skipgram_150: run, running, think, thinking: 0.08328285298530103\n",
      "skipgram_300: run, running, think, thinking: 0.06572295097742854\n",
      "skipgram_50_dense: run, running, think, thinking: 0.012145371455604355\n",
      "skipgram_150_dense: run, running, think, thinking: 0.06641353890075766\n",
      "skipgram_300_dense: run, running, think, thinking: 0.13502023716520042\n",
      "\n",
      "cbow_50: say, saying, sit, sitting: 0.13290110049743256\n",
      "cbow_150: say, saying, sit, sitting: 0.13794787877818132\n",
      "cbow_300: say, saying, sit, sitting: 0.1255869428992714\n",
      "cbow_50_dense: say, saying, sit, sitting: 0.08854998828125173\n",
      "cbow_150_dense: say, saying, sit, sitting: 0.08481168346115567\n",
      "cbow_300_dense: say, saying, sit, sitting: 0.002778512915029485\n",
      "skipgram_50: say, saying, sit, sitting: 0.06671581439417851\n",
      "skipgram_150: say, saying, sit, sitting: 0.024395699928681472\n",
      "skipgram_300: say, saying, sit, sitting: 0.08653137863087766\n",
      "skipgram_50_dense: say, saying, sit, sitting: 0.2291511923882307\n",
      "skipgram_150_dense: say, saying, sit, sitting: 0.08249327141657764\n",
      "skipgram_300_dense: say, saying, sit, sitting: 0.031370623390230355\n",
      "\n",
      "cbow_50: alice, she, rabbit, he: 0.3032260713980009\n",
      "cbow_150: alice, she, rabbit, he: 0.28750781874194553\n",
      "cbow_300: alice, she, rabbit, he: 0.23737374549441895\n",
      "cbow_50_dense: alice, she, rabbit, he: 0.37400362858646385\n",
      "cbow_150_dense: alice, she, rabbit, he: 0.2604214341177389\n",
      "cbow_300_dense: alice, she, rabbit, he: 0.22134533492778896\n",
      "skipgram_50: alice, she, rabbit, he: 0.3969428627541493\n",
      "skipgram_150: alice, she, rabbit, he: 0.26935194521993117\n",
      "skipgram_300: alice, she, rabbit, he: 0.1325306631609167\n",
      "skipgram_50_dense: alice, she, rabbit, he: 0.08122499625428377\n",
      "skipgram_150_dense: alice, she, rabbit, he: 0.19001593659421726\n",
      "skipgram_300_dense: alice, she, rabbit, he: 0.1196936498430301\n",
      "\n",
      "cbow_50: alice, her, rabbit, him: 0.4245334730572496\n",
      "cbow_150: alice, her, rabbit, him: 0.3949279690641324\n",
      "cbow_300: alice, her, rabbit, him: 0.4694802520899805\n",
      "cbow_50_dense: alice, her, rabbit, him: 0.37489014507553303\n",
      "cbow_150_dense: alice, her, rabbit, him: 0.2922573512779353\n",
      "cbow_300_dense: alice, her, rabbit, him: 0.3085777141782657\n",
      "skipgram_50: alice, her, rabbit, him: 0.43744368034614123\n",
      "skipgram_150: alice, her, rabbit, him: 0.28236727353514146\n",
      "skipgram_300: alice, her, rabbit, him: 0.16623145761281516\n",
      "skipgram_50_dense: alice, her, rabbit, him: 0.003912821913825373\n",
      "skipgram_150_dense: alice, her, rabbit, him: 0.079360369362521\n",
      "skipgram_300_dense: alice, her, rabbit, him: 0.004352950260186055\n",
      "\n",
      "cbow_50: alice, girl, rabbit, sir: 0.38352821418807104\n",
      "cbow_150: alice, girl, rabbit, sir: 0.3037741386102526\n",
      "cbow_300: alice, girl, rabbit, sir: 0.29111823565411055\n",
      "cbow_50_dense: alice, girl, rabbit, sir: 0.296456905787305\n",
      "cbow_150_dense: alice, girl, rabbit, sir: 0.18437463780691493\n",
      "cbow_300_dense: alice, girl, rabbit, sir: 0.17745145079999616\n",
      "skipgram_50: alice, girl, rabbit, sir: 0.37706869416324595\n",
      "skipgram_150: alice, girl, rabbit, sir: 0.2434311774890583\n",
      "skipgram_300: alice, girl, rabbit, sir: 0.013468505209538413\n",
      "skipgram_50_dense: alice, girl, rabbit, sir: 0.007664461700388371\n",
      "skipgram_150_dense: alice, girl, rabbit, sir: 0.013923791377918283\n",
      "skipgram_300_dense: alice, girl, rabbit, sir: 0.16162886469339285\n",
      "\n",
      "cbow_50: dinah, cat, alice, girl: 0.18871490618643927\n",
      "cbow_150: dinah, cat, alice, girl: 0.1988998323029214\n",
      "cbow_300: dinah, cat, alice, girl: 0.21994575208961464\n",
      "cbow_50_dense: dinah, cat, alice, girl: 0.01817282196713359\n",
      "cbow_150_dense: dinah, cat, alice, girl: 0.12974284936731623\n",
      "cbow_300_dense: dinah, cat, alice, girl: 0.0973591792683185\n",
      "skipgram_50: dinah, cat, alice, girl: 0.20264584206408742\n",
      "skipgram_150: dinah, cat, alice, girl: 0.23600359629142628\n",
      "skipgram_300: dinah, cat, alice, girl: 0.1798156827185624\n",
      "skipgram_50_dense: dinah, cat, alice, girl: 0.06226421184792411\n",
      "skipgram_150_dense: dinah, cat, alice, girl: 0.04952489944505424\n",
      "skipgram_300_dense: dinah, cat, alice, girl: 0.016715979149657174\n",
      "\n",
      "cbow_50: his, her, he, she: 0.08099932963910215\n",
      "cbow_150: his, her, he, she: 0.03569783846020872\n",
      "cbow_300: his, her, he, she: 0.022474709476888687\n",
      "cbow_50_dense: his, her, he, she: 0.25305776920456663\n",
      "cbow_150_dense: his, her, he, she: 0.05257730241374489\n",
      "cbow_300_dense: his, her, he, she: 0.12253203367780965\n",
      "skipgram_50: his, her, he, she: 0.5350455025860693\n",
      "skipgram_150: his, her, he, she: 0.4214261528756635\n",
      "skipgram_300: his, her, he, she: 0.1928937824570437\n",
      "skipgram_50_dense: his, her, he, she: 0.2154861486119754\n",
      "skipgram_150_dense: his, her, he, she: 0.14655767256694316\n",
      "skipgram_300_dense: his, her, he, she: 0.1511302407262479\n",
      "\n",
      "cbow_50: long, longer, quick, quicker: 0.4120102891993884\n",
      "cbow_150: long, longer, quick, quicker: 0.23017015273506933\n",
      "cbow_300: long, longer, quick, quicker: 0.09401260595447117\n",
      "cbow_50_dense: long, longer, quick, quicker: 0.01408052840685802\n",
      "cbow_150_dense: long, longer, quick, quicker: 0.007133586407366825\n",
      "cbow_300_dense: long, longer, quick, quicker: 0.07831883522036924\n",
      "skipgram_50: long, longer, quick, quicker: 0.02151832074829586\n",
      "skipgram_150: long, longer, quick, quicker: 0.09068842882436388\n",
      "skipgram_300: long, longer, quick, quicker: 0.07102139535964663\n",
      "skipgram_50_dense: long, longer, quick, quicker: 0.05400072789551662\n",
      "skipgram_150_dense: long, longer, quick, quicker: 0.11150849188104847\n",
      "skipgram_300_dense: long, longer, quick, quicker: 0.03754801662507641\n",
      "\n",
      "cbow_50: long, longer, small, smaller: 0.4318003131750905\n",
      "cbow_150: long, longer, small, smaller: 0.3554968324347603\n",
      "cbow_300: long, longer, small, smaller: 0.19269746490298645\n",
      "cbow_50_dense: long, longer, small, smaller: 0.5372986667713919\n",
      "cbow_150_dense: long, longer, small, smaller: 0.3725341328264276\n",
      "cbow_300_dense: long, longer, small, smaller: 0.35016791043829654\n",
      "skipgram_50: long, longer, small, smaller: 0.21398489733806456\n",
      "skipgram_150: long, longer, small, smaller: 0.1640505580848037\n",
      "skipgram_300: long, longer, small, smaller: 0.21245308466171794\n",
      "skipgram_50_dense: long, longer, small, smaller: 0.06976419471060234\n",
      "skipgram_150_dense: long, longer, small, smaller: 0.008430045436527846\n",
      "skipgram_300_dense: long, longer, small, smaller: 0.02207475087097485\n",
      "\n",
      "cbow_50: long, longer, bad, worse: 0.3260491473042464\n",
      "cbow_150: long, longer, bad, worse: 0.15212735080104456\n",
      "cbow_300: long, longer, bad, worse: 0.20373219592586617\n",
      "cbow_50_dense: long, longer, bad, worse: 0.08853810932159445\n",
      "cbow_150_dense: long, longer, bad, worse: 0.02362576370261302\n",
      "cbow_300_dense: long, longer, bad, worse: 0.02967005557613777\n",
      "skipgram_50: long, longer, bad, worse: 0.09991521837069943\n",
      "skipgram_150: long, longer, bad, worse: 0.04688277512539548\n",
      "skipgram_300: long, longer, bad, worse: 0.04225910785783235\n",
      "skipgram_50_dense: long, longer, bad, worse: 0.0591265043266381\n",
      "skipgram_150_dense: long, longer, bad, worse: 0.026776340215094604\n",
      "skipgram_300_dense: long, longer, bad, worse: 0.0009287152378468827\n",
      "\n",
      "cbow_50: go, going, look, looking: 0.04482878540457188\n",
      "cbow_150: go, going, look, looking: 0.13521208123901596\n",
      "cbow_300: go, going, look, looking: 0.11739576262876612\n",
      "cbow_50_dense: go, going, look, looking: 0.2275989682841857\n",
      "cbow_150_dense: go, going, look, looking: 0.08095648478867602\n",
      "cbow_300_dense: go, going, look, looking: 0.014954370905789528\n",
      "skipgram_50: go, going, look, looking: 0.04897776970140745\n",
      "skipgram_150: go, going, look, looking: 0.3108869698881552\n",
      "skipgram_300: go, going, look, looking: 0.1897161720304399\n",
      "skipgram_50_dense: go, going, look, looking: 0.14061684371374158\n",
      "skipgram_150_dense: go, going, look, looking: 0.14720249473774485\n",
      "skipgram_300_dense: go, going, look, looking: 0.002864495321771528\n",
      "\n",
      "cbow_50: listen, listening, look, looking: 0.3802069701610734\n",
      "cbow_150: listen, listening, look, looking: 0.36921053308958424\n",
      "cbow_300: listen, listening, look, looking: 0.23802999618462123\n",
      "cbow_50_dense: listen, listening, look, looking: 0.03956834867672034\n",
      "cbow_150_dense: listen, listening, look, looking: 0.025226025836383444\n",
      "cbow_300_dense: listen, listening, look, looking: 0.08170528413458206\n",
      "skipgram_50: listen, listening, look, looking: 0.21922497121328843\n",
      "skipgram_150: listen, listening, look, looking: 0.11884336654412271\n",
      "skipgram_300: listen, listening, look, looking: 0.012053642266116044\n",
      "skipgram_50_dense: listen, listening, look, looking: 0.3328211143150717\n",
      "skipgram_150_dense: listen, listening, look, looking: 0.0595487007636639\n",
      "skipgram_300_dense: listen, listening, look, looking: 0.0406596642434014\n",
      "\n",
      "cbow_50: swim, swimming, sit, sitting: 0.48978575850663114\n",
      "cbow_150: swim, swimming, sit, sitting: 0.22129192423968272\n",
      "cbow_300: swim, swimming, sit, sitting: 0.04745686624994828\n",
      "cbow_50_dense: swim, swimming, sit, sitting: 0.021958860917220397\n",
      "cbow_150_dense: swim, swimming, sit, sitting: 0.17068327726846955\n",
      "cbow_300_dense: swim, swimming, sit, sitting: 0.03918166245483594\n",
      "skipgram_50: swim, swimming, sit, sitting: 0.2045576159267067\n",
      "skipgram_150: swim, swimming, sit, sitting: 0.02695449005542896\n",
      "skipgram_300: swim, swimming, sit, sitting: 0.0759698816019391\n",
      "skipgram_50_dense: swim, swimming, sit, sitting: 0.03028533116032402\n",
      "skipgram_150_dense: swim, swimming, sit, sitting: 0.05055787779525484\n",
      "skipgram_300_dense: swim, swimming, sit, sitting: 0.03563140413128219\n",
      "\n",
      "cbow_50: run, running, listen, listening: 0.7591559036884049\n",
      "cbow_150: run, running, listen, listening: 0.500506534222073\n",
      "cbow_300: run, running, listen, listening: 0.2172115315370583\n",
      "cbow_50_dense: run, running, listen, listening: 0.1839417128743973\n",
      "cbow_150_dense: run, running, listen, listening: 0.22631221236606874\n",
      "cbow_300_dense: run, running, listen, listening: 0.16730155288174092\n",
      "skipgram_50: run, running, listen, listening: 0.008977071763193276\n",
      "skipgram_150: run, running, listen, listening: 0.06712680136774937\n",
      "skipgram_300: run, running, listen, listening: 0.05989072385340193\n",
      "skipgram_50_dense: run, running, listen, listening: 0.0398748541017174\n",
      "skipgram_150_dense: run, running, listen, listening: 0.012654900797069137\n",
      "skipgram_300_dense: run, running, listen, listening: 0.052294495200113054\n",
      "\n",
      "cbow_50: think, thinking, read, reading: 0.2990498498151042\n",
      "cbow_150: think, thinking, read, reading: 0.2330940450897781\n",
      "cbow_300: think, thinking, read, reading: 0.16911559484697625\n",
      "cbow_50_dense: think, thinking, read, reading: 0.3787095492702201\n",
      "cbow_150_dense: think, thinking, read, reading: 0.3078049519115134\n",
      "cbow_300_dense: think, thinking, read, reading: 0.08962903058811725\n",
      "skipgram_50: think, thinking, read, reading: 0.06297131665063069\n",
      "skipgram_150: think, thinking, read, reading: 0.0061040761486036025\n",
      "skipgram_300: think, thinking, read, reading: 0.022228808308668864\n",
      "skipgram_50_dense: think, thinking, read, reading: 0.126542806632079\n",
      "skipgram_150_dense: think, thinking, read, reading: 0.0181158051746606\n",
      "skipgram_300_dense: think, thinking, read, reading: 0.03892256124563785\n",
      "\n",
      "cbow_50: up, down, close, far: 0.36010716857066855\n",
      "cbow_150: up, down, close, far: 0.36598875609203435\n",
      "cbow_300: up, down, close, far: 0.21333871878277946\n",
      "cbow_50_dense: up, down, close, far: 0.19196383523652996\n",
      "cbow_150_dense: up, down, close, far: 0.009307886939470968\n",
      "cbow_300_dense: up, down, close, far: 0.007063529840594001\n",
      "skipgram_50: up, down, close, far: 0.006113836150702873\n",
      "skipgram_150: up, down, close, far: 0.16539584160054252\n",
      "skipgram_300: up, down, close, far: 0.1783465178663802\n",
      "skipgram_50_dense: up, down, close, far: 0.04473971846960458\n",
      "skipgram_150_dense: up, down, close, far: 0.14023607002769808\n",
      "skipgram_300_dense: up, down, close, far: 0.018702310370623847\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#w2v and glove analogy performance\n",
    "cbow50analogylist=[]\n",
    "cbow50denseanalogylist=[]\n",
    "cbow150analogylist=[]\n",
    "cbow150denseanalogylist=[]\n",
    "cbow300analogylist=[]\n",
    "cbow300denseanalogylist=[]\n",
    "skipgram50analogylist=[]\n",
    "skipgram50denseanalogylist=[]\n",
    "skipgram150analogylist=[]\n",
    "skipgram150denseanalogylist=[]\n",
    "skipgram300analogylist=[]\n",
    "skipgram300denseanalogylist=[]\n",
    "co_occurrencelist=[]\n",
    "\n",
    "\n",
    "for analogy in analogy_list:\n",
    "    if(analogy[0] in tokenizer.word_index and analogy[1] in tokenizer.word_index and analogy[2] in tokenizer.word_index and analogy[3] in tokenizer.word_index):\n",
    "        try:\n",
    "            co_occurrenceanalogy=analogy_check(analogy,tf_cooc, tokenizer.word_index )\n",
    "            cbow50analogy=analogy_check(analogy,embed_cbow_50, tokenizer.word_index )\n",
    "            cbow150analogy=analogy_check(analogy,embed_cbow_150, tokenizer.word_index )\n",
    "            cbow300analogy=analogy_check(analogy,embed_cbow_300, tokenizer.word_index )\n",
    "            cbow50denseanalogy=analogy_check(analogy,embed_cbow_50_dense, tokenizer.word_index )\n",
    "            cbow150denseanalogy=analogy_check(analogy,embed_cbow_150_dense, tokenizer.word_index )\n",
    "            cbow300denseanalogy=analogy_check(analogy,embed_cbow_300_dense, tokenizer.word_index )\n",
    "            skipgram50analogy=analogy_check(analogy,embed_skipgram_50, tokenizer.word_index )\n",
    "            skipgram150analogy=analogy_check(analogy,embed_skipgram_150, tokenizer.word_index )\n",
    "            skipgram300analogy=analogy_check(analogy,embed_skipgram_300, tokenizer.word_index )\n",
    "            skipgram50denseanalogy=analogy_check(analogy,embed_skipgram_50_dense, tokenizer.word_index )\n",
    "            skipgram150denseanalogy=analogy_check(analogy,embed_skipgram_150_dense, tokenizer.word_index )\n",
    "            skipgram300denseanalogy=analogy_check(analogy,embed_skipgram_300_dense, tokenizer.word_index )\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(\"cbow_50: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow50analogy))\n",
    "            print(\"cbow_150: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow150analogy))\n",
    "            print(\"cbow_300: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow300analogy))\n",
    "            print(\"cbow_50_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow50denseanalogy))\n",
    "            print(\"cbow_150_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow150denseanalogy))\n",
    "            print(\"cbow_300_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow300denseanalogy))\n",
    "            print(\"skipgram_50: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram50analogy))\n",
    "            print(\"skipgram_150: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram150analogy))\n",
    "            print(\"skipgram_300: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram300analogy))\n",
    "            print(\"skipgram_50_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram50denseanalogy))\n",
    "            print(\"skipgram_150_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram150denseanalogy))\n",
    "            print(\"skipgram_300_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram300denseanalogy))\n",
    "            \n",
    "            \n",
    "            co_occurrencelist.append(co_occurrence)\n",
    "            cbow50analogylist.append(cbow50analogy)\n",
    "            cbow150analogylist.append(cbow150analogy)\n",
    "            cbow300analogylist.append(cbow300analogy)\n",
    "            cbow50denseanalogylist.append(cbow50denseanalogy)\n",
    "            cbow150denseanalogylist.append(cbow150denseanalogy)\n",
    "            cbow300denseanalogylist.append(cbow300denseanalogy)\n",
    "            skipgram50analogylist.append(skipgram50analogy)\n",
    "            skipgram150analogylist.append(skipgram150analogy)\n",
    "            skipgram300analogylist.append(skipgram300analogy)\n",
    "            skipgram50denseanalogylist.append(skipgram50denseanalogy)\n",
    "            skipgram150denseanalogylist.append(skipgram150denseanalogy)\n",
    "            skipgram300denseanalogylist.append(skipgram300denseanalogy)\n",
    "            \n",
    "            \n",
    "            print()\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization results trained word embeddings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def draw_word_vecs(X,strings):\n",
    "    col = ['r','b','g','y']\n",
    "    if len(X)!= len(strings):\n",
    "        print(\"mismatch in lengths between labels and vectors\")\n",
    "        \n",
    "    X_embedded = TSNE(n_components=4,method='exact').fit_transform(X)\n",
    "    maxt = np.amax(X_embedded)\n",
    "    mint = np.amin(X_embedded)\n",
    "    #print(maxt,mint)\n",
    "    maxt = max(maxt,mint*-1)\n",
    "    for i in range(len(X_embedded)):\n",
    "        plt.quiver(X_embedded[i][0]/maxt,X_embedded[i][1]/maxt,X_embedded[i][2]/maxt,X_embedded[i][3]/maxt,angles='xy', scale_units='xy',color=col[i], scale=1,label=strings[i])\n",
    "        #for val in X_embedded[i]:\n",
    "            #print(val/maxt)\n",
    "    #print(X_embedded)\n",
    "    plt.ylim(-1.2,1.2)\n",
    "    plt.xlim(-1.2,1.2)\n",
    "    plt.legend(strings)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEICAYAAAC3Y/QeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3Xl4VOXd//H3NwkhLGGNrAEDmioQEDEi7jwqCq0oCshiVRQXFIva1hYf+4NqtdrSVmoftUXFXcEHsfCIiisqVpQAkR0TkCWAAmEnBhJy//44ExhJgEAmc2b5vK5rrtxnzpk530ySz5zc58x9m3MOERGJLwl+FyAiIuGn8BcRiUMKfxGROKTwFxGJQwp/EZE4pPAXEYlDCn+JK2Y2zMxm+12HiN8U/iI1zMyeN7N9ZrY76JYYtP5iM1tuZkVm9rGZnehnvRIfFP4i4fFn51z9oNt+ADNLA6YC/w9oAuQAk32sU+KEwl9ikpm1MbOpZrbZzArN7H9+vNr+YWY7AkfcFwetaGVm081sq5nlm9ktgftTzOyHQFhjZr8zs1IzaxBYfsjMxh9HqVcDS5xz/+ucKwZ+D5xmZqce7/cuUhUKf4k5gS6Vt4A1QAbQGpgUtMlZwCogDRgLTDWzJoF1rwEFQCtgAPBHM7s4EMxzgQsD210QeP5zg5Y/OUJZdwTeUOaZWf+g+zsBX5cvOOf2ACsD94vUGIW/xKLueOF9r3Nuj3Ou2DkXfJJ3EzDeOVfinJsMrAB+ZmZtgPOA3wYekws8A1wXeNwnwIVmlgR0AR4PLKcAZwKfHaaex4FMoBle987zZlb+plEf2HHI9juA1OP95kWqQuEvsagNsMY5V3qY9evdj0c0XIP3ZtEK2Oqc23XIutaB9idAT6AbsAh4H+8/gR5AvnNuS2U7c87Nd84VOudKnXNvA6/gdfcA7AYaHPKQBsAuRGqQwl9i0TqgbeAIvTKtzcyCltsCGwK3JmaWesi69YH2f4BTgKuAT5xzSwPrf8aRu3wO5YDy/S8BTitfYWb1gJMC94vUGIW/xKKvgI3Ao2ZWL3Cy9tyg9c2AUWZWy8wGAh2At51z6/AC/pHAY7oAw/GO1HHOFQHzgJEcDPv/ALdxhPA3swFmVt/MEszsUuDnwPTA6jeBLDPrH+g+GgMsdM4tD8ULIXI4Cn+JOYHLKPsCJwNr8U7gDgra5Eu8PvgtwMPAAOdcYWDdELyTxBvwgnmsc+79oMd+AtTCe4MpX04FPj1CSXfh/fewHRgH3OKcmxWodTPQP1DHNryT0YOP8VsWOWamyVxEROKPjvxFROKQwl9EJA4p/EVE4pDCX0QkDh3uOmjfpaWluYyMDL/LEBGJKvPmzdvinDvhaNtFbPhnZGSQk5PjdxkiIlHFzNZUZTt1+4iIxCGFv4hIHFL4i4jEoYjt8xeR+FBSUkJBQQHFxcV+lxJVUlJSSE9Pp1atWsf1eIW/iPiqoKCA1NRUMjIy+PFgq3I4zjkKCwspKCigXbt2x/Uc6vYREV8VFxfTtGlTBf8xMDOaNm1arf+WFP4i4jsF/7Gr7mum8BcRiUPq8xeRyBLq/wI0bH2ldOQvIhLEOUdZWZnfZdQ4hb+IxL3Vq1fToUMH7rjjDrp160ZiYuKBdVOmTGHYsGEADBs2jFGjRnHOOefQvn17pkyZ4lPF1afwFxEBVqxYwfXXX8+CBQuoV6/eYbfbuHEjs2fP5q233mL06NFhrDC0FP4iIsCJJ55Ijx49jrpdv379SEhIoGPHjnz//fdhqKxmhCT8zWyimW0ys8WHWW9m9riZ5ZvZQjPrFor9ioiESvDRfvBllIdeS1+7du0D7WieAz1UR/7PA72PsL4PkBm43Qo8FaL9ioiEXPPmzVm2bBllZWW8+eabfpdTI0Jyqadz7lMzyzjCJlcCLzrvbXKOmTUys5bOuY2h2L+IxJAIOJp+9NFHufzyy2nTpg1ZWVns3r3b75JCLlzX+bcG1gUtFwTu+1H4m9mteP8Z0LZt2zCVJiLxLiMjg8WLD/ZaDxgwgAEDBlTY7vnnn//RcjS/KYTrhG9ln9qo8PbunJvgnMt2zmWfcMJRZyETEZHjFK7wLwDaBC2nAxvCtG8RETlEuMJ/OnB94KqfHsAO9feLiPgnJH3+ZvYa0BNIM7MCYCxQC8A590/gbeCnQD5QBNwYiv2KiMjxCdXVPkOOst4BI0OxLxERqT59wldEJA4p/EUkopiF9ua3m2++maVLl/pdRgUaz19EJIhzDuccCQmhOTZ+5plnQvI8oaYjfxGJe9Ud0nnWrFn07NmTAQMGcOqpp3LttdceGPenZ8+e5OTkAFC/fn3uv/9+TjvtNHr06HFgYLiVK1fSo0cPzjzzTMaMGUP9+vVr/HtW+IuIUP0hnRcsWMD48eNZunQpq1at4vPPP6/w2D179tCjRw++/vprLrjgAp5++mkA7rrrLu666y7mzp1Lq1atQv/NVULhLyJC9Yd07t69O+np6SQkJNC1a1dWr15d4bHJyclcfvnlAJxxxhkHtvniiy8YOHAgAEOHDq3+N1MFCn8REao/pHPw/YmJiZSWllbYR61atQ489+G2CReFv4jIIcI9pHOPHj144403AJg0aVKN7w8U/iISYZwL7e14lA/pfNFFF9GyZcvQfoOVGD9+PH/729/o3r07GzdupGHDhjW+T4vUmWiys7Nd+RlyEYldy5Yto0OHDn6X4auioiLq1KmDmTFp0iRee+01pk2bdtTHVfbamdk851z20R6r6/xFRHw2b9487rzzTpxzNGrUiIkTJ9b4PhX+IiI+O//88/n666/Duk/1+YuIxCGFv4hIHFL4i4jEIYW/iEgc0glfEYko9kBox2F2Y49+OXv9+vXZvXs3GzZsYNSoUQcGbDvU9u3befXVV7njjjtCWqMfdOQvIhLQqlWrwwY/eOH/5JNPhrGimqPwFxEJWL16NVlZWQAsWbKE7t2707VrV7p06UJeXh6jR49m5cqVdO3alXvvvReAcePGceaZZ9KlSxfGjh174Hk6dOjALbfcQqdOnbj00kv54YcffPu+KqPwFxGpxD//+U/uuusucnNzycnJIT09nUcffZSTTjqJ3Nxcxo0bx3vvvUdeXh5fffUVubm5zJs3j08//RSAvLw8Ro4cyZIlS2jUqNGBsXsihfr8RUQqcfbZZ/Pwww9TUFDA1VdfTWZmZoVt3nvvPd577z1OP/10AHbv3k1eXh5t27alXbt2dO3aFfjx8M2RQkf+InJM5syBPXv8rqLmDR06lOnTp1OnTh0uu+wyPvroowrbOOe47777yM3NJTc3l/z8fIYPHw5UbYhnPyn8RaTKdu6EoUMhKNdi1qpVq2jfvj2jRo3iiiuuYOHChaSmprJr164D21x22WVMnDiR3bt3A7B+/Xo2bdrkV8nHRN0+IlJlI0fC+vWQVIPJUZVLM8Nh8uTJvPzyy9SqVYsWLVowZswYmjRpwrnnnktWVhZ9+vRh3LhxLFu2jLPPPhvwLhl9+eWXfzQHcKTSkM4iUiWvvAI//zk0agTbtoXueTWk8/GrzpDO6vYRkaP69lu4/XavXbeuv7VIaCj8ReSISkvh2muhvKtb4R8bFP4ickR/+AN88cXBZYV/bFD4i8hhffYZPPTQj+9T+McGhb+IVGr7du8Eb1nZj+9X+McGhb+IVOAcjBgBa9dWXKfwjw26zl9EKsjJgVq1YMwY+PvfYceOg+tqOvxnzQrtkM49e0bWkM5jxozhggsu4JJLLjnu5wgFHfmLSAVnngkvvQSDBh0M/oEDoWHD2D7yD8eQzg8++KDvwQ8KfxE5gsmTD7b/8AeYORNatPCvnpoWjiGdhw0bduANJiMjg7Fjx9KtWzc6d+7M8uXLAdi8eTO9evWiW7du3HbbbZx44ols2bIlpN+rwl9EKuUcTJrktbt2hVNOgbPOgt//3teywiZcQzqnpaUxf/58br/9dv7yl78A8MADD3DRRRcxf/58rrrqKtZWdvKlmtTnLyKVys2Fb77x2oMHH7w/HgZ1g/AN6Xz11Vcf2Gbq1KkAzJ49mzfffBOA3r1707hx41B/ezryF5HKBXf5DBrkXx1+CdeQzuXbBW8TjjHXQhL+ZtbbzFaYWb6Zja5k/TAz22xmuYHbzaHYr4jUjOAunx49ICPD13J84eeQzueddx6vv/464P13sS2UI+kFVLvbx8wSgSeAXkABMNfMpjvnlh6y6WTn3J3V3Z+I1Lwvv4Q1a7x2uI/6q3JpZjj4OaTz2LFjGTJkCJMnT+bCCy+kZcuWpKamhuLbOqDaQzqb2dnA751zlwWW7wNwzj0StM0wIPtYwl9DOov45+67vev7zWDdOmjduub2pSGdK9q7dy+JiYkkJSXxxRdfcPvtt5Obm1thu+oM6RyKE76tgXVBywXAWZVs19/MLgC+Ae5xzq07dAMzuxW4FaBt27YhKE1EjtX+/RDoceCCC2o2+KVya9eu5ZprrqGsrIzk5GSefvrpkO8jFOFf2cfxDv134v+A15xze81sBPACcFGFBzk3AZgA3pF/CGoTkWM0ezZs3Oi1g6/ykfDJzMxkwYIFNbqPUJzwLQDaBC2nAxuCN3DOFTrn9gYWnwbOCMF+RaQGlJ/oTUyE/v3Ds89InVEwklX3NQtF+M8FMs2snZklA4OB6cEbmFnLoMUrgGUh2K+IhFhJCZSPbnDxxXDCCTW/z5SUFAoLC/UGcAyccxQWFpKSknLcz1Htbh/nXKmZ3QnMBBKBic65JWb2IJDjnJsOjDKzK4BSYCswrLr7FZHQ++gjKB9FIFxdPunp6RQUFLB58+bw7DBGpKSkkJ6eftyP1wTuInLAjTfC8897I3pu2uRN1i7RRRO4i8gx2bsXAiMK0KePgj/WKfxFBPBG7CwfvllX+cQ+hb+IAAev8qlTB/r29bcWqXkKfxFhzx6YNs1rX3451K/vbz1S8xT+IsKMGVBU5LXV5RMfFP4icmD45tRU72SvxD6Fv0ic27nTO/IH6NfP6/OX2Kfwl7hVVFLkdwkRYdo07zJPiM9JW+KVwl/i0qptq+j8VGcmzJvgdym+K7/Kp3Fj6NXL31okfBT+EneWbl7Khc+dx6ptqxjx1gi+LPjS75J8U1gI773ntfv3h+Rkf+uR8NEE7hJXcjbk0Pvl3vRrXkhOAlza6dd0b93d77J88+abUD61rK7yiS8Kf4kbn6z+hL6v9WXXvl38pxCe7AbNm2+mpKSQ5OQ0v8vzRXmXT7NmcOGF/tYi4aVuH4kLM76ZQe9XerNrnzf59sjz/oeGDc/n+++f56uvTmXjxufibkjh776Djz/22gMHQpIOBeOKwl9i3qTFk+g3uR/FpcUkWiIv9nuRkd1H0qbNbwAoLS1kxYqbyM3tyZ498TPVxJQpUFbmtdXlE38U/hLTJsybwNA3hlJaVkpyYjJTrpnCdaddB0DTpj+lbt2Dk1/v2PEpOTmnsWrV79i//we/Sg6b8i6f9HQ45xx/a5HwU/hLzBr3+Thue+s2HI56teoxY+gM+p3a78B6swTatLn3R49xroS1ax9m7tzObN36XrhLDpt16+Dzz732oEGQoCSIO/qRS8xxzvG7j37Hbz7wunUapTTi/eve55L2l1TYtnnzoSQnt6pwf3HxShYuvIy8vFE4t7/Gaw63118/2NYHu+KTwl9iSpkr4xfv/IKHP3sYgGb1mjHrhlmc3ebsSrdPSKhNevrdFe5PTT2LM86Yz8knj8cssUZr9kN5l0/79pB91DmfJBYp/CVmlJaVMuzfw3hi7hMAtG3Yltk3zua0Fqcd8XGtWt1KYmKDH923a9eXFBWtwCz2/kTy86F8htTBg8HM33rEH7H3my1xqbi0mIH/O5CXFr4EwE+a/oTZN84ms2nmUR+blNSQVq1GANCq1UgSE1MBWL78BrZtm1VjNfulfARP0FU+8UzhL1Fv977dXP7q5fx7+b8B6NqiK5/d+BltGrap8nOkp99FUlIT2rd/hE6dpmKWhHP7WLy4H3v2LKmp0n1RHv4dO0JWlr+1iH8U/hLVtv6wlV4v9eLDbz8E4Jw25/DxDR/TrF6zY3qe2rVbkZX1b5KSUmnS5BJOOWUiAPv372Dhwj7s3bs+5LX7YckSWLTIaw8apC6feKbwl6j13e7v6Pl8T+YUzAHg0pMu5b2fv0ejlEbH9XyNGp1/oN2ixXW0a+edNN67dx0LF/6U0tKd1S/aZ8FdPrrKJ74p/CUqrdm+hvOfO59Fm7zD2P4d+jN98HTqJdcL2T7atr2Pli1vA2DPnoUsWdKfsrJ9IXv+cHPu4FU+p58Op5zibz3iL4W/RJ3lW5Zz3nPnkb81H4BhXYcxacAkaifVDul+zIzMzP+hadPLAdi27QNWrLg5ascAWrAA8vK8tk70isJfosqCjQu44LkLKNhZAMCo7qN49opnSUqomVHJEhKS6NhxEqmpZwLw/fcv8e23/69G9lXTgrt8rrnGvzokMij8JWp8vvZz/uuF/2Jz0WYAxl44lvG9x5NQw9fiJybWo3Pnt0hJaQ/A2rUPs2HDv2p0n6EW3OXTowdkZPhajkQAhb9EhZn5M+n1Ui927N0BwN8u/Ru/7/l7LEyXqyQnN6NLl3dJSmoKwDff3MGWLW+FZd+hMGcOrF3rtdXlI6DwlyjwxtI36PtaX34o/YEES+CZvs9wz9n3hL2OunUz6dz5LRISUoAyli4dxM6dX4W9juNRftRv5o3dL6Lwl4j23ILnuGbKNZSUlVAroRaT+k9ieLfhvtXTsGEPOnacBCRQVlbEokWXU1SU71s9VbF//8GB3C68EFpVHMdO4pDCXyLG9uLtP1r++5y/c9P0myhzZdRJqsP0IdMZ2Mn/w9a0tCvJzHwcgJKSzSxa1Id9+zb7XNXhffaZN2sXqMtHDlL4S0RwzjHkjSHsKN6Bc44HZj3A3TO90TYb1G7AzJ/PpPfJvX2u8qDWrUfSps1vAfjhh3wWLerL/v1FPldVufIun8RE6N/f31okcmjWTokI01ZM4938d3k3/13mFMxh/JfjAUirm8bMn8+kW8tuPldYUfv2f2Tv3nVs2vQqu3Z9ydKlQ8jKmhpRQ0CXlHjTNQJccgmkxec89VIJhb/4rri0mF/O/CUAI2aMOND90zq1Ne9f9z4dTuhwpIf7xiyBU0+dyL59G9m+/WMKC6eTl/cLMjOfCNtVSEfz4YdQWOi11eUjwdTtI7577IvH+Hb7t8DBfv+TGp/E7JtmR2zwl0tIqE2nTlOpV88bHnPDhqdYt+7PPld1UHmXT3Iy9Ot35G0lvij8xVfrd64/MOtWsLq16vJ23tsUFhX6UNWxqVWrEZ07v01ycmsAVq0azfffv+JzVbB3L7z5ptfu3RsaHd94dxKjQhL+ZtbbzFaYWb6Zja5kfW0zmxxY/6WZZYRivxL97vvwPvaU7Klw/6JNi/hnzj/5fN3nPlR17FJS2tClyzsHZgRbvvxGtm37yNea3n0XdgYGIlWXjxyq2uFv3tmtJ4A+QEdgiJl1PGSz4cA259zJwGPAn6q7X4l+cwrmHJh5K1jnZp2ZMnAKuSNyueKUK3yo7PjUr9+ZrKw3MauFcyUsXnwVu3cv8q2e5cu9K3zq1IG+fX0rQyJUKI78uwP5zrlVzrl9wCTgykO2uRJ4IdCeAlxskXJGTKrmq6+8TuPi4pA8XZkrY9Q7o350X5fmXXjjmjfIHZFL/479a3zMnprQuPFFnHrqcwDs37+ThQv7UFxc4Estv/2td33/tGlQv74vJUgEC8VfV2tgXdByQeC+SrdxzpUCO4Cmhz6Rmd1qZjlmlrN5c+R+aCbufPopnHeelyK//GVInvKlr19i7oa5gBf6U6+ZyoLbFnB1h6ujMvSDNW9+Le3aPQLAvn3rWbSoD6WlO3ypJS0NevXyZdcS4ULxV1bZEfyhA55XZRuccxOcc9nOuewTTjghBKVJSPTo4c3+AfDUUwfHCjhOu/buYvSHozmt+WkHQv+qDldFfegHa9v2t7RqdTsAe/YsZvHiq6J6IhiJPaH4aysAgmfKTgc2HG4bM0sCGgJbQ7BvCYfkZG8w+PLLRW6+GVauPO6nm5E3g6d+9hTzb5sfc6FfzpsI5h80beqds9i+/WOWL78J58p8rkzEE4q/urlAppm1M7NkYDAw/ZBtpgM3BNoDgI9ctE6HFK8yMuA5ry+bXbu82UD27j2upxqcNZh+p/aLydAPZpZIx46vkZp6FgCbNr3Ct9/e73NVIp5q//UF+vDvBGYCy4DXnXNLzOxBMyu/VONZoKmZ5QO/BCpcDipRoF8/GBU4STt/Ptx7r7/1RIHExLp07vx/1KlzMgBr1z7K+vVP+lyVCFikHoBnZ2e7nJwcv8uQQ+3dC+eeC/PmectvvAFXX+1vTVGgqCifBQvOpqRkC5BAVtZU0tIOvShOpPrMbJ5zLvto28X2/90SerVreyd8G3gfZuKmm2DVKn9rigJ1654cmAimDt5EMIPZseMLv8uSOKbwl2PXvj08+6zX3rHD+/joPl3JcjQNGpwVNBFMMYsW9aWo6Bu/y5I4pfCX4zNgANxxh9eeO9f7RJEcVVraFWRmPgFAaWkhCxf2Yd++TT5XJfFI4S/H769/ha5dvfb48d6HwOSoWrceQdu29wFQXLyKRYsuZ//+iuMbidQkhb8cv5QUr/+/fOyAYcNgzRpfS4oW7do9TPPmPwdg1665LF06mLKyUp+rknii8JfqycyEp5/22tu3e/3/JSX+1hQFzIxTTnmWRo0uBqCw8C3y8kYSqVffSexR+Ev1DR4Mt93mtefMgf/+b3/riRIJCclkZb1BvXpdANi4cQJr1z7ic1USLxT+EhqPPQZdvBDjL3+BGTP8rSdKJCU1pEuXt6ldOx2Ab7+9n+++e9HnqiQeKPwlNOrU8fr/69Xzlq+/HtatO/JjBIDatVvTufM7JCY2BGDFiuFs3fq+z1VJrFP4S+iccgr8619ee+tWGDJE/f9VVL9+FllZ/8YsGedKWbKkP7t3f+13WRLDFP4SWtdeC8OHe+3PP4cxY/ytJ4o0btyTU099HoD9+3excOFPKS5e629RErMU/hJ6jz8OWVle+9FHvclkpUqaNx9C+/Z/BmDfvg0sXNiHkpJtPlclsUjhL6FXt67X/1+3rrd83XWwfr2/NUWRNm1+TevWdwJQVLQ0MBHM8Q2fLXI4Cn+pGR06wJOBoYu3bIGhQ6FUH2KqCjPj5JPHk5bWD4AdOz5h+fJhmghGQkrhLzXnhhu8G3jzAD/wgL/1RBGzRDp0eJUGDc4GYNOmSaxapfGTJHQU/lKznnjC+y8A4OGH4YMP/K0niiQm1iErazp16mQCsG7dXygoeNznqiRWKPylZtWr5/X/16kDznlXA23c6HdVUSM5OY0uXd6lVq1mAOTn383mzVN9rkpigcJfal5WFvzjH1570ybvDWD/fn9riiJ16rQPTARTF3AsW3YtO3Z87ndZEuUU/hIeN93khT7Axx/DQw/5W0+UadDgTDp1ep2DE8FcQVHRCr/Lkiim8JfwMIOnnoKf/MRbfuAB701Aqqxp05/xk588BUBp6VYWLuzN3r3f+VyVRCuFv4RPaqrX/1+7ttf/P3QofP+931VFlVatbuXEE38HQHHxahYtupzS0t0+VyXRSOEv4XXaafD3v3vt777zPgBWpuvXj0VGxoM0b349ALt3z2Pp0ms0EYwcM4W/hN+tt8KgQV77/ffhEY1hfyy8iWCepnHjXgBs3foOeXm3ayIYOSYKfwk/M5gwAU4+2VseM8b7EJhUWUJCMp06TaFevdMA2LjxGdas0Ul0qTqFv/ijQQOv/z852ev2GTIENm/2u6qokpTUIDARTBsAVq8ew3ffveBzVRItFP7in9NPh7/9zWtv2OBNAKP+/2NSu3YrunR5h6SkRiQntzgwJaTI0Sj8xV933AEDBnjtd9+FceP8rScK1avXic6dZ9Ct2xxSU0/3uxyJEgp/8ZcZPPMMtGvnLd9/vzcJjByThg3PISXlRL/LkCii8Bf/NWzo9f/XquUN+zB4MBQW+l2VSExT+EtkyM4+2OVTUADDhnkfBBORGqHwl8gxahT08yYw4a23Dp4MFpGQU/hL5DCDiRMhI8NbHj0a5szxtSSRWKXwl8jSuDFMmgRJSd60j4MGwdatflclEnMU/hJ5zjoL/vQnr712Ldx4o/r/RUJM4S+R6Z57oG9frz19+sHB4EQkJBT+EpnM4PnnoY03dAG/+Q3MnetrSSKxpFrhb2ZNzOx9M8sLfG18mO32m1lu4Da9OvuUONKkidf/n5gIJSVwzTWwfbvfVYnEhOoe+Y8GPnTOZQIfBpYr84NzrmvgdkU19ynx5Jxz4I9/9NqrV8Pw4er/FwmB6ob/lUD5MIIvAP2q+XwiFf3619Cnj9eeOhWeeMLfekRiQHXDv7lzbiNA4Guzw2yXYmY5ZjbHzA77BmFmtwa2y9ms4X2lXEICvPgitG7tLf/qVzB/vr81iUS5o4a/mX1gZosruV15DPtp65zLBoYC483spMo2cs5NcM5lO+eyTzjhhGN4eol5aWnw2mte//++fV7//86dflclErWOGv7OuUucc1mV3KYB35tZS4DA102HeY4Nga+rgFmAxp2VY3f++fDgg1575Uq45Rb1/4scp+p2+0wHbgi0bwCmHbqBmTU2s9qBdhpwLrC0mvuVeDV6NFx6qdd+/XX417/8rUckSlU3/B8FeplZHtArsIyZZZvZM4FtOgA5ZvY18DHwqHNO4S/HJyEBXnoJWrb0lu++G3Jz/a1JJAqZi9B/m7Ozs11OTo7fZUikmjULLr7Ym/YxMxPmzYPUVL+rEvGdmc0LnGM9In3CV6JTz54wdqzXzsuDESPU/y9yDBT+Er3uvx8uushrv/oqPPusv/WIRBGFv0SvxER45RVo3txb/sUvYNEif2sSiRIKf4luLVp4bwBmUFzsXf+/e7ffVYlEPIW/RL+LL4bf/c5rL18OI0f6W49IFFD4S2wYOxYuvNBrv/iiNxy0iByWwl9iQ2Kid9K3fFiQkSNhqT5OInI4Cn+JHa1aeR8AAygq8vr/i4r8rUkkQin8JbZKVHgHAAAHoUlEQVRcdhncd5/XXrLEuwJIRCpQ+EvsefBBOO88rz1xIrz8sr/1iEQghb/EnqQkb/jnpk295REjvKuAROQAhb/EpvT0g/3/e/Z4/f8//OBvTSIRROEvsatPH/jNb7z2okXeCKAiAij8JdY99JA3CTzAhAkwaZK/9YhECIW/xLZatbz+/8aNveVbbvFGARWJcwp/iX1t28ILL3jt3bu9/v/iYn9rEvGZwl/iQ9++8Mtfeu3cXPjVr/ytR8RnCn+JH488At27e+0nn4QpU/ytR8RHCn+JH8nJMHkyNGrkLQ8fDitX+luTiE8U/hJfMjLguee89s6dXv//3r2+liTiB4W/xJ9+/WDUKK89fz7ce6+/9Yj4QOEv8enPf4YzzvDa//gHTJ3qbz0iYabwl/hUuza8/jo0aOAt33QTfPutvzWJhJHCX+JX+/bw7LNee8cOGDQI9u3ztyaRMFH4S3wbMADuuMNrz50Lo0f7W49ImCj8Rf76V+ja1Ws/9hhMn+5vPSJhoPAXSUnx+v/r1/eWhw2DNWt8LUmkpin8RQAyM+Hpp732tm0weDCUlHjLr7ziX10iNUThL1Ju8GC49VavPWcO3H8/rFvnXQmUn+9vbSIhpvAXCTZ+PHTp4rXHjYOBA70rgDQPsMQYhb9IsDp1vP7/evW85S+/9L6+9BI4519dIiGm8Bcpt2UL3HMP3H57xaBftQr+8x9/6hKpAQp/kXJpaXDppd58v0VFFdeXTwgvEgMU/iLB+vTxJnu54IKK6yZP1gxgEjMU/iKHat0aPvwQxowBs4P3b98OM2b4V5dICCn8RSqTlAQPPAAffAAtWhy8/8UX/atJJIQU/iJHctFF8PXX3rkAgLff9k4Mi0S5aoW/mQ00syVmVmZm2UfYrreZrTCzfDPTyFkSXZo1g3fe8eYAds7r+xeJctU98l8MXA18ergNzCwReALoA3QEhphZx2ruVyS8EhK8ET8/+QRmzfK7GpFqS6rOg51zywAs+KRYRd2BfOfcqsC2k4ArgaXV2beIL849Fzp0gNJS77yASJQKR59/a2Bd0HJB4L4KzOxWM8sxs5zNmzeHoTSR49CkiYJfot5Rf4PN7AOgRSWr7nfOTavCPir7t6DSz8k75yYAEwCys7P1WXoRkRpy1PB3zl1SzX0UAG2CltOBDdV8ThERqYZwdPvMBTLNrJ2ZJQODAU2VJCLio+pe6nmVmRUAZwMzzGxm4P5WZvY2gHOuFLgTmAksA153zi2pXtkiIlId1b3a503gzUru3wD8NGj5beDt6uxLRERCR5/wFRGJQwp/EZE4pPAXEYlDCn8RkTik8BcRiUMKfxGROKTwFxGJQwp/EZE4pPAXEYlDCn8RkTik8BcRiUMKfxGROGTOReacKWa2GVgTxl2mAVvCuL9oodelcnpdKqfXpaJwvyYnOudOONpGERv+4WZmOc65bL/riDR6XSqn16Vyel0qitTXRN0+IiJxSOEvIhKHFP4HTfC7gAil16Vyel0qp9elooh8TdTnLyISh3TkLyIShxT+IiJxKG7D38wGmtkSMyszs8NehmVmvc1shZnlm9nocNboBzNrYmbvm1le4Gvjw2y338xyA7fp4a4zXI728zez2mY2ObD+SzPLCH+V4VWF12SYmW0O+v242Y86w83MJprZJjNbfJj1ZmaPB163hWbWLdw1Bovb8AcWA1cDnx5uAzNLBJ4A+gAdgSFm1jE85flmNPChcy4T+DCwXJkfnHNdA7crwlde+FTx5z8c2OacOxl4DPhTeKsMr2P4m5gc9PvxTFiL9M/zQO8jrO8DZAZutwJPhaGmw4rb8HfOLXPOrTjKZt2BfOfcKufcPmAScGXNV+erK4EXAu0XgH4+1uK3qvz8g1+vKcDFZmZhrDHc4vFvokqcc58CW4+wyZXAi84zB2hkZi3DU11FcRv+VdQaWBe0XBC4L5Y1d85tBAh8bXaY7VLMLMfM5phZrL5BVOXnf2Ab51wpsANoGpbq/FHVv4n+ga6NKWbWJjylRbyIypMkv3YcDmb2AdCiklX3O+emVeUpKrkv6q+NPdLrcgxP09Y5t8HM2gMfmdki59zK0FQYMary84/J35EjqMr3+3/Aa865vWY2Au8/o4tqvLLIF1G/KzEd/s65S6r5FAVA8FFLOrChms/puyO9Lmb2vZm1dM5tDPxLuukwz7Eh8HWVmc0CTgdiLfyr8vMv36bAzJKAhhz5X/9od9TXxDlXGLT4NDF+HuQYRFSeqNvnyOYCmWbWzsySgcFAzF7ZEjAduCHQvgGo8B+SmTU2s9qBdhpwLrA0bBWGT1V+/sGv1wDgIxfbn5w86mtySD/2FcCyMNYXyaYD1weu+ukB7CjvYvWFcy4ub8BVeO/Ee4HvgZmB+1sBbwdt91PgG7yj2vv9rjsMr0tTvKt88gJfmwTuzwaeCbTPARYBXwe+Dve77hp8PSr8/IEHgSsC7RTgf4F84Cugvd81R8Br8giwJPD78TFwqt81h+l1eQ3YCJQEsmU4MAIYEVhveFdKrQz83WT7Wa+GdxARiUPq9hERiUMKfxGROKTwFxGJQwp/EZE4pPAXEYlDCn8RkTik8BcRiUP/H5dpny5Kj3QUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24b0f12cba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run' 'running' 'listen' 'listening']\n"
     ]
    }
   ],
   "source": [
    "#cbow 50\n",
    "\n",
    "w2visualize=analogy_list[42]\n",
    "embedlist=[]\n",
    "for i in range(4):\n",
    "    #embedlist.append(word2vec[analogy_list[1][i]])\n",
    "    embedlist.append(embed_cbow_50[tokenizer.word_index[w2visualize[i]]-1])\n",
    "plt.title(\"cbow 50\")\n",
    "draw_word_vecs(embedlist,w2visualize)    \n",
    "print(w2visualize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We made a function analogy_check() for checking how similar a set of analogy is. For an analogy, we will have a set of embedding vector (v0, v1, v2, v3). The way we checked it by checking cosine_similarity of (v0+v1) and (v2+v3). If it is an analogy, then the cosine should be high because (v0+v1) and (v2+v3) should be closed (in terms of cosine angle) with each other.\n",
    "\n",
    "Overall, the performance is not satisfying. This could be caused by several factors: inadequate training sample, the world in analogy is not frequently appear, etc. Adding more dimension in embedding vector also doesn't prove to increase the similarity. Most of the analogy works better for n=50 compared to n=150 or 300. Adding dense layer also doens not prove to increase similarity. The extra training time for adding dense layer is not improving the similarity of an analogy (but there is few that improves such as (large, largest, good, best) on cbow_50 and cbow_50_dense)\n",
    "\n",
    "CBOW works better on frequent word. For example (eat, eats, find, finds) cbow_50 is better than skipgram_50. In alice.txt there are more than 100 occurance of 'eat' word. CBOW better in this case because context words are averaged before predicting the targeted word, and since it has more sample then it works better in this case. This means Skipgram is better on rare words.\n",
    "\n",
    "One of the highest one (run, running, listen, listening) by cbow with dim=50. As we can see in the picture above, the red and blue arrow are almost 90$0$ from each other and so does the green and yellow arrow. So when the cosine_similarity was used for the resultant of both vectors, then it should produce a close similarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5\n",
    "### Use the word co-occurence matrix from Question 1. Compare the performance on the analogy task with the performance of your trained word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "co-occurance: sudden, suddenly, usual, usually: 0.20341951009664783\n",
      "cbow_50: sudden, suddenly, usual, usually: 0.2145599465610109\n",
      "cbow_150: sudden, suddenly, usual, usually: 0.16464666681544313\n",
      "cbow_300: sudden, suddenly, usual, usually: 0.04262983580543956\n",
      "cbow_50_dense: sudden, suddenly, usual, usually: 0.024934976086477847\n",
      "cbow_150_dense: sudden, suddenly, usual, usually: 0.06584301080295592\n",
      "cbow_300_dense: sudden, suddenly, usual, usually: 0.057512587300851306\n",
      "skipgram_50: sudden, suddenly, usual, usually: 0.051247048932523284\n",
      "skipgram_150: sudden, suddenly, usual, usually: 0.11488630353144216\n",
      "skipgram_300: sudden, suddenly, usual, usually: 0.025398620492292738\n",
      "skipgram_50_dense: sudden, suddenly, usual, usually: 0.11550091531896342\n",
      "skipgram_150_dense: sudden, suddenly, usual, usually: 0.09122986493247628\n",
      "skipgram_300_dense: sudden, suddenly, usual, usually: 0.0379434827632857\n",
      "\n",
      "co-occurance: bad, worse, good, better: 0.340842718662506\n",
      "cbow_50: bad, worse, good, better: 0.007139452508570647\n",
      "cbow_150: bad, worse, good, better: 0.04960375886754415\n",
      "cbow_300: bad, worse, good, better: 0.08364212988123694\n",
      "cbow_50_dense: bad, worse, good, better: 0.026874943420956886\n",
      "cbow_150_dense: bad, worse, good, better: 0.12296815517749676\n",
      "cbow_300_dense: bad, worse, good, better: 0.022567480791767187\n",
      "skipgram_50: bad, worse, good, better: 0.14242828767090374\n",
      "skipgram_150: bad, worse, good, better: 0.06110748320636268\n",
      "skipgram_300: bad, worse, good, better: 0.014283902125049552\n",
      "skipgram_50_dense: bad, worse, good, better: 0.07730987059232503\n",
      "skipgram_150_dense: bad, worse, good, better: 0.11583589719793469\n",
      "skipgram_300_dense: bad, worse, good, better: 0.06542767465641082\n",
      "\n",
      "co-occurance: go, going, look, looking: 0.5257224725382912\n",
      "cbow_50: go, going, look, looking: 0.04482878540457188\n",
      "cbow_150: go, going, look, looking: 0.13521208123901596\n",
      "cbow_300: go, going, look, looking: 0.11739576262876612\n",
      "cbow_50_dense: go, going, look, looking: 0.2275989682841857\n",
      "cbow_150_dense: go, going, look, looking: 0.08095648478867602\n",
      "cbow_300_dense: go, going, look, looking: 0.014954370905789528\n",
      "skipgram_50: go, going, look, looking: 0.04897776970140745\n",
      "skipgram_150: go, going, look, looking: 0.3108869698881552\n",
      "skipgram_300: go, going, look, looking: 0.1897161720304399\n",
      "skipgram_50_dense: go, going, look, looking: 0.14061684371374158\n",
      "skipgram_150_dense: go, going, look, looking: 0.14720249473774485\n",
      "skipgram_300_dense: go, going, look, looking: 0.002864495321771528\n",
      "\n",
      "co-occurance: he, she, his, her: 0.7385962387549866\n",
      "cbow_50: he, she, his, her: 0.08099932963910215\n",
      "cbow_150: he, she, his, her: 0.03569783846020872\n",
      "cbow_300: he, she, his, her: 0.022474709476888687\n",
      "cbow_50_dense: he, she, his, her: 0.25305776920456663\n",
      "cbow_150_dense: he, she, his, her: 0.05257730241374489\n",
      "cbow_300_dense: he, she, his, her: 0.12253203367780965\n",
      "skipgram_50: he, she, his, her: 0.5350455025860693\n",
      "skipgram_150: he, she, his, her: 0.4214261528756635\n",
      "skipgram_300: he, she, his, her: 0.1928937824570437\n",
      "skipgram_50_dense: he, she, his, her: 0.2154861486119754\n",
      "skipgram_150_dense: he, she, his, her: 0.14655767256694316\n",
      "skipgram_300_dense: he, she, his, her: 0.1511302407262479\n",
      "\n",
      "co-occurance: brother, sister, his, her: 0.6112346949924595\n",
      "cbow_50: brother, sister, his, her: 0.3216747204943751\n",
      "cbow_150: brother, sister, his, her: 0.23105893917756617\n",
      "cbow_300: brother, sister, his, her: 0.07589060484117083\n",
      "cbow_50_dense: brother, sister, his, her: 0.08839213138780096\n",
      "cbow_150_dense: brother, sister, his, her: 0.03201457747498062\n",
      "cbow_300_dense: brother, sister, his, her: 0.010614877330893632\n",
      "skipgram_50: brother, sister, his, her: 0.08925583606036332\n",
      "skipgram_150: brother, sister, his, her: 0.11066786236035159\n",
      "skipgram_300: brother, sister, his, her: 0.15242621645498913\n",
      "skipgram_50_dense: brother, sister, his, her: 0.16731238470239565\n",
      "skipgram_150_dense: brother, sister, his, her: 0.1600951228220338\n",
      "skipgram_300_dense: brother, sister, his, her: 0.10670694926142113\n",
      "\n",
      "co-occurance: listen, listening, look, looking: 0.26481698509308443\n",
      "cbow_50: listen, listening, look, looking: 0.3802069701610734\n",
      "cbow_150: listen, listening, look, looking: 0.36921053308958424\n",
      "cbow_300: listen, listening, look, looking: 0.23802999618462123\n",
      "cbow_50_dense: listen, listening, look, looking: 0.03956834867672034\n",
      "cbow_150_dense: listen, listening, look, looking: 0.025226025836383444\n",
      "cbow_300_dense: listen, listening, look, looking: 0.08170528413458206\n",
      "skipgram_50: listen, listening, look, looking: 0.21922497121328843\n",
      "skipgram_150: listen, listening, look, looking: 0.11884336654412271\n",
      "skipgram_300: listen, listening, look, looking: 0.012053642266116044\n",
      "skipgram_50_dense: listen, listening, look, looking: 0.3328211143150717\n",
      "skipgram_150_dense: listen, listening, look, looking: 0.0595487007636639\n",
      "skipgram_300_dense: listen, listening, look, looking: 0.0406596642434014\n",
      "\n",
      "co-occurance: saying, said, thinking, thought: 0.35946825219809\n",
      "cbow_50: saying, said, thinking, thought: 0.3083834417108346\n",
      "cbow_150: saying, said, thinking, thought: 0.30258397528363445\n",
      "cbow_300: saying, said, thinking, thought: 0.3385169623849108\n",
      "cbow_50_dense: saying, said, thinking, thought: 0.27146892652097987\n",
      "cbow_150_dense: saying, said, thinking, thought: 0.26399041172107607\n",
      "cbow_300_dense: saying, said, thinking, thought: 0.12383424063284779\n",
      "skipgram_50: saying, said, thinking, thought: 0.565914284020611\n",
      "skipgram_150: saying, said, thinking, thought: 0.3787360042101855\n",
      "skipgram_300: saying, said, thinking, thought: 0.30719562937336314\n",
      "skipgram_50_dense: saying, said, thinking, thought: 0.032715337214361935\n",
      "skipgram_150_dense: saying, said, thinking, thought: 0.03265436792557913\n",
      "skipgram_300_dense: saying, said, thinking, thought: 0.08585073444779104\n",
      "\n",
      "co-occurance: bird, birds, cat, cats: 0.26944042644259525\n",
      "cbow_50: bird, birds, cat, cats: 0.25155843706819225\n",
      "cbow_150: bird, birds, cat, cats: 0.11949157172847855\n",
      "cbow_300: bird, birds, cat, cats: 0.1781694964528609\n",
      "cbow_50_dense: bird, birds, cat, cats: 0.2320395959316713\n",
      "cbow_150_dense: bird, birds, cat, cats: 0.0884316106458272\n",
      "cbow_300_dense: bird, birds, cat, cats: 0.14467242053834647\n",
      "skipgram_50: bird, birds, cat, cats: 0.4165848617676572\n",
      "skipgram_150: bird, birds, cat, cats: 0.12949779747079\n",
      "skipgram_300: bird, birds, cat, cats: 0.12433095616959039\n",
      "skipgram_50_dense: bird, birds, cat, cats: 0.012887874151781279\n",
      "skipgram_150_dense: bird, birds, cat, cats: 0.07353652983537766\n",
      "skipgram_300_dense: bird, birds, cat, cats: 0.05631322940932175\n",
      "\n",
      "co-occurance: good, better, old, older: 0.30714575708258646\n",
      "cbow_50: good, better, old, older: 0.28356033517821916\n",
      "cbow_150: good, better, old, older: 0.3367662060157432\n",
      "cbow_300: good, better, old, older: 0.24294226160000545\n",
      "cbow_50_dense: good, better, old, older: 0.12562361925379575\n",
      "cbow_150_dense: good, better, old, older: 0.10944203217062437\n",
      "cbow_300_dense: good, better, old, older: 0.18656535061624072\n",
      "skipgram_50: good, better, old, older: 0.006747658278795679\n",
      "skipgram_150: good, better, old, older: 0.2613328446046628\n",
      "skipgram_300: good, better, old, older: 0.16584128942361212\n",
      "skipgram_50_dense: good, better, old, older: 0.006715441594898397\n",
      "skipgram_150_dense: good, better, old, older: 0.05311411308035306\n",
      "skipgram_300_dense: good, better, old, older: 0.05186729010261828\n",
      "\n",
      "co-occurance: good, better, quick, quicker: 0.34107029029906366\n",
      "cbow_50: good, better, quick, quicker: 0.12513511819856912\n",
      "cbow_150: good, better, quick, quicker: 0.10664919624378821\n",
      "cbow_300: good, better, quick, quicker: 0.03208647290314115\n",
      "cbow_50_dense: good, better, quick, quicker: 0.12567182118934672\n",
      "cbow_150_dense: good, better, quick, quicker: 0.06164886348505986\n",
      "cbow_300_dense: good, better, quick, quicker: 0.051326262550663464\n",
      "skipgram_50: good, better, quick, quicker: 0.037811205524927546\n",
      "skipgram_150: good, better, quick, quicker: 0.011419143924304096\n",
      "skipgram_300: good, better, quick, quicker: 0.026034704557969784\n",
      "skipgram_50_dense: good, better, quick, quicker: 0.033102714983078194\n",
      "skipgram_150_dense: good, better, quick, quicker: 0.03085308262693412\n",
      "skipgram_300_dense: good, better, quick, quicker: 0.0796093389770551\n",
      "\n",
      "co-occurance: large, largest, good, best: 0.1395444089352949\n",
      "cbow_50: large, largest, good, best: 0.055252841538935865\n",
      "cbow_150: large, largest, good, best: 0.14962042649321572\n",
      "cbow_300: large, largest, good, best: 0.13627840091820803\n",
      "cbow_50_dense: large, largest, good, best: 0.1395942175402173\n",
      "cbow_150_dense: large, largest, good, best: 0.11470696113616369\n",
      "cbow_300_dense: large, largest, good, best: 0.05309922636686337\n",
      "skipgram_50: large, largest, good, best: 0.0076305093982703895\n",
      "skipgram_150: large, largest, good, best: 0.1707115412567479\n",
      "skipgram_300: large, largest, good, best: 0.1725711060097743\n",
      "skipgram_50_dense: large, largest, good, best: 0.12473340544962884\n",
      "skipgram_150_dense: large, largest, good, best: 0.06615579167947909\n",
      "skipgram_300_dense: large, largest, good, best: 0.053627787932685286\n",
      "\n",
      "co-occurance: falling, fell, knowing, knew: 0.11600348176198484\n",
      "cbow_50: falling, fell, knowing, knew: 0.34969637290903044\n",
      "cbow_150: falling, fell, knowing, knew: 0.16103343892183927\n",
      "cbow_300: falling, fell, knowing, knew: 0.01912836021160874\n",
      "cbow_50_dense: falling, fell, knowing, knew: 0.018394198007298426\n",
      "cbow_150_dense: falling, fell, knowing, knew: 0.05989618949756096\n",
      "cbow_300_dense: falling, fell, knowing, knew: 0.037205425222480805\n",
      "skipgram_50: falling, fell, knowing, knew: 0.06791467768999672\n",
      "skipgram_150: falling, fell, knowing, knew: 0.09136214862017362\n",
      "skipgram_300: falling, fell, knowing, knew: 0.01463649822550943\n",
      "skipgram_50_dense: falling, fell, knowing, knew: 0.16193351261122524\n",
      "skipgram_150_dense: falling, fell, knowing, knew: 0.03656470212890241\n",
      "skipgram_300_dense: falling, fell, knowing, knew: 0.03872969424142178\n",
      "\n",
      "co-occurance: walk, walking, think, thinking: 0.06948063618614567\n",
      "cbow_50: walk, walking, think, thinking: 0.23305398188264462\n",
      "cbow_150: walk, walking, think, thinking: 0.16217284732039994\n",
      "cbow_300: walk, walking, think, thinking: 0.1371422823556235\n",
      "cbow_50_dense: walk, walking, think, thinking: 0.441744421903988\n",
      "cbow_150_dense: walk, walking, think, thinking: 0.27691568613316025\n",
      "cbow_300_dense: walk, walking, think, thinking: 0.25241882965411033\n",
      "skipgram_50: walk, walking, think, thinking: 0.1326619778939263\n",
      "skipgram_150: walk, walking, think, thinking: 0.1950671462577301\n",
      "skipgram_300: walk, walking, think, thinking: 0.05063676675719801\n",
      "skipgram_50_dense: walk, walking, think, thinking: 0.11086919505279523\n",
      "skipgram_150_dense: walk, walking, think, thinking: 0.039340863036024035\n",
      "skipgram_300_dense: walk, walking, think, thinking: 0.020751693251079326\n",
      "\n",
      "co-occurance: child, children, cat, cats: 0.12887794267338276\n",
      "cbow_50: child, children, cat, cats: 0.5761045501314452\n",
      "cbow_150: child, children, cat, cats: 0.6283387407761182\n",
      "cbow_300: child, children, cat, cats: 0.4224878099785585\n",
      "cbow_50_dense: child, children, cat, cats: 0.13089713945022188\n",
      "cbow_150_dense: child, children, cat, cats: 0.31170060389105086\n",
      "cbow_300_dense: child, children, cat, cats: 0.15971883179637444\n",
      "skipgram_50: child, children, cat, cats: 0.18690841970146993\n",
      "skipgram_150: child, children, cat, cats: 0.15727020501279124\n",
      "skipgram_300: child, children, cat, cats: 0.1633643593580084\n",
      "skipgram_50_dense: child, children, cat, cats: 0.11475457926841195\n",
      "skipgram_150_dense: child, children, cat, cats: 0.07555755343684083\n",
      "skipgram_300_dense: child, children, cat, cats: 0.08558659954598827\n",
      "\n",
      "co-occurance: dog, dogs, eye, eyes: 0.2349695309752005\n",
      "cbow_50: dog, dogs, eye, eyes: 0.048068004590513976\n",
      "cbow_150: dog, dogs, eye, eyes: 0.18301195503900555\n",
      "cbow_300: dog, dogs, eye, eyes: 0.08293971404713851\n",
      "cbow_50_dense: dog, dogs, eye, eyes: 0.009944152990215106\n",
      "cbow_150_dense: dog, dogs, eye, eyes: 0.00018806916728422024\n",
      "cbow_300_dense: dog, dogs, eye, eyes: 0.04959143883742041\n",
      "skipgram_50: dog, dogs, eye, eyes: 0.5401933619978343\n",
      "skipgram_150: dog, dogs, eye, eyes: 0.011997018957234177\n",
      "skipgram_300: dog, dogs, eye, eyes: 0.036955218552049134\n",
      "skipgram_50_dense: dog, dogs, eye, eyes: 0.014302918123874776\n",
      "skipgram_150_dense: dog, dogs, eye, eyes: 0.04161267376478868\n",
      "skipgram_300_dense: dog, dogs, eye, eyes: 0.09854696917931136\n",
      "\n",
      "co-occurance: hand, hands, rat, rats: 0.33242520863352953\n",
      "cbow_50: hand, hands, rat, rats: 0.20928379513093132\n",
      "cbow_150: hand, hands, rat, rats: 0.08922689088034921\n",
      "cbow_300: hand, hands, rat, rats: 0.06167524716738153\n",
      "cbow_50_dense: hand, hands, rat, rats: 0.2241956513486761\n",
      "cbow_150_dense: hand, hands, rat, rats: 0.08479348857676028\n",
      "cbow_300_dense: hand, hands, rat, rats: 0.21763028239299223\n",
      "skipgram_50: hand, hands, rat, rats: 0.029477426759401692\n",
      "skipgram_150: hand, hands, rat, rats: 0.13241202071518388\n",
      "skipgram_300: hand, hands, rat, rats: 0.056338820916069676\n",
      "skipgram_50_dense: hand, hands, rat, rats: 0.000745369944340421\n",
      "skipgram_150_dense: hand, hands, rat, rats: 0.18282660345720494\n",
      "skipgram_300_dense: hand, hands, rat, rats: 0.07454463081175015\n",
      "\n",
      "co-occurance: eat, eats, find, finds: 0.11861436543909255\n",
      "cbow_50: eat, eats, find, finds: 0.6344386909160316\n",
      "cbow_150: eat, eats, find, finds: 0.6230622716693793\n",
      "cbow_300: eat, eats, find, finds: 0.38332741252697833\n",
      "cbow_50_dense: eat, eats, find, finds: 0.11014595751932027\n",
      "cbow_150_dense: eat, eats, find, finds: 0.022188421800295247\n",
      "cbow_300_dense: eat, eats, find, finds: 0.02799474581397439\n",
      "skipgram_50: eat, eats, find, finds: 0.26850222986801453\n",
      "skipgram_150: eat, eats, find, finds: 0.08289657352440934\n",
      "skipgram_300: eat, eats, find, finds: 0.1310917767169901\n",
      "skipgram_50_dense: eat, eats, find, finds: 0.022223655143363493\n",
      "skipgram_150_dense: eat, eats, find, finds: 0.04586212657365139\n",
      "skipgram_300_dense: eat, eats, find, finds: 0.004353422652560424\n",
      "\n",
      "co-occurance: find, finds, say, says: 0.23988741456332002\n",
      "cbow_50: find, finds, say, says: 0.19636398876648298\n",
      "cbow_150: find, finds, say, says: 0.3493458745768275\n",
      "cbow_300: find, finds, say, says: 0.4225110412871306\n",
      "cbow_50_dense: find, finds, say, says: 0.10255216118966275\n",
      "cbow_150_dense: find, finds, say, says: 0.04139482654371349\n",
      "cbow_300_dense: find, finds, say, says: 0.09204581834643971\n",
      "skipgram_50: find, finds, say, says: 0.02189051838308856\n",
      "skipgram_150: find, finds, say, says: 0.11727715537439058\n",
      "skipgram_300: find, finds, say, says: 0.1485523068621352\n",
      "skipgram_50_dense: find, finds, say, says: 0.21955934322292522\n",
      "skipgram_150_dense: find, finds, say, says: 0.02131875144526285\n",
      "skipgram_300_dense: find, finds, say, says: 0.024942033757297807\n",
      "\n",
      "co-occurance: old, older, good, better: 0.30714575708258646\n",
      "cbow_50: old, older, good, better: 0.28356033517821916\n",
      "cbow_150: old, older, good, better: 0.3367662060157432\n",
      "cbow_300: old, older, good, better: 0.24294226160000545\n",
      "cbow_50_dense: old, older, good, better: 0.12562361925379575\n",
      "cbow_150_dense: old, older, good, better: 0.10944203217062437\n",
      "cbow_300_dense: old, older, good, better: 0.18656535061624072\n",
      "skipgram_50: old, older, good, better: 0.006747658278795679\n",
      "skipgram_150: old, older, good, better: 0.2613328446046628\n",
      "skipgram_300: old, older, good, better: 0.16584128942361212\n",
      "skipgram_50_dense: old, older, good, better: 0.006715441594898397\n",
      "skipgram_150_dense: old, older, good, better: 0.05311411308035306\n",
      "skipgram_300_dense: old, older, good, better: 0.05186729010261828\n",
      "\n",
      "co-occurance: large, larger, quick, quicker: 0.46126229661503876\n",
      "cbow_50: large, larger, quick, quicker: 0.15041247724164664\n",
      "cbow_150: large, larger, quick, quicker: 0.23806847996439426\n",
      "cbow_300: large, larger, quick, quicker: 0.04205617897711103\n",
      "cbow_50_dense: large, larger, quick, quicker: 0.14810958793009651\n",
      "cbow_150_dense: large, larger, quick, quicker: 0.12186104289525825\n",
      "cbow_300_dense: large, larger, quick, quicker: 0.09311372510784723\n",
      "skipgram_50: large, larger, quick, quicker: 0.08552472433803812\n",
      "skipgram_150: large, larger, quick, quicker: 0.12424542939530621\n",
      "skipgram_300: large, larger, quick, quicker: 0.06756714447400183\n",
      "skipgram_50_dense: large, larger, quick, quicker: 0.12221104436704669\n",
      "skipgram_150_dense: large, larger, quick, quicker: 0.053115179996420764\n",
      "skipgram_300_dense: large, larger, quick, quicker: 0.06817445995579048\n",
      "\n",
      "co-occurance: go, going, listen, listening: 0.17052103002986832\n",
      "cbow_50: go, going, listen, listening: 0.004348558915977116\n",
      "cbow_150: go, going, listen, listening: 0.04591844648923439\n",
      "cbow_300: go, going, listen, listening: 0.028175657728302012\n",
      "cbow_50_dense: go, going, listen, listening: 0.019190198412343568\n",
      "cbow_150_dense: go, going, listen, listening: 0.13541379022058453\n",
      "cbow_300_dense: go, going, listen, listening: 0.08877512926435754\n",
      "skipgram_50: go, going, listen, listening: 0.05539435165038242\n",
      "skipgram_150: go, going, listen, listening: 0.03247324062648229\n",
      "skipgram_300: go, going, listen, listening: 0.15185486231081524\n",
      "skipgram_50_dense: go, going, listen, listening: 0.14996689018468176\n",
      "skipgram_150_dense: go, going, listen, listening: 0.04243841588618983\n",
      "skipgram_300_dense: go, going, listen, listening: 0.010873228635317379\n",
      "\n",
      "co-occurance: run, running, walk, walking: 0.09035624609139908\n",
      "cbow_50: run, running, walk, walking: 0.43239444601331156\n",
      "cbow_150: run, running, walk, walking: 0.17316018462778576\n",
      "cbow_300: run, running, walk, walking: 0.06752979323171769\n",
      "cbow_50_dense: run, running, walk, walking: 0.19041077959930008\n",
      "cbow_150_dense: run, running, walk, walking: 0.08575569090759745\n",
      "cbow_300_dense: run, running, walk, walking: 0.13319373973395193\n",
      "skipgram_50: run, running, walk, walking: 0.05440431387771808\n",
      "skipgram_150: run, running, walk, walking: 0.08192690911244668\n",
      "skipgram_300: run, running, walk, walking: 0.10293102828061876\n",
      "skipgram_50_dense: run, running, walk, walking: 0.10158365041561519\n",
      "skipgram_150_dense: run, running, walk, walking: 0.03850630114665086\n",
      "skipgram_300_dense: run, running, walk, walking: 0.036897706755464\n",
      "\n",
      "co-occurance: run, running, think, thinking: 0.2779494787370918\n",
      "cbow_50: run, running, think, thinking: 0.12738615012738252\n",
      "cbow_150: run, running, think, thinking: 0.1885880627853949\n",
      "cbow_300: run, running, think, thinking: 0.13662853663187174\n",
      "cbow_50_dense: run, running, think, thinking: 0.09327913484627907\n",
      "cbow_150_dense: run, running, think, thinking: 0.09934669415267226\n",
      "cbow_300_dense: run, running, think, thinking: 0.013760378794701674\n",
      "skipgram_50: run, running, think, thinking: 0.0266290831646828\n",
      "skipgram_150: run, running, think, thinking: 0.08328285298530103\n",
      "skipgram_300: run, running, think, thinking: 0.06572295097742854\n",
      "skipgram_50_dense: run, running, think, thinking: 0.012145371455604355\n",
      "skipgram_150_dense: run, running, think, thinking: 0.06641353890075766\n",
      "skipgram_300_dense: run, running, think, thinking: 0.13502023716520042\n",
      "\n",
      "co-occurance: say, saying, sit, sitting: 0.15328841775286633\n",
      "cbow_50: say, saying, sit, sitting: 0.13290110049743256\n",
      "cbow_150: say, saying, sit, sitting: 0.13794787877818132\n",
      "cbow_300: say, saying, sit, sitting: 0.1255869428992714\n",
      "cbow_50_dense: say, saying, sit, sitting: 0.08854998828125173\n",
      "cbow_150_dense: say, saying, sit, sitting: 0.08481168346115567\n",
      "cbow_300_dense: say, saying, sit, sitting: 0.002778512915029485\n",
      "skipgram_50: say, saying, sit, sitting: 0.06671581439417851\n",
      "skipgram_150: say, saying, sit, sitting: 0.024395699928681472\n",
      "skipgram_300: say, saying, sit, sitting: 0.08653137863087766\n",
      "skipgram_50_dense: say, saying, sit, sitting: 0.2291511923882307\n",
      "skipgram_150_dense: say, saying, sit, sitting: 0.08249327141657764\n",
      "skipgram_300_dense: say, saying, sit, sitting: 0.031370623390230355\n",
      "\n",
      "co-occurance: alice, she, rabbit, he: 0.34414807845164874\n",
      "cbow_50: alice, she, rabbit, he: 0.3032260713980009\n",
      "cbow_150: alice, she, rabbit, he: 0.28750781874194553\n",
      "cbow_300: alice, she, rabbit, he: 0.23737374549441895\n",
      "cbow_50_dense: alice, she, rabbit, he: 0.37400362858646385\n",
      "cbow_150_dense: alice, she, rabbit, he: 0.2604214341177389\n",
      "cbow_300_dense: alice, she, rabbit, he: 0.22134533492778896\n",
      "skipgram_50: alice, she, rabbit, he: 0.3969428627541493\n",
      "skipgram_150: alice, she, rabbit, he: 0.26935194521993117\n",
      "skipgram_300: alice, she, rabbit, he: 0.1325306631609167\n",
      "skipgram_50_dense: alice, she, rabbit, he: 0.08122499625428377\n",
      "skipgram_150_dense: alice, she, rabbit, he: 0.19001593659421726\n",
      "skipgram_300_dense: alice, she, rabbit, he: 0.1196936498430301\n",
      "\n",
      "co-occurance: alice, her, rabbit, him: 0.32771434927105814\n",
      "cbow_50: alice, her, rabbit, him: 0.4245334730572496\n",
      "cbow_150: alice, her, rabbit, him: 0.3949279690641324\n",
      "cbow_300: alice, her, rabbit, him: 0.4694802520899805\n",
      "cbow_50_dense: alice, her, rabbit, him: 0.37489014507553303\n",
      "cbow_150_dense: alice, her, rabbit, him: 0.2922573512779353\n",
      "cbow_300_dense: alice, her, rabbit, him: 0.3085777141782657\n",
      "skipgram_50: alice, her, rabbit, him: 0.43744368034614123\n",
      "skipgram_150: alice, her, rabbit, him: 0.28236727353514146\n",
      "skipgram_300: alice, her, rabbit, him: 0.16623145761281516\n",
      "skipgram_50_dense: alice, her, rabbit, him: 0.003912821913825373\n",
      "skipgram_150_dense: alice, her, rabbit, him: 0.079360369362521\n",
      "skipgram_300_dense: alice, her, rabbit, him: 0.004352950260186055\n",
      "\n",
      "co-occurance: alice, girl, rabbit, sir: 0.09186016685209755\n",
      "cbow_50: alice, girl, rabbit, sir: 0.38352821418807104\n",
      "cbow_150: alice, girl, rabbit, sir: 0.3037741386102526\n",
      "cbow_300: alice, girl, rabbit, sir: 0.29111823565411055\n",
      "cbow_50_dense: alice, girl, rabbit, sir: 0.296456905787305\n",
      "cbow_150_dense: alice, girl, rabbit, sir: 0.18437463780691493\n",
      "cbow_300_dense: alice, girl, rabbit, sir: 0.17745145079999616\n",
      "skipgram_50: alice, girl, rabbit, sir: 0.37706869416324595\n",
      "skipgram_150: alice, girl, rabbit, sir: 0.2434311774890583\n",
      "skipgram_300: alice, girl, rabbit, sir: 0.013468505209538413\n",
      "skipgram_50_dense: alice, girl, rabbit, sir: 0.007664461700388371\n",
      "skipgram_150_dense: alice, girl, rabbit, sir: 0.013923791377918283\n",
      "skipgram_300_dense: alice, girl, rabbit, sir: 0.16162886469339285\n",
      "\n",
      "co-occurance: dinah, cat, alice, girl: 0.3292661488822022\n",
      "cbow_50: dinah, cat, alice, girl: 0.18871490618643927\n",
      "cbow_150: dinah, cat, alice, girl: 0.1988998323029214\n",
      "cbow_300: dinah, cat, alice, girl: 0.21994575208961464\n",
      "cbow_50_dense: dinah, cat, alice, girl: 0.01817282196713359\n",
      "cbow_150_dense: dinah, cat, alice, girl: 0.12974284936731623\n",
      "cbow_300_dense: dinah, cat, alice, girl: 0.0973591792683185\n",
      "skipgram_50: dinah, cat, alice, girl: 0.20264584206408742\n",
      "skipgram_150: dinah, cat, alice, girl: 0.23600359629142628\n",
      "skipgram_300: dinah, cat, alice, girl: 0.1798156827185624\n",
      "skipgram_50_dense: dinah, cat, alice, girl: 0.06226421184792411\n",
      "skipgram_150_dense: dinah, cat, alice, girl: 0.04952489944505424\n",
      "skipgram_300_dense: dinah, cat, alice, girl: 0.016715979149657174\n",
      "\n",
      "co-occurance: his, her, he, she: 0.7385962387549866\n",
      "cbow_50: his, her, he, she: 0.08099932963910215\n",
      "cbow_150: his, her, he, she: 0.03569783846020872\n",
      "cbow_300: his, her, he, she: 0.022474709476888687\n",
      "cbow_50_dense: his, her, he, she: 0.25305776920456663\n",
      "cbow_150_dense: his, her, he, she: 0.05257730241374489\n",
      "cbow_300_dense: his, her, he, she: 0.12253203367780965\n",
      "skipgram_50: his, her, he, she: 0.5350455025860693\n",
      "skipgram_150: his, her, he, she: 0.4214261528756635\n",
      "skipgram_300: his, her, he, she: 0.1928937824570437\n",
      "skipgram_50_dense: his, her, he, she: 0.2154861486119754\n",
      "skipgram_150_dense: his, her, he, she: 0.14655767256694316\n",
      "skipgram_300_dense: his, her, he, she: 0.1511302407262479\n",
      "\n",
      "co-occurance: long, longer, quick, quicker: 0.0754247233265651\n",
      "cbow_50: long, longer, quick, quicker: 0.4120102891993884\n",
      "cbow_150: long, longer, quick, quicker: 0.23017015273506933\n",
      "cbow_300: long, longer, quick, quicker: 0.09401260595447117\n",
      "cbow_50_dense: long, longer, quick, quicker: 0.01408052840685802\n",
      "cbow_150_dense: long, longer, quick, quicker: 0.007133586407366825\n",
      "cbow_300_dense: long, longer, quick, quicker: 0.07831883522036924\n",
      "skipgram_50: long, longer, quick, quicker: 0.02151832074829586\n",
      "skipgram_150: long, longer, quick, quicker: 0.09068842882436388\n",
      "skipgram_300: long, longer, quick, quicker: 0.07102139535964663\n",
      "skipgram_50_dense: long, longer, quick, quicker: 0.05400072789551662\n",
      "skipgram_150_dense: long, longer, quick, quicker: 0.11150849188104847\n",
      "skipgram_300_dense: long, longer, quick, quicker: 0.03754801662507641\n",
      "\n",
      "co-occurance: long, longer, small, smaller: 0.08908306380621506\n",
      "cbow_50: long, longer, small, smaller: 0.4318003131750905\n",
      "cbow_150: long, longer, small, smaller: 0.3554968324347603\n",
      "cbow_300: long, longer, small, smaller: 0.19269746490298645\n",
      "cbow_50_dense: long, longer, small, smaller: 0.5372986667713919\n",
      "cbow_150_dense: long, longer, small, smaller: 0.3725341328264276\n",
      "cbow_300_dense: long, longer, small, smaller: 0.35016791043829654\n",
      "skipgram_50: long, longer, small, smaller: 0.21398489733806456\n",
      "skipgram_150: long, longer, small, smaller: 0.1640505580848037\n",
      "skipgram_300: long, longer, small, smaller: 0.21245308466171794\n",
      "skipgram_50_dense: long, longer, small, smaller: 0.06976419471060234\n",
      "skipgram_150_dense: long, longer, small, smaller: 0.008430045436527846\n",
      "skipgram_300_dense: long, longer, small, smaller: 0.02207475087097485\n",
      "\n",
      "co-occurance: long, longer, bad, worse: 0.12267116321986311\n",
      "cbow_50: long, longer, bad, worse: 0.3260491473042464\n",
      "cbow_150: long, longer, bad, worse: 0.15212735080104456\n",
      "cbow_300: long, longer, bad, worse: 0.20373219592586617\n",
      "cbow_50_dense: long, longer, bad, worse: 0.08853810932159445\n",
      "cbow_150_dense: long, longer, bad, worse: 0.02362576370261302\n",
      "cbow_300_dense: long, longer, bad, worse: 0.02967005557613777\n",
      "skipgram_50: long, longer, bad, worse: 0.09991521837069943\n",
      "skipgram_150: long, longer, bad, worse: 0.04688277512539548\n",
      "skipgram_300: long, longer, bad, worse: 0.04225910785783235\n",
      "skipgram_50_dense: long, longer, bad, worse: 0.0591265043266381\n",
      "skipgram_150_dense: long, longer, bad, worse: 0.026776340215094604\n",
      "skipgram_300_dense: long, longer, bad, worse: 0.0009287152378468827\n",
      "\n",
      "co-occurance: go, going, look, looking: 0.5257224725382912\n",
      "cbow_50: go, going, look, looking: 0.04482878540457188\n",
      "cbow_150: go, going, look, looking: 0.13521208123901596\n",
      "cbow_300: go, going, look, looking: 0.11739576262876612\n",
      "cbow_50_dense: go, going, look, looking: 0.2275989682841857\n",
      "cbow_150_dense: go, going, look, looking: 0.08095648478867602\n",
      "cbow_300_dense: go, going, look, looking: 0.014954370905789528\n",
      "skipgram_50: go, going, look, looking: 0.04897776970140745\n",
      "skipgram_150: go, going, look, looking: 0.3108869698881552\n",
      "skipgram_300: go, going, look, looking: 0.1897161720304399\n",
      "skipgram_50_dense: go, going, look, looking: 0.14061684371374158\n",
      "skipgram_150_dense: go, going, look, looking: 0.14720249473774485\n",
      "skipgram_300_dense: go, going, look, looking: 0.002864495321771528\n",
      "\n",
      "co-occurance: listen, listening, look, looking: 0.26481698509308443\n",
      "cbow_50: listen, listening, look, looking: 0.3802069701610734\n",
      "cbow_150: listen, listening, look, looking: 0.36921053308958424\n",
      "cbow_300: listen, listening, look, looking: 0.23802999618462123\n",
      "cbow_50_dense: listen, listening, look, looking: 0.03956834867672034\n",
      "cbow_150_dense: listen, listening, look, looking: 0.025226025836383444\n",
      "cbow_300_dense: listen, listening, look, looking: 0.08170528413458206\n",
      "skipgram_50: listen, listening, look, looking: 0.21922497121328843\n",
      "skipgram_150: listen, listening, look, looking: 0.11884336654412271\n",
      "skipgram_300: listen, listening, look, looking: 0.012053642266116044\n",
      "skipgram_50_dense: listen, listening, look, looking: 0.3328211143150717\n",
      "skipgram_150_dense: listen, listening, look, looking: 0.0595487007636639\n",
      "skipgram_300_dense: listen, listening, look, looking: 0.0406596642434014\n",
      "\n",
      "co-occurance: swim, swimming, sit, sitting: 0.02995723447576391\n",
      "cbow_50: swim, swimming, sit, sitting: 0.48978575850663114\n",
      "cbow_150: swim, swimming, sit, sitting: 0.22129192423968272\n",
      "cbow_300: swim, swimming, sit, sitting: 0.04745686624994828\n",
      "cbow_50_dense: swim, swimming, sit, sitting: 0.021958860917220397\n",
      "cbow_150_dense: swim, swimming, sit, sitting: 0.17068327726846955\n",
      "cbow_300_dense: swim, swimming, sit, sitting: 0.03918166245483594\n",
      "skipgram_50: swim, swimming, sit, sitting: 0.2045576159267067\n",
      "skipgram_150: swim, swimming, sit, sitting: 0.02695449005542896\n",
      "skipgram_300: swim, swimming, sit, sitting: 0.0759698816019391\n",
      "skipgram_50_dense: swim, swimming, sit, sitting: 0.03028533116032402\n",
      "skipgram_150_dense: swim, swimming, sit, sitting: 0.05055787779525484\n",
      "skipgram_300_dense: swim, swimming, sit, sitting: 0.03563140413128219\n",
      "\n",
      "co-occurance: run, running, listen, listening: 0.13591085134405553\n",
      "cbow_50: run, running, listen, listening: 0.7591559036884049\n",
      "cbow_150: run, running, listen, listening: 0.500506534222073\n",
      "cbow_300: run, running, listen, listening: 0.2172115315370583\n",
      "cbow_50_dense: run, running, listen, listening: 0.1839417128743973\n",
      "cbow_150_dense: run, running, listen, listening: 0.22631221236606874\n",
      "cbow_300_dense: run, running, listen, listening: 0.16730155288174092\n",
      "skipgram_50: run, running, listen, listening: 0.008977071763193276\n",
      "skipgram_150: run, running, listen, listening: 0.06712680136774937\n",
      "skipgram_300: run, running, listen, listening: 0.05989072385340193\n",
      "skipgram_50_dense: run, running, listen, listening: 0.0398748541017174\n",
      "skipgram_150_dense: run, running, listen, listening: 0.012654900797069137\n",
      "skipgram_300_dense: run, running, listen, listening: 0.052294495200113054\n",
      "\n",
      "co-occurance: think, thinking, read, reading: 0.307303933969022\n",
      "cbow_50: think, thinking, read, reading: 0.2990498498151042\n",
      "cbow_150: think, thinking, read, reading: 0.2330940450897781\n",
      "cbow_300: think, thinking, read, reading: 0.16911559484697625\n",
      "cbow_50_dense: think, thinking, read, reading: 0.3787095492702201\n",
      "cbow_150_dense: think, thinking, read, reading: 0.3078049519115134\n",
      "cbow_300_dense: think, thinking, read, reading: 0.08962903058811725\n",
      "skipgram_50: think, thinking, read, reading: 0.06297131665063069\n",
      "skipgram_150: think, thinking, read, reading: 0.0061040761486036025\n",
      "skipgram_300: think, thinking, read, reading: 0.022228808308668864\n",
      "skipgram_50_dense: think, thinking, read, reading: 0.126542806632079\n",
      "skipgram_150_dense: think, thinking, read, reading: 0.0181158051746606\n",
      "skipgram_300_dense: think, thinking, read, reading: 0.03892256124563785\n",
      "\n",
      "co-occurance: up, down, close, far: 0.28084517529031744\n",
      "cbow_50: up, down, close, far: 0.36010716857066855\n",
      "cbow_150: up, down, close, far: 0.36598875609203435\n",
      "cbow_300: up, down, close, far: 0.21333871878277946\n",
      "cbow_50_dense: up, down, close, far: 0.19196383523652996\n",
      "cbow_150_dense: up, down, close, far: 0.009307886939470968\n",
      "cbow_300_dense: up, down, close, far: 0.007063529840594001\n",
      "skipgram_50: up, down, close, far: 0.006113836150702873\n",
      "skipgram_150: up, down, close, far: 0.16539584160054252\n",
      "skipgram_300: up, down, close, far: 0.1783465178663802\n",
      "skipgram_50_dense: up, down, close, far: 0.04473971846960458\n",
      "skipgram_150_dense: up, down, close, far: 0.14023607002769808\n",
      "skipgram_300_dense: up, down, close, far: 0.018702310370623847\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#w2v and glove analogy performance\n",
    "cbow50analogylist=[]\n",
    "cbow50denseanalogylist=[]\n",
    "cbow150analogylist=[]\n",
    "cbow150denseanalogylist=[]\n",
    "cbow300analogylist=[]\n",
    "cbow300denseanalogylist=[]\n",
    "skipgram50analogylist=[]\n",
    "skipgram50denseanalogylist=[]\n",
    "skipgram150analogylist=[]\n",
    "skipgram150denseanalogylist=[]\n",
    "skipgram300analogylist=[]\n",
    "skipgram300denseanalogylist=[]\n",
    "co_occurrencelist=[]\n",
    "\n",
    "\n",
    "for analogy in analogy_list:\n",
    "    if(analogy[0] in tokenizer.word_index and analogy[1] in tokenizer.word_index and analogy[2] in tokenizer.word_index and analogy[3] in tokenizer.word_index):\n",
    "        try:\n",
    "            co_occurrenceanalogy=analogy_check(analogy,tf_cooc, tokenizer.word_index )\n",
    "            cbow50analogy=analogy_check(analogy,embed_cbow_50, tokenizer.word_index )\n",
    "            cbow150analogy=analogy_check(analogy,embed_cbow_150, tokenizer.word_index )\n",
    "            cbow300analogy=analogy_check(analogy,embed_cbow_300, tokenizer.word_index )\n",
    "            cbow50denseanalogy=analogy_check(analogy,embed_cbow_50_dense, tokenizer.word_index )\n",
    "            cbow150denseanalogy=analogy_check(analogy,embed_cbow_150_dense, tokenizer.word_index )\n",
    "            cbow300denseanalogy=analogy_check(analogy,embed_cbow_300_dense, tokenizer.word_index )\n",
    "            skipgram50analogy=analogy_check(analogy,embed_skipgram_50, tokenizer.word_index )\n",
    "            skipgram150analogy=analogy_check(analogy,embed_skipgram_150, tokenizer.word_index )\n",
    "            skipgram300analogy=analogy_check(analogy,embed_skipgram_300, tokenizer.word_index )\n",
    "            skipgram50denseanalogy=analogy_check(analogy,embed_skipgram_50_dense, tokenizer.word_index )\n",
    "            skipgram150denseanalogy=analogy_check(analogy,embed_skipgram_150_dense, tokenizer.word_index )\n",
    "            skipgram300denseanalogy=analogy_check(analogy,embed_skipgram_300_dense, tokenizer.word_index )\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(\"co-occurance: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],co_occurrenceanalogy))\n",
    "            print(\"cbow_50: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow50analogy))\n",
    "            print(\"cbow_150: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow150analogy))\n",
    "            print(\"cbow_300: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow300analogy))\n",
    "            print(\"cbow_50_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow50denseanalogy))\n",
    "            print(\"cbow_150_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow150denseanalogy))\n",
    "            print(\"cbow_300_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow300denseanalogy))\n",
    "            print(\"skipgram_50: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram50analogy))\n",
    "            print(\"skipgram_150: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram150analogy))\n",
    "            print(\"skipgram_300: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram300analogy))\n",
    "            print(\"skipgram_50_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram50denseanalogy))\n",
    "            print(\"skipgram_150_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram150denseanalogy))\n",
    "            print(\"skipgram_300_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram300denseanalogy))\n",
    "            \n",
    "            \n",
    "            co_occurrencelist.append(co_occurrence)\n",
    "            cbow50analogylist.append(cbow50analogy)\n",
    "            cbow150analogylist.append(cbow150analogy)\n",
    "            cbow300analogylist.append(cbow300analogy)\n",
    "            cbow50denseanalogylist.append(cbow50denseanalogy)\n",
    "            cbow150denseanalogylist.append(cbow150denseanalogy)\n",
    "            cbow300denseanalogylist.append(cbow300denseanalogy)\n",
    "            skipgram50analogylist.append(skipgram50analogy)\n",
    "            skipgram150analogylist.append(skipgram150analogy)\n",
    "            skipgram300analogylist.append(skipgram300analogy)\n",
    "            skipgram50denseanalogylist.append(skipgram50denseanalogy)\n",
    "            skipgram150denseanalogylist.append(skipgram150denseanalogy)\n",
    "            skipgram300denseanalogylist.append(skipgram300denseanalogy)\n",
    "            \n",
    "            \n",
    "            print()\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation results of the visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2489b4f7198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['find' 'finds' 'say' 'says']\n"
     ]
    }
   ],
   "source": [
    "#co_occurrence (tf normalized)\n",
    "\n",
    "embedlist=[]\n",
    "for i in range(4):\n",
    "    #embedlist.append(word2vec[analogy_list[1][i]])\n",
    "    embedlist.append(tf_cooc[tokenizer.word_index[w2visualize[i]]-1])\n",
    "plt.title(\"Co-occurrence (tf normalized)\")\n",
    "draw_word_vecs(embedlist,w2visualize)    \n",
    "print(w2visualize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "Using tf-normalized co-occurrence matrix as the embedding matrix, we can see that there are some analogy that has high similarity eventhough it has unrelated word structure. For example: (brother, sister, his, her) that has value of 0.61. This is happened because brother and sister are closely "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 \n",
    "### Discussion of the advantages of CBOW and Skipgram, the advantages of negative sampling and drawbacks of CBOW and Skipgram\n",
    "\n",
    "CBOW tries to predict a word by context, it sees the context and maximizes the probability of the target word.\n",
    "This means CBOW is good at predicting frequent words. To train CBOW a reasonably low amount of data is sufficient.\n",
    "The drawback of CBOW is that whilst it will preform well at predicting frequent words it will have low accuracy for less frequent words.\n",
    "this is because some words compete in the sense that they are a valid target for the same context.\n",
    "The more frequent word will then be predicted.\n",
    "\n",
    "In negative sampling we choose random words to pair with the target and have an output of 0. \n",
    "The updating of the weights is then performed on these K samples, which reduces the computational requirements.\n",
    "The model does not need all observations but simply only the K sampled pairs (context + target).\n",
    "\n",
    "Skip gram is designed to predict context. It sees the target and tries to find the context around the word. \n",
    "Skip gram is rather well suited even for rare words. Thake the example delightfull, it will try to predict something like yesterday was a day.\n",
    "Whilst if CBOw would have gotten this context delightfull would have never been predicted it would have chosen more frequent words like good.\n",
    "The drawback for skip gram is that it requires a large amount of data to train. This is because if we for example look at the delightfull word it will have context.\n",
    "Similar nice will also have a context, delightfull day and nice day are 2 independant sets. In cbow this use of nice and delightfull would be competing since the context day has both \n",
    "delightfull and nice as targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7\n",
    "### Load pre-trained embeddings on large corpuses (see the pdf file). You only have to consider the word embeddings with an embedding size of 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pretrained word embeddings of word2vec\n",
    "\n",
    "path_word2vec = \"tes\\GoogleNews-vectors-negative300.bin\"\n",
    "\n",
    "word2vec = KeyedVectors.load_word2vec_format(path_word2vec, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pretraind word embeddings of Glove\n",
    "import gensim\n",
    "#path = \"tes\\glove.6B\\glove.6B.300d_converted.txt\"\n",
    "path = \"tes\\glove.6B.300d.txt\"\n",
    "\n",
    "#convert GloVe into word2vec format\n",
    "gensim.scripts.glove2word2vec.get_glove_info(path)\n",
    "gensim.scripts.glove2word2vec.glove2word2vec(path, \"glove_converted.txt\")\n",
    "\n",
    "glove = KeyedVectors.load_word2vec_format(\"glove_converted.txt\", binary=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v: sudden, suddenly, usual, usually: 0.22255026056670402\n",
      "glove: sudden, suddenly, usual, usually: 0.3100777731068751\n",
      "cbow: sudden, suddenly, usual, usually: 0.04262983580543956\n",
      "cbow_dense: sudden, suddenly, usual, usually: 0.057512587300851306\n",
      "skipgram: sudden, suddenly, usual, usually: 0.025398620492292738\n",
      "skipgram_dense: sudden, suddenly, usual, usually: 0.0379434827632857\n",
      "\n",
      "w2v: bad, worse, good, better: 0.6724906513772779\n",
      "glove: bad, worse, good, better: 0.6565830036364912\n",
      "cbow: bad, worse, good, better: 0.08364212988123694\n",
      "cbow_dense: bad, worse, good, better: 0.022567480791767187\n",
      "skipgram: bad, worse, good, better: 0.014283902125049552\n",
      "skipgram_dense: bad, worse, good, better: 0.06542767465641082\n",
      "\n",
      "w2v: go, going, look, looking: 0.4437767197062708\n",
      "glove: go, going, look, looking: 0.6695781772903449\n",
      "cbow: go, going, look, looking: 0.11739576262876612\n",
      "cbow_dense: go, going, look, looking: 0.014954370905789528\n",
      "skipgram: go, going, look, looking: 0.1897161720304399\n",
      "skipgram_dense: go, going, look, looking: 0.002864495321771528\n",
      "\n",
      "w2v: he, she, his, her: 0.661601926269319\n",
      "glove: he, she, his, her: 0.7343965200095653\n",
      "cbow: he, she, his, her: 0.022474709476888687\n",
      "cbow_dense: he, she, his, her: 0.12253203367780965\n",
      "skipgram: he, she, his, her: 0.1928937824570437\n",
      "skipgram_dense: he, she, his, her: 0.1511302407262479\n",
      "\n",
      "w2v: brother, sister, his, her: 0.29478371779476814\n",
      "glove: brother, sister, his, her: 0.565070276491166\n",
      "cbow: brother, sister, his, her: 0.07589060484117083\n",
      "cbow_dense: brother, sister, his, her: 0.010614877330893632\n",
      "skipgram: brother, sister, his, her: 0.15242621645498913\n",
      "skipgram_dense: brother, sister, his, her: 0.10670694926142113\n",
      "\n",
      "w2v: listen, listening, look, looking: 0.21896109979844153\n",
      "glove: listen, listening, look, looking: 0.4071841107300849\n",
      "cbow: listen, listening, look, looking: 0.23802999618462123\n",
      "cbow_dense: listen, listening, look, looking: 0.08170528413458206\n",
      "skipgram: listen, listening, look, looking: 0.012053642266116044\n",
      "skipgram_dense: listen, listening, look, looking: 0.0406596642434014\n",
      "\n",
      "w2v: saying, said, thinking, thought: 0.40956290213903407\n",
      "glove: saying, said, thinking, thought: 0.49768632598408674\n",
      "cbow: saying, said, thinking, thought: 0.3385169623849108\n",
      "cbow_dense: saying, said, thinking, thought: 0.12383424063284779\n",
      "skipgram: saying, said, thinking, thought: 0.30719562937336314\n",
      "skipgram_dense: saying, said, thinking, thought: 0.08585073444779104\n",
      "\n",
      "w2v: bird, birds, cat, cats: 0.548314343723498\n",
      "glove: bird, birds, cat, cats: 0.48856988240789534\n",
      "cbow: bird, birds, cat, cats: 0.1781694964528609\n",
      "cbow_dense: bird, birds, cat, cats: 0.14467242053834647\n",
      "skipgram: bird, birds, cat, cats: 0.12433095616959039\n",
      "skipgram_dense: bird, birds, cat, cats: 0.05631322940932175\n",
      "\n",
      "w2v: good, better, old, older: 0.21694786651491343\n",
      "glove: good, better, old, older: 0.40961181661362545\n",
      "cbow: good, better, old, older: 0.24294226160000545\n",
      "cbow_dense: good, better, old, older: 0.18656535061624072\n",
      "skipgram: good, better, old, older: 0.16584128942361212\n",
      "skipgram_dense: good, better, old, older: 0.05186729010261828\n",
      "\n",
      "w2v: good, better, quick, quicker: 0.5330237925619995\n",
      "glove: good, better, quick, quicker: 0.5328881245927063\n",
      "cbow: good, better, quick, quicker: 0.03208647290314115\n",
      "cbow_dense: good, better, quick, quicker: 0.051326262550663464\n",
      "skipgram: good, better, quick, quicker: 0.026034704557969784\n",
      "skipgram_dense: good, better, quick, quicker: 0.0796093389770551\n",
      "\n",
      "w2v: large, largest, good, best: 0.21683160333463167\n",
      "glove: large, largest, good, best: 0.2652648164246623\n",
      "cbow: large, largest, good, best: 0.13627840091820803\n",
      "cbow_dense: large, largest, good, best: 0.05309922636686337\n",
      "skipgram: large, largest, good, best: 0.1725711060097743\n",
      "skipgram_dense: large, largest, good, best: 0.053627787932685286\n",
      "\n",
      "w2v: falling, fell, knowing, knew: 0.14287526113350987\n",
      "glove: falling, fell, knowing, knew: 0.15409427727346053\n",
      "cbow: falling, fell, knowing, knew: 0.01912836021160874\n",
      "cbow_dense: falling, fell, knowing, knew: 0.037205425222480805\n",
      "skipgram: falling, fell, knowing, knew: 0.01463649822550943\n",
      "skipgram_dense: falling, fell, knowing, knew: 0.03872969424142178\n",
      "\n",
      "w2v: walk, walking, think, thinking: 0.25107561442774934\n",
      "glove: walk, walking, think, thinking: 0.4035633827468627\n",
      "cbow: walk, walking, think, thinking: 0.1371422823556235\n",
      "cbow_dense: walk, walking, think, thinking: 0.25241882965411033\n",
      "skipgram: walk, walking, think, thinking: 0.05063676675719801\n",
      "skipgram_dense: walk, walking, think, thinking: 0.020751693251079326\n",
      "\n",
      "w2v: child, children, cat, cats: 0.36624447596308296\n",
      "glove: child, children, cat, cats: 0.28044855781310063\n",
      "cbow: child, children, cat, cats: 0.4224878099785585\n",
      "cbow_dense: child, children, cat, cats: 0.15971883179637444\n",
      "skipgram: child, children, cat, cats: 0.1633643593580084\n",
      "skipgram_dense: child, children, cat, cats: 0.08558659954598827\n",
      "\n",
      "w2v: dog, dogs, eye, eyes: 0.13321162577935888\n",
      "glove: dog, dogs, eye, eyes: 0.3071176163860798\n",
      "cbow: dog, dogs, eye, eyes: 0.08293971404713851\n",
      "cbow_dense: dog, dogs, eye, eyes: 0.04959143883742041\n",
      "skipgram: dog, dogs, eye, eyes: 0.036955218552049134\n",
      "skipgram_dense: dog, dogs, eye, eyes: 0.09854696917931136\n",
      "\n",
      "w2v: hand, hands, rat, rats: 0.04862699542761563\n",
      "glove: hand, hands, rat, rats: 0.05072466972752036\n",
      "cbow: hand, hands, rat, rats: 0.06167524716738153\n",
      "cbow_dense: hand, hands, rat, rats: 0.21763028239299223\n",
      "skipgram: hand, hands, rat, rats: 0.056338820916069676\n",
      "skipgram_dense: hand, hands, rat, rats: 0.07454463081175015\n",
      "\n",
      "w2v: eat, eats, find, finds: 0.2830192036624857\n",
      "glove: eat, eats, find, finds: 0.30765008316898457\n",
      "cbow: eat, eats, find, finds: 0.38332741252697833\n",
      "cbow_dense: eat, eats, find, finds: 0.02799474581397439\n",
      "skipgram: eat, eats, find, finds: 0.1310917767169901\n",
      "skipgram_dense: eat, eats, find, finds: 0.004353422652560424\n",
      "\n",
      "w2v: find, finds, say, says: 0.38303518154481636\n",
      "glove: find, finds, say, says: 0.4858085924624003\n",
      "cbow: find, finds, say, says: 0.4225110412871306\n",
      "cbow_dense: find, finds, say, says: 0.09204581834643971\n",
      "skipgram: find, finds, say, says: 0.1485523068621352\n",
      "skipgram_dense: find, finds, say, says: 0.024942033757297807\n",
      "\n",
      "w2v: old, older, good, better: 0.21694786651491343\n",
      "glove: old, older, good, better: 0.40961181661362545\n",
      "cbow: old, older, good, better: 0.24294226160000545\n",
      "cbow_dense: old, older, good, better: 0.18656535061624072\n",
      "skipgram: old, older, good, better: 0.16584128942361212\n",
      "skipgram_dense: old, older, good, better: 0.05186729010261828\n",
      "\n",
      "w2v: large, larger, quick, quicker: 0.22521266715730429\n",
      "glove: large, larger, quick, quicker: 0.22567543578240246\n",
      "cbow: large, larger, quick, quicker: 0.04205617897711103\n",
      "cbow_dense: large, larger, quick, quicker: 0.09311372510784723\n",
      "skipgram: large, larger, quick, quicker: 0.06756714447400183\n",
      "skipgram_dense: large, larger, quick, quicker: 0.06817445995579048\n",
      "\n",
      "w2v: go, going, listen, listening: 0.23913213804946878\n",
      "glove: go, going, listen, listening: 0.42662491131551733\n",
      "cbow: go, going, listen, listening: 0.028175657728302012\n",
      "cbow_dense: go, going, listen, listening: 0.08877512926435754\n",
      "skipgram: go, going, listen, listening: 0.15185486231081524\n",
      "skipgram_dense: go, going, listen, listening: 0.010873228635317379\n",
      "\n",
      "w2v: run, running, walk, walking: 0.4228847541114353\n",
      "glove: run, running, walk, walking: 0.47095163467027384\n",
      "cbow: run, running, walk, walking: 0.06752979323171769\n",
      "cbow_dense: run, running, walk, walking: 0.13319373973395193\n",
      "skipgram: run, running, walk, walking: 0.10293102828061876\n",
      "skipgram_dense: run, running, walk, walking: 0.036897706755464\n",
      "\n",
      "w2v: run, running, think, thinking: 0.24565625385619846\n",
      "glove: run, running, think, thinking: 0.3926802350946642\n",
      "cbow: run, running, think, thinking: 0.13662853663187174\n",
      "cbow_dense: run, running, think, thinking: 0.013760378794701674\n",
      "skipgram: run, running, think, thinking: 0.06572295097742854\n",
      "skipgram_dense: run, running, think, thinking: 0.13502023716520042\n",
      "\n",
      "w2v: say, saying, sit, sitting: 0.19387733146836375\n",
      "glove: say, saying, sit, sitting: 0.33033972016602986\n",
      "cbow: say, saying, sit, sitting: 0.1255869428992714\n",
      "cbow_dense: say, saying, sit, sitting: 0.002778512915029485\n",
      "skipgram: say, saying, sit, sitting: 0.08653137863087766\n",
      "skipgram_dense: say, saying, sit, sitting: 0.031370623390230355\n",
      "\n",
      "w2v: alice, she, rabbit, he: 0.4352757480653299\n",
      "glove: alice, she, rabbit, he: 0.4769463106145698\n",
      "cbow: alice, she, rabbit, he: 0.23737374549441895\n",
      "cbow_dense: alice, she, rabbit, he: 0.22134533492778896\n",
      "skipgram: alice, she, rabbit, he: 0.1325306631609167\n",
      "skipgram_dense: alice, she, rabbit, he: 0.1196936498430301\n",
      "\n",
      "w2v: alice, her, rabbit, him: 0.4179929072878149\n",
      "glove: alice, her, rabbit, him: 0.4330083526998539\n",
      "cbow: alice, her, rabbit, him: 0.4694802520899805\n",
      "cbow_dense: alice, her, rabbit, him: 0.3085777141782657\n",
      "skipgram: alice, her, rabbit, him: 0.16623145761281516\n",
      "skipgram_dense: alice, her, rabbit, him: 0.004352950260186055\n",
      "\n",
      "w2v: alice, girl, rabbit, sir: 0.391360154857756\n",
      "glove: alice, girl, rabbit, sir: 0.3090358756196289\n",
      "cbow: alice, girl, rabbit, sir: 0.29111823565411055\n",
      "cbow_dense: alice, girl, rabbit, sir: 0.17745145079999616\n",
      "skipgram: alice, girl, rabbit, sir: 0.013468505209538413\n",
      "skipgram_dense: alice, girl, rabbit, sir: 0.16162886469339285\n",
      "\n",
      "w2v: his, her, he, she: 0.661601926269319\n",
      "glove: his, her, he, she: 0.7343965200095653\n",
      "cbow: his, her, he, she: 0.022474709476888687\n",
      "cbow_dense: his, her, he, she: 0.12253203367780965\n",
      "skipgram: his, her, he, she: 0.1928937824570437\n",
      "skipgram_dense: his, her, he, she: 0.1511302407262479\n",
      "\n",
      "w2v: long, longer, quick, quicker: 0.27729260342003326\n",
      "glove: long, longer, quick, quicker: 0.3099571305282724\n",
      "cbow: long, longer, quick, quicker: 0.09401260595447117\n",
      "cbow_dense: long, longer, quick, quicker: 0.07831883522036924\n",
      "skipgram: long, longer, quick, quicker: 0.07102139535964663\n",
      "skipgram_dense: long, longer, quick, quicker: 0.03754801662507641\n",
      "\n",
      "w2v: long, longer, small, smaller: 0.2388453687212515\n",
      "glove: long, longer, small, smaller: 0.45009013669954157\n",
      "cbow: long, longer, small, smaller: 0.19269746490298645\n",
      "cbow_dense: long, longer, small, smaller: 0.35016791043829654\n",
      "skipgram: long, longer, small, smaller: 0.21245308466171794\n",
      "skipgram_dense: long, longer, small, smaller: 0.02207475087097485\n",
      "\n",
      "w2v: long, longer, bad, worse: 0.2819685717087468\n",
      "glove: long, longer, bad, worse: 0.40626429575998596\n",
      "cbow: long, longer, bad, worse: 0.20373219592586617\n",
      "cbow_dense: long, longer, bad, worse: 0.02967005557613777\n",
      "skipgram: long, longer, bad, worse: 0.04225910785783235\n",
      "skipgram_dense: long, longer, bad, worse: 0.0009287152378468827\n",
      "\n",
      "w2v: go, going, look, looking: 0.4437767197062708\n",
      "glove: go, going, look, looking: 0.6695781772903449\n",
      "cbow: go, going, look, looking: 0.11739576262876612\n",
      "cbow_dense: go, going, look, looking: 0.014954370905789528\n",
      "skipgram: go, going, look, looking: 0.1897161720304399\n",
      "skipgram_dense: go, going, look, looking: 0.002864495321771528\n",
      "\n",
      "w2v: listen, listening, look, looking: 0.21896109979844153\n",
      "glove: listen, listening, look, looking: 0.4071841107300849\n",
      "cbow: listen, listening, look, looking: 0.23802999618462123\n",
      "cbow_dense: listen, listening, look, looking: 0.08170528413458206\n",
      "skipgram: listen, listening, look, looking: 0.012053642266116044\n",
      "skipgram_dense: listen, listening, look, looking: 0.0406596642434014\n",
      "\n",
      "w2v: swim, swimming, sit, sitting: 0.15879369259853693\n",
      "glove: swim, swimming, sit, sitting: 0.24853629762099705\n",
      "cbow: swim, swimming, sit, sitting: 0.04745686624994828\n",
      "cbow_dense: swim, swimming, sit, sitting: 0.03918166245483594\n",
      "skipgram: swim, swimming, sit, sitting: 0.0759698816019391\n",
      "skipgram_dense: swim, swimming, sit, sitting: 0.03563140413128219\n",
      "\n",
      "w2v: run, running, listen, listening: 0.09999018014940893\n",
      "glove: run, running, listen, listening: 0.15729225189857585\n",
      "cbow: run, running, listen, listening: 0.2172115315370583\n",
      "cbow_dense: run, running, listen, listening: 0.16730155288174092\n",
      "skipgram: run, running, listen, listening: 0.05989072385340193\n",
      "skipgram_dense: run, running, listen, listening: 0.052294495200113054\n",
      "\n",
      "w2v: think, thinking, read, reading: 0.3014273799197356\n",
      "glove: think, thinking, read, reading: 0.411297884485633\n",
      "cbow: think, thinking, read, reading: 0.16911559484697625\n",
      "cbow_dense: think, thinking, read, reading: 0.08962903058811725\n",
      "skipgram: think, thinking, read, reading: 0.022228808308668864\n",
      "skipgram_dense: think, thinking, read, reading: 0.03892256124563785\n",
      "\n",
      "w2v: up, down, close, far: 0.31230518986077627\n",
      "glove: up, down, close, far: 0.6523693175355175\n",
      "cbow: up, down, close, far: 0.21333871878277946\n",
      "cbow_dense: up, down, close, far: 0.007063529840594001\n",
      "skipgram: up, down, close, far: 0.1783465178663802\n",
      "skipgram_dense: up, down, close, far: 0.018702310370623847\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#w2v and glove analogy performance\n",
    "w2vanalogylist=[]\n",
    "gloveanalogylist=[]\n",
    "cbowanalogylist=[]\n",
    "cbowdenseanalogylist=[]\n",
    "skipgramanalogylist=[]\n",
    "skipgramdenseanalogylist=[]\n",
    "\n",
    "for analogy in analogy_list:\n",
    "    if(analogy[0] in tokenizer.word_index and analogy[1] in tokenizer.word_index and analogy[2] in tokenizer.word_index and analogy[3] in tokenizer.word_index):\n",
    "        try:\n",
    "            w2vanalogy=word2vec.n_similarity([analogy[0],analogy[1]],[analogy[2],analogy[3]])\n",
    "            gloveanalogy=glove.n_similarity([analogy[0],analogy[1]],[analogy[2],analogy[3]])\n",
    "            cbowanalogy=analogy_check(analogy,embed_cbow_300, tokenizer.word_index )\n",
    "            cbowdenseanalogy=analogy_check(analogy,embed_cbow_300_dense, tokenizer.word_index )\n",
    "            skipgramanalogy=analogy_check(analogy,embed_skipgram_300, tokenizer.word_index )\n",
    "            skipgramdenseanalogy=analogy_check(analogy,embed_skipgram_300_dense, tokenizer.word_index )\n",
    "            \n",
    "            print(\"w2v: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],w2vanalogy))\n",
    "            print(\"glove: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],gloveanalogy))\n",
    "            print(\"cbow: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbowanalogy))\n",
    "            print(\"cbow_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbowdenseanalogy))\n",
    "            print(\"skipgram: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgramanalogy))\n",
    "            print(\"skipgram_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgramdenseanalogy))\n",
    "            \n",
    "            \n",
    "            w2vanalogylist.append(w2vanalogy)\n",
    "            gloveanalogylist.append(gloveanalogy)\n",
    "            cbowanalogylist.append(cbowanalogy)\n",
    "            cbowdenseanalogylist.append(cbowdenseanalogy)\n",
    "            skipgramanalogylist.append(skipgramanalogy)\n",
    "            skipgramdenseanalogylist.append(skipgramdenseanalogy)\n",
    "            \n",
    "            \n",
    "            print()\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2489b2cf518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['find' 'finds' 'say' 'says']\n"
     ]
    }
   ],
   "source": [
    "#Visualize the pre-trained word embeddings\n",
    "    \n",
    "embedlist=[]\n",
    "for i in range(4):\n",
    "    embedlist.append(word2vec[w2visualize[i]])\n",
    "    #embedlist.append(embed_skipgram_300[tokenizer.word_index[w2visualize[i]]-1])\n",
    "len(embedlist)\n",
    "plt.title(\"Word2Vec\")\n",
    "draw_word_vecs(embedlist,w2visualize)    \n",
    "print(w2visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2489b385a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['find' 'finds' 'say' 'says']\n"
     ]
    }
   ],
   "source": [
    "#Visualize the pre-trained word embeddings\n",
    "    \n",
    "embedlist=[]\n",
    "for i in range(4):\n",
    "    embedlist.append(glove[w2visualize[i]])\n",
    "    #embedlist.append(embed_skipgram_300[tokenizer.word_index[w2visualize[i]]-1])\n",
    "len(embedlist)\n",
    "plt.title(\"Glove\")\n",
    "draw_word_vecs(embedlist,w2visualize)    \n",
    "print(w2visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2489b177390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['find' 'finds' 'say' 'says']\n"
     ]
    }
   ],
   "source": [
    "#Visualize the pre-trained word embeddings\n",
    "    \n",
    "embedlist=[]\n",
    "for i in range(4):\n",
    "    #embedlist.append(word2vec[analogy_list[1][i]])\n",
    "    embedlist.append(embed_cbow_300[tokenizer.word_index[w2visualize[i]]-1])\n",
    "len(embedlist)\n",
    "plt.title(\"CBOW 300\")\n",
    "draw_word_vecs(embedlist,w2visualize)    \n",
    "print(w2visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2489b1da6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['find' 'finds' 'say' 'says']\n"
     ]
    }
   ],
   "source": [
    "#Visualize the pre-trained word embeddings\n",
    "    \n",
    "embedlist=[]\n",
    "for i in range(4):\n",
    "    #embedlist.append(word2vec[analogy_list[1][i]])\n",
    "    embedlist.append(embed_cbow_300_dense[tokenizer.word_index[w2visualize[i]]-1])\n",
    "len(embedlist)\n",
    "plt.title(\"CBOW 300 Dense\")\n",
    "draw_word_vecs(embedlist,w2visualize)    \n",
    "print(w2visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEICAYAAAC3Y/QeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3Xt8FOW9x/HPLwkkhDuEW0gQUFApiIVYW+utVy5akFJbsbWiItWWarWgtNpaOfbUWi1oq7ZgtXp6CigFSwGvXI5aazV4ASIiF2sSErmDCfckz/ljJhjIhiTsZmez832/XnntzsyTmV8myXdnZ559xpxziIhIuKQEXYCIiMSfwl9EJIQU/iIiIaTwFxEJIYW/iEgIKfxFREJI4S/NipmNN7NX6lj2bTN7Pt41iTRHCn9JOGZ2rpm9amZ7zGynmf3TzM6q7/ucc//rnPtqPGqMNTP7kZltMrOPzazEzKabWVqN5b3NbLmZ7TOz98zsy8d8/01m9pG/zx41s/T4/xTSnCj8JaGYWTtgEfA7oBPQE7gTOBhgTWZmTf2/8g9giHOuHTAQGAzcUGP5bOAtoDNwGzDPzLr49Q0DpgJfAnoDffH2mUidFP6SaPoDOOdmO+cqnXP7nXPPO+dWRWpsZr8xs1fMrP2xp4TMzJnZDf4R9Xa/bYq/LNXM7vPnf2Bmk/z2af7yFWb2SzP7J7AP6GtmV5nZWjMr89f5vRrbutDMis3sFjPbamalZnaJmY00s/f9dzA/reuHds5tdM7trl4dUAWc4q+7PzAEuMPfH38DVgNj/fZXAn9yzhU453YB/wWMb+yOl3BR+EuieR+oNLPHzWyEmXWM1MjMUsxsFnAG8FXn3J461jcGyMMLz9HA1f78a4ERwJn+sksifO8VwESgLfAhsBW4GGgHXAVMN7MhNdp3BzLw3q38HJgFfAcYCpwH/NzM+tb1g5vZ5Wb2MbAd78j/j/6iTwGbnHNlNZq/48+vXv7OMcu6mVnnurYlovCXhOKc+xg4F3B44bnNzBaaWbcazVrgnQbpBHzNObfvOKv8tXNup3OuEJgBjPPnfxO43zlX7B8t3x3he//sH01XOOcOO+cW+0fozjn3f8DzeKFe7TDwS+fcYWAOkOVvo8w5VwAU4L1Y1fWz/9U/7dMf+AOwxV/UBjj2xW0P3otSpOXVz9siUgeFvyQc59xa59x451wO3vnvbLzgrnYK3lH8nc65Q/WsrqjG8w/9deE/FtXRLuI8/53Ia/4pnN3ASLyAr7bDOVfpP9/vP26psXw/XlAfl3NuPd4LxUP+rHK8dxs1tQPK6lhe/bwMkToo/CWhOefeA/6M9yJQbS3eaZdnzOzUelaRW+N5L6DEf14K5NTR7sjmq5/4vWf+BtwLdHPOdQCW4J2fbwppwMn+8wK8aw41j+QH+/Orlw8+ZtkW59yOJqpNkoDCXxKKmZ1mZj82sxx/OhfvVM1rNds552YDPwVeNLOTa6/piClm1tFfz43AXH/+k8CNZtbTzDoAt9ZTWksgHdgGVJjZCCBm3UrNbIKZdfWfDwB+AiwFcM69D7wN3GFmGWY2Bu/00d/8b38CuMbMBvjXSG7He8EUqVNa/U1E4qoMOBu42Q/l3XhdP6cc29A597iZtQSWmdkFdazv78BKoD1eIP7Jnz8L79z6KuBj4AHgQqCy1hq8bZWZ2Q14LxrpeF0zFzb+x6vT54FfmlkbvBeYp4Cf1Vh+mV//LqAQ+IZzbptf27Nmdg+wHGiF96JwRwxrkyRkupmLJCszc0A/59yGBrQdAfzBOXdS01cmEjyd9pFQMrNWfh/8NDPriXekvCDoukTiReEvYWV4n4LdhffJ2bV4ffNFQkGnfUREQkhH/iIiIZSwvX2ysrJc7969gy5DRKRZWbly5XbnXJf62iVs+Pfu3Zv8/PygyxARaVbM7MOGtNNpHxGREFL4i4iEkMJfRCSEEvacv4hIYx0+fJji4mIOHDgQdClNLiMjg5ycHFq0aHFC36/wF5GkUVxcTNu2benduzdmTTXgavCcc+zYsYPi4mL69OlzQuvQaR8RSRoHDhygc+fOSR38AGZG586do3qHo/AXkaSS7MFfLdqfU+EvzUZl5d6gSxBJGgp/aTY2bfopFRW6M6E0gllsvxrggQce4PTTT6djx47cfXekW0PXbfz48cybN+9EftJG0wVfaTYqK8soKBjLoEGLSElpGXQ5IhE99NBDPPPMMyd8ITZedOQvzUarVv3ZtesF1q27Bueqgi5HpJbrrruOTZs2MWrUKKZPn86kSZMA74j+hhtu4JxzzqFv375Hju6dc0yaNIkBAwZw0UUXsXXr1rjVqvCXZiMzsz8AW7b8hU2bfhJwNSK1/eEPfyA7O5vly5fTsWPHo5aVlpbyyiuvsGjRIqZOnQrAggULWLduHatXr2bWrFm8+uqrcatV4S/NRqtW/Y88Lyq6h+Li+wOsRqRxLrnkElJSUhgwYABbtmwB4KWXXmLcuHGkpqaSnZ3NF7/4xbjVE5PwN7NHzWyrma2pY7mZ2QNmtsHMVpnZkFhsV8KlVauTj5resOEmtm59MqBqRBonPT39yPOaN9EKqmtqrI78/wwMP87yEUA//2si8HCMtishkpraivT0XjXmONauvYJdu5YHVpNINM4//3zmzJlDZWUlpaWlLF8ev7/lmIS/c+4lYOdxmowGnnCe14AOZtYjFtuWcKk+71/NuUOsWXMJ5eWrAqpIEppzsf2KsTFjxtCvXz8GDRrE9ddfzwUXXBDzbdQlZvfwNbPewCLn3MAIyxYBdzvnXvGnlwK3Oufyj2k3Ee+dAb169Rr64YcNuieBhMj77/+AkpKHas1v2TKbIUP+RUZGrwjfJWGxdu1aTj/99KDLiJtIP6+ZrXTO5dX3vfHq5x/ppFatVx3n3ExgJkBeXp7uLC+1HHvkD3DSST+nZcse7N37rsJfpIHiFf7FQG6N6RygJE7bliRS3eOnTZtPU17+FgAVFTvp0+fOIMsSaXbi1dVzIfBdv9fPZ4E9zrnSOG1bkkhmZn8yMvowePCLdOz4ZQBKSx/h0KH4fThGJBnEqqvnbOBfwKlmVmxm15jZdWZ2nd9kCbAJ2ADMAr4fi+1K+KSnn8TAgQto0aITvXp5H5SpqjrA5s2/C7gykeYlJqd9nHPj6lnugB/EYlsSbikpabRpMxiADh2+SNu2eZSV5bN58+/Jzb2FtLS2AVco0jzoE77SbJnZkaP/iordlJbODLgikeZD4S/NWlbWJUcuAhcV/ZaqqoMBVySJJIARnZvNkM4Kf2nWzFLp1esWAA4dKuGjj/4n4Iok7B566CGWLFnCrl27jgzglogU/tLsdev2HVq27Al4A745VxlwRRJWsRzSeerUqQwYMIAzzjiDyZMnx7xWhb80eykp6eTm3gzA/v3r2bZtQcAVSVjFakjnnTt3smDBAgoKCli1ahW33357zGtV+EtS6NHjWtLSvH+2wsK7idWwJSKx0pghndu1a0dGRgYTJkxg/vz5ZGZmxrwehb8khbS0tvTs6b3FLi9fya5dSwOuSORojRnSOS0tjddff52xY8fy9NNPM3z48QZNPjEKf0kaPXv+kJSUVoB39C+S6Ooa0rm8vJw9e/YwcuRIZsyYwdtvvx3zbesG7pI0WrbsQo8eE9i8+Xfs3r2Ujz9+g3btzgq6LAlQop/9GzNmDMuWLWPQoEH079//yJDOZWVljB49mgMHDuCcY/r06THfdsyGdI61vLw8l5+fX39DkRoOHPiQ1147GagkK2ssAwfGp8+0JAYN6dzwIZ112keSSkbGSXTrdjkA27fPZ9++dQFXJJKYFP6SdHJzb/GfOQoLfxNoLSKJSuEvSadNm4F07vw1ALZseYKDBzcHXJFI4lH4S1KqHvDNucMUFcX+YplIc6fwl6TUvv05tG9/HgAlJX/g8OGdAVckklgU/pK0PrnZy142b34w4GpEEov6+UvS6tRpBK1bn8HevasoLr6f3NybSU1tHXRZEkd2ZwPHYW4gd0dido0/ETryl6R19M1edlBa+mjAFYkkDoW/JLUuXS4lI6MPAEVF91JVdTjgiiSZ7d27l4suuojBgwczcOBA5s6dy7Rp0zjrrLMYOHAgEydOxDnHxo0bGTJkyJHvW79+PUOHDo1rrQp/SWopKWnk5k4B4ODBQrZunRNwRZLMnn32WbKzs3nnnXdYs2YNw4cPZ9KkSbzxxhusWbOG/fv3s2jRIk4++WTat29/ZMyexx57jPHjx8e1VoW/JL3u3cfTokVXAAoLf41zVQFXJMlq0KBBvPjii9x66628/PLLtG/fnuXLl3P22WczaNAgli1bRkFBAQATJkzgscceo7Kykrlz53L55ZfHtVaFvyS91NRW5OT8CIB9+wrYsWNxwBVJsurfvz8rV65k0KBB/OQnP2HatGl8//vfZ968eaxevZprr72WAwcOADB27FieeeYZFi1axNChQ+ncuXNca1X4SyhkZ19PampbAAoLf6WbvUiTKCkpITMzk+985ztMnjyZN998E4CsrCzKy8uPujl7RkYGw4YN4/rrr+eqq66Ke63q6imh0KJFB7Kzr6eo6B4+/vhf7NnzCh06nBd0WdLE4t01c/Xq1UyZMoWUlBRatGjBww8/zNNPP82gQYPo3bs3Z5119BDj3/72t5k/fz5f/epX41onKPwlRHJyfkRx8QycO0Rh4d0Kf4m5YcOGMWzYsKPm5eXlcdddd0Vs/8orr3D11VeTmpoaj/KOovCX0EhP70H37uMpLZ3Jzp1LKC9fRZs2ZwRdloTUmDFj2LhxI8uWLQtk+zrnL6Hidfv0/ux1q0cJ0oIFC1i1ahVZWVmBbF/hL6GSmXkKXbp8A4CtW+eyf/+mgCsSCYbCX0KnesgHqKKo6N5AaxEJisJfQqdt20/TsaN3Ua609FEOHdoScEUi8afwl1D65GYvBykuvj/gakTiT719JJQ6dLiAtm3Ppqzs32ze/CC9et1KWlr7oMuSGFuxIrZDOl94YfJ8OFBH/hJKNYd7rqz8mJKSPwZckUh8KfwltLKyRpGZeRoAxcXTqaw8EHBF0tzFYkjnqVOnMmDAAM444wwmT57cZLUq/CW0zFLIzb0VgEOHPmLLlicCrkiau2iHdN65cycLFiygoKCAVatWcfvttzdZrQp/CbVu3S4nPT0HgMLCe3CuMuCKpDmLdkjndu3akZGRwYQJE5g/fz6ZmZlNVqvCX0ItJaUlOTk/BuDAgY1s2/a3gCuS5izaIZ3T0tJ4/fXXGTt2LE8//TTDhw9vslpjEv5mNtzM1pnZBjObGmH5eDPbZmZv+18TYrFdkVjo0WMCaWmdAG/IBw33LCcq2iGdy8vL2bNnDyNHjmTGjBlHTgs1hai7eppZKvAg8BWgGHjDzBY65949pulc59ykaLcnEmtpaW3o2fOHfPjhnZSXv8WuXS/QqVP8h9iV2It318xoh3QuKytj9OjRHDhwAOcc06dPb7JaY9HP/zPABufcJgAzmwOMBo4Nf5GElZPzQ4qKfkNV1T4KC3+l8JcTEu2Qzj169OD1119v8johNqd9egJFNaaL/XnHGmtmq8xsnpnlRlqRmU00s3wzy9+2bVsMShNpmBYtOpOdPRGA3btXsGfPawFXJMluzJgxPPHEE9x4442BbD8W4R/pI3THvtf6B9DbOXcG8CLweKQVOedmOufynHN5Xbp0iUFpIg2Xk3MzZt6b4aKiXwdcjSS7ZBjSuRioeSSfA5TUbOCc2+GcO+hPzgKGxmC7IjGVkZFLt27fAWD79qfZu3dtwBXJiQjLBftof85YhP8bQD8z62NmLYHLgIU1G5hZjxqTowD9V0lCys295cjzoqJ7AqxETkRGRgY7duxI+hcA5xw7duwgIyPjhNcR9QVf51yFmU0CngNSgUedcwVmNg3Id84tBG4ws1FABbATGB/tdkWaQuvWp5OVdQnbtz/Nli1/oXfvaWRkRLxEJQkoJyeH4uJiwnDNMCMjg5ycnBP+fkvUV8i8vDyXn58fdBkSQnv2vMZbb30O8G76fsopTdfdTiTWzGylcy6vvnb6hK/IMdq3/ywdOlwIQEnJTA4f3hFsQSJNQOEvEkH1cM9VVfvYvPn3AVcjEnsKf5EIOnb8Km3anAlAcfEDVFbuDbgikdhS+ItEUPNmLxUVOyktfSTgikRiS+EvUoesrLFkZJwMQFHRfVRVHQq4IpHYUfiL1CElJY1evaYAcPBgEVu2/DXgikRiR+Evchzdul1Jy5bdAW/IB+eqAq5IJDYU/iLHkZqaQU7OTQDs2/ce27cvrOc7RJoHhb9IPbKzryM1tT0AhYW/SvqhAyQcFP4i9UhLa0fPnt8HoKzsdXbv/r+AKxKJnsJfpAFycm7ELB3wbvUo0twp/EUaoGXLbvTocTUAu3Y9R1nZWwFXJBIdhb9IA+XmTqb6X6awUDd7keZN4S/SQK1a9aVr128BsG3bU+zbtyHgikROnMJfpBF69brVf1ZFUdG9gdYiEg2Fv0gjtGkzmE6dRgDw0UePcfBgacAViZwYhb9II1UP+ObcIYqL7w+miPJy2LMnmG1LUlD4izRS+/bn0a6dd6evkpKHqaiIcwhXVMBll8F550FxcXy3LUlD4S/SSDWHe66s/JjNmx+KbwGzZsHixbB6NXz2s/DOO/HdviQFhb/ICejc+WIyMz8FQHHxDCor98dv49deC9dd5z3fvNl7B/D88/HbviQFhb/ICTBLOdLz5/DhrXz00Z/jt/G0NHjoIbjb/6RxWRlcdBE89lj8apBmT+EvcoK6dr2M9PReABQV/Yaqqor4bdwMbr0V/vpXaNnSuw5w9dVwxx2ggeekART+IicoJaWF/6lfOHDgA7Zteyr+RYwbBy+8AB06eNPTpsFVV8Eh3XVMjk/hLxKFHj2uoUWLLMAb8C2Q4Z7PPx9efRV69/amH38cRo5UV1A5LoW/SBRSUzPp2fMGAPbuXcXOnc8GU8jpp8O//gVDh3rTS5fCuedCUVEw9UjCU/iLRKlnzx+QktIaCHi45+7dYcUKuPhib3rNGnUFlTop/EWi1KJFJ7KzvwfAnj0vsWfPq8EV06YNLFgA11/vTZeUqCuoRKTwF4mBnJybMGsBJMBwz2lp8OCD8Gu/jrIy7xrAo48GW5ckFIW/SAxkZOTQrdsVAOzYsZC9ewuCLcgMbrkFZs/2uoJWVsI118DPf66uoAIo/EViJjd3CmAAlJYmyAeuLrvM6wrasaM3/V//BePHqyuoKPxFYqV169Po1eunfOpT8zj55AS609exXUGfeAJGjFBX0JBT+IvEUN++d9Gly1jMUoMu5WinnQavvQZ5ed70smXqChpyCn+RsOjWLXJX0LffDrQsCYbCXyRMWreO3BX0ueeCrUviTuEvEjbVXUHvucebLi/3RgX905+CrUviSuEvEkZmMGUKzJnzSVfQCRPUFTREYhL+ZjbczNaZ2QYzmxphebqZzfWX/9vMesdiuyISpW99C1588eiuoFdeqa6gIRB1+JvXreFBYAQwABhnZgOOaXYNsMs5dwowHUigfnAiIXfeeV5X0D59vOn/+R91BQ2BWBz5fwbY4Jzb5Jw7BMwBRh/TZjTwuP98HvAlM7MYbFtEYuG007xRQdUVNDTSYrCOnkDNv5Bi4Oy62jjnKsxsD9AZ2F6zkZlNBCYCdOzekftevY9KV0llVeVRjxVVFbXmHbUswvzKqrqX1bu+CMs237yZFqktYrD7RBJEdVfQcePgH//4pCvo4sVw5plBVycxFovwj3QEf+wVo4a0wTk3E5gJYNnmJr8wOfrqmkilq6QFCn9JMtVdQW+4wbtPcHVX0HnzYNiwoKuTGIpF+BcDuTWmc4CSOtoUm1ka0B7YeaIbNIzUlFRSLZXUlFTSUtKOPK/5mJaSVmteTNpbKhbx9UwkCaSmwu9/710DmDLlk66gf/yjNzicJIVYhP8bQD8z6wNsBi4DLj+mzULgSuBfwDeAZa6e+90N7j6Y5bcsjxjCulwg0sTMYPJk6NULrrjC6/0zYQL85z/efYL1P9jsRX3B1zlXAUwCngPWAk865wrMbJqZjfKb/QnobGYbgJuBWt1Bj5WWkkbHVh1pl96O1i1bk5GWQVpKmoJfJJ6++c2ju4LedZe6giYJC+SG0w2Ql5fn8vPzgy5DRADWrfO6f37wgTf9hS/A/PnQoUOwdUktZrbSOZdXXzt9wldE6nfqqV5X0LPO8qaXL/e6ghYWBluXnDCFv4g0TLduXuiP8s/mFhR4XUHfeivYuuSEKPxFpOFat/ZO9/zgB950aal3s5hnnw22Lmk0hb+INE5qKvzud3Dvvd50ebl3j4BHHgm2LmkUhb+INJ4Z/PjH8OSTkJ7ujQp67bVw++0aFbSZUPiLyIm79FKvK2inTt70L38J3/2uuoI2Awp/EYnOuecePSroX/4Cw4fD7t3B1iXHpfAXkeideqp3g/jPfMabVlfQhKfwF5HY6NrVC/3R/oju6gqa0BT+IhI7mZnwt7/BpEnedHVX0GeeCbYuqUXhLyKxlZoKDzwA993nTZeXw9e+BrNmBVuXHEXhLyKxZwY333x0V9CJE9UVNIEo/EWk6Vx6KSxdqq6gCUjhLyJN6/Of9waF69vXm1ZX0ISg8BeRpte/v/cCcLZ/e+/ly70XhQ8/DLauEFP4i0h8dO0Ky5Z90hX03Xe9rqBvvhlsXSGl8BeR+KnuCvrDH3rTH32krqABUfiLSHylpsL998Nvf+v1Ctq71+sKOnNm0JWFisJfROLPDG666eiuoN/7Htx2m7qCxonCX0SC841veNcBOnf2pv/7v+GKK+DgwWDrCgGFv4gE65xzvFFBq7uC/u//el1Bd+0Ktq4kp/AXkeD17++NCup3BXUrVnijgqoraJNR+ItIYujSBZYt44OvTGQQq5nz7iCqzv6cuoI2EYW/iCSOzEx+0f1hChjIOOYwdMtilpxzF27xkqArSzoKfxFJKEOGphy5/vs2n+aig/M5/+J2vDxlYbCFJRmFv4gklBtvhE2b4Be/gLatDgPwCudy/r2jGHnKOt56U11BY0HhLyIJp107uOMO2FTYgpsvKyGdAwA8s/FUhgw1vnVpJe+/H3CRzZzCX0QSVlYW3Dc7mw0vlXJt2zmkUgHAk/NSGTDAce21UFQUcJHNlMJfRBJeznl9mLnxS7w7+HIuYzYAlZXGI49Av37efWO2bQu4yGZG4S8izUOXLvR/9c/MHvMUb3EmI1kMeB8Gnj7d+4zYHXfAxx8HXGczofAXkeYjMxOeeoozb7yQxVzMy5zLeSn/BLxbBU+bBn17V3LfXfvZvz/gWhOcwl9EmpfUVJgxA6ZP51x7lf+rOpcldhFn5m4HYMeuVCb/rBX9+nkDhR4+HHC9CUrhLyLN049+BPPmYRkZjHBLWFnUlbmXzKZ/ZjEAmzd7A4UOGABz5kBVVcD1JhiFv4g0X1//+pFRQVNwfPPpyynY15tHuIactFIANmyAceNgyBBYvFgjRldT+ItI8/a5z3n3B+7TB4A0KrmGR1lf0YffjnyBrCyv2TvvwMUXw3nnwcsvB1hvglD4i0jz5Zx3M/jbbqvV4T+Dg9y09GtsemEjd94Jbdt68//5T+/OkSNGwFtvHb26hQuhuDhOtQcsqvA3s05m9oKZrfcfO9bRrtLM3va/NECHiMRORQXs3u09HuvgQdpO/h4//5lj0yb48Y+9G4cBPPusdyroW9+Cdeu8ee++CxdcAIWF8Ss/KNEe+U8Fljrn+gFL/elI9jvnzvS/RkW5TRERjxl85Svw/PPw9tveXcDS0o5us3Qp/OUvZGXBvfd61wAmTvQ6DYF3J8lPfQomTIAPPvDGFbrgAvjPf+L+08SVuSiufpjZOuBC51ypmfUAVjjnTo3Qrtw516Yx687Ly3P5+fknXJuIhFRRkXeD+JkzoazMm5eVBe+998ntIoH1670Phc2eHXk1ubneGaWTT45DzTFkZiudc3n1tYv2yL+bc64UwH/sWke7DDPLN7PXzOySulZmZhP9dvnb9FltETkRubneIX5REdxzD/TsCdu3w5QpRzXr1w/++lfvDcNFF9VeTVGR9w5g/fo41R1n9Ya/mb1oZmsifI1uxHZ6+a9ElwMzzCzia6lzbqZzLs85l9elS5dGrF5E5Bjt23uBv2kTPP44rFwJK1bUajZ4sDeMdIcOtVexebP3AvDee01fbrzVG/7OuS875wZG+Po7sMU/3YP/uLWOdZT4j5uAFcCnY/YTiIgcT8uW8N3veof4OTm1Fj/8MAwb5l0zjqS0FC68EAoKmrbMeIv2tM9C4Er/+ZXA349tYGYdzSzdf54FfB54N8rtiog0jhmcckqt2ddfDzt2eNeFf/Mb7wNhp57qNa+2ZQt84QuwalUc621i0V7w7Qw8CfQCCoFLnXM7zSwPuM45N8HMzgH+CFThvdjMcM79qb5164KviASprMz7YNibb37ytXWr10X0zDODrq5uDb3gG1X4NyWFv4gkmv37vQ+B9esXdCV1i1dvHxGR0GjVKrGDvzEU/iIiIaTwFxEJIYW/iEgIKfxFREJI4S8iEkIKfxGREFL4i4iEkMJfRCSEFP4iIiGk8BcRCSGFv4hICCn8RURCSOEvIhJCCn8RkRBS+IuIhJDCX0QkhBT+IiIhpPAXEQkhhb+ISAgp/EVEQkjhLyISQgp/EZEQUviLiISQwl9EJIQU/iIiIaTwFxEJIYW/iEgIKfxFREJI4S8iEkIKfxGREFL4i4iEkMJfRCSEFP4iIiGk8BcRCSGFv4hICCn8RURCKKrwN7NLzazAzKrMLO847Yab2Toz22BmU6PZpoiIRC/aI/81wNeBl+pqYGapwIPACGAAMM7MBkS5XRERiUJaNN/snFsLYGbHa/YZYINzbpPfdg4wGng3mm2LiMiJi8c5/55AUY3pYn9eLWY20czyzSx/27ZtcShNRCSc6j3yN7MXge4RFt3mnPt7A7YR6W2Bi9TQOTcTmAmQl5cXsY2IiESv3vB3zn05ym0UA7k1pnOAkijXKSIiUYjHaZ83gH5m1sfMWgKXAQvjsF0REalDtF09x5j8YjY3AAAEB0lEQVRZMfA5YLGZPefPzzazJQDOuQpgEvAcsBZ40jlXEF3ZIiISjWh7+ywAFkSYXwKMrDG9BFgSzbZERCR29AlfEZEQUviLiISQwl9EJIQU/iIiIaTwFxEJIYW/iEgIKfxFREJI4S8iEkIKfxGREFL4i4iEkMJfRCSEFP4iIiFkziXmPVPMbBvwYRw3mQVsj+P2mgvtl8i0XyLTfqkt3vvkJOdcl/oaJWz4x5uZ5Tvn8oKuI9Fov0Sm/RKZ9kttibpPdNpHRCSEFP4iIiGk8P/EzKALSFDaL5Fpv0Sm/VJbQu4TnfMXEQkhHfmLiISQwl9EJIRCG/5mdqmZFZhZlZnV2Q3LzIab2Toz22BmU+NZYxDMrJOZvWBm6/3HjnW0qzSzt/2vhfGuM17q+/2bWbqZzfWX/9vMese/yvhqwD4Zb2bbavx9TAiizngzs0fNbKuZraljuZnZA/5+W2VmQ+JdY02hDX9gDfB14KW6GphZKvAgMAIYAIwzswHxKS8wU4Glzrl+wFJ/OpL9zrkz/a9R8Ssvfhr4+78G2OWcOwWYDvw6vlXGVyP+J+bW+Pt4JK5FBufPwPDjLB8B9PO/JgIPx6GmOoU2/J1za51z6+pp9hlgg3Nuk3PuEDAHGN301QVqNPC4//xx4JIAawlaQ37/NffXPOBLZmZxrDHewvg/0SDOuZeAncdpMhp4wnleAzqYWY/4VFdbaMO/gXoCRTWmi/15yaybc64UwH/sWke7DDPLN7PXzCxZXyAa8vs/0sY5VwHsATrHpbpgNPR/Yqx/amOemeXGp7SEl1B5khbUhuPBzF4EukdYdJtz7u8NWUWEec2+b+zx9ksjVtPLOVdiZn2BZWa22jm3MTYVJoyG/P6T8m/kOBry8/4DmO2cO2hm1+G9M/pik1eW+BLqbyWpw9859+UoV1EM1DxqyQFKolxn4I63X8xsi5n1cM6V+m9Jt9axjhL/cZOZrQA+DSRb+Dfk91/dptjM0oD2HP+tf3NX7z5xzu2oMTmLJL8O0ggJlSc67XN8bwD9zKyPmbUELgOStmeLbyFwpf/8SqDWOyQz62hm6f7zLODzwLtxqzB+GvL7r7m/vgEsc8n9ycl698kx57FHAWvjWF8iWwh81+/181lgT/Up1kA450L5BYzBeyU+CGwBnvPnZwNLarQbCbyPd1R7W9B1x2G/dMbr5bPef+zkz88DHvGfnwOsBt7xH68Juu4m3B+1fv/ANGCU/zwDeArYALwO9A265gTYJ78CCvy/j+XAaUHXHKf9MhsoBQ772XINcB1wnb/c8HpKbfT/b/KCrFfDO4iIhJBO+4iIhJDCX0QkhBT+IiIhpPAXEQkhhb+ISAgp/EVEQkjhLyISQv8PoZ74g32tUh4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2489b1776a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['find' 'finds' 'say' 'says']\n"
     ]
    }
   ],
   "source": [
    "#Visualize the pre-trained word embeddings\n",
    "    \n",
    "embedlist=[]\n",
    "for i in range(4):\n",
    "    #embedlist.append(word2vec[analogy_list[1][i]])\n",
    "    embedlist.append(embed_skipgram_300[tokenizer.word_index[w2visualize[i]]-1])\n",
    "len(embedlist)\n",
    "plt.title(\"Skipgram 300\")\n",
    "draw_word_vecs(embedlist,w2visualize)    \n",
    "print(w2visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2489b252a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['find' 'finds' 'say' 'says']\n"
     ]
    }
   ],
   "source": [
    "#Visualize the pre-trained word embeddings\n",
    "    \n",
    "embedlist=[]\n",
    "for i in range(4):\n",
    "    #embedlist.append(word2vec[analogy_list[1][i]])\n",
    "    embedlist.append(embed_skipgram_300_dense[tokenizer.word_index[w2visualize[i]]-1])\n",
    "len(embedlist)\n",
    "plt.title(\"Skipgram 300 Dense\")\n",
    "draw_word_vecs(embedlist,w2visualize)    \n",
    "print(w2visualize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "From the visualization it is clear that the pretrained word embeddings outperform the skipgram and CBOW implementations as done in this assignment. \n",
    "Glove and word2vec have the vectors which one would expect to be similar reasonably parrallel to each other.\n",
    "Where for example the CBOW300 implementation has all vectors pointing in completely different directions thus showing randomness. It seems like training of CBOW300 was cut off to fast and should have been trained longer. \n",
    "Skip gram does perform resoanbly well with similar words being close to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison performance with your own trained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['happy', 'unhappy', 'pleasant', 'unpleasant'], dtype='<U10'),\n",
       " array(['sudden', 'suddenly', 'usual', 'usually'], dtype='<U8'),\n",
       " array(['bad', 'worse', 'good', 'better'], dtype='<U6'),\n",
       " array(['go', 'going', 'look', 'looking'], dtype='<U7'),\n",
       " array(['he', 'she', 'his', 'her'], dtype='<U3'),\n",
       " array(['brother', 'sister', 'his', 'her'], dtype='<U7'),\n",
       " array(['listen', 'listening', 'look', 'looking'], dtype='<U9'),\n",
       " array(['saying', 'said', 'thinking', 'thought'], dtype='<U8'),\n",
       " array(['bird', 'birds', 'cat', 'cats'], dtype='<U5'),\n",
       " array(['good', 'better', 'old', 'older'], dtype='<U6'),\n",
       " array(['good', 'better', 'quick', 'quicker'], dtype='<U7'),\n",
       " array(['large', 'largest', 'good', 'best'], dtype='<U7'),\n",
       " array(['happy', 'unhappy', 'comfortable', 'uncomfortable'], dtype='<U13'),\n",
       " array(['falling', 'fell', 'knowing', 'knew'], dtype='<U7'),\n",
       " array(['walk', 'walking', 'think', 'thinking'], dtype='<U8'),\n",
       " array(['child', 'children', 'cat', 'cats'], dtype='<U8'),\n",
       " array(['dog', 'dogs', 'eye', 'eyes'], dtype='<U4'),\n",
       " array(['hand', 'hands', 'rat', 'rats'], dtype='<U5'),\n",
       " array(['eat', 'eats', 'find', 'finds'], dtype='<U5'),\n",
       " array(['find', 'finds', 'say', 'says'], dtype='<U5'),\n",
       " array(['old', 'older', 'good', 'better'], dtype='<U6'),\n",
       " array(['large', 'larger', 'quick', 'quicker'], dtype='<U7'),\n",
       " array(['go', 'going', 'listen', 'listening'], dtype='<U9'),\n",
       " array(['run', 'running', 'walk', 'walking'], dtype='<U7'),\n",
       " array(['run', 'running', 'think', 'thinking'], dtype='<U8'),\n",
       " array(['pleasant', 'pleasanter', 'large', 'larger'], dtype='<U10'),\n",
       " array(['say', 'saying', 'sit', 'sitting'], dtype='<U7'),\n",
       " array(['wrong', 'true', 'happy', 'unhappy'], dtype='<U7'),\n",
       " array(['alice', 'she', 'rabbit', 'he'], dtype='<U6'),\n",
       " array(['alice', 'her', 'rabbit', 'him'], dtype='<U6'),\n",
       " array(['alice', 'girl', 'rabbit', 'sir'], dtype='<U6'),\n",
       " array(['uneasily', 'easily', 'sudden', 'suddenly'], dtype='<U8'),\n",
       " array(['uneasily', 'easily', 'calmly', 'angrily', ''], dtype='<U8'),\n",
       " array(['dinah', 'cat', 'alice', 'girl'], dtype='<U5'),\n",
       " array(['never', 'always', 'happy', 'unhappy'], dtype='<U7'),\n",
       " array(['his', 'her', 'he', 'she'], dtype='<U3'),\n",
       " array(['long', 'longer', 'quick', 'quicker'], dtype='<U7'),\n",
       " array(['long', 'longer', 'small', 'smaller'], dtype='<U7'),\n",
       " array(['long', 'longer', 'bad', 'worse'], dtype='<U6'),\n",
       " array(['go', 'going', 'look', 'looking'], dtype='<U7'),\n",
       " array(['listen', 'listening', 'look', 'looking'], dtype='<U9'),\n",
       " array(['swim', 'swimming', 'sit', 'sitting'], dtype='<U8'),\n",
       " array(['run', 'running', 'listen', 'listening'], dtype='<U9'),\n",
       " array(['think', 'thinking', 'read', 'reading'], dtype='<U8'),\n",
       " array(['up', 'down', 'close', 'far'], dtype='<U5'),\n",
       " array(['queen', 'woman', 'king', 'man'], dtype='<U5'),\n",
       " array(['boy', 'girl', 'man', 'woman'], dtype='<U5')]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy_list\n",
    "#print(len(analogy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #47"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
