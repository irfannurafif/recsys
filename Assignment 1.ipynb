{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "Irfan Nur Afif\n",
    "\n",
    "Timothy Aerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(13) #TODO Check if this is used for sgd\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Reshape, Lambda\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.preprocessing import sequence\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors as nn\n",
    "from matplotlib import pylab\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT Modify the lines in this cell\n",
    "path = 'alice.txt'#'analogy_alice.txt'\n",
    "corpus = open(path).readlines()[0:700]\n",
    "\n",
    "corpus = [sentence for sentence in corpus if sentence.count(\" \") >= 2]\n",
    "\n",
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'+\"'\")\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "corpus = tokenizer.texts_to_sequences(corpus)\n",
    "nb_samples = sum(len(s) for s in corpus)\n",
    "V = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Is this something they need to change?\n",
    "dim = 100\n",
    "window_size = 2 #use this window size for Skipgram, CBOW, and the model with the additional hidden layer\n",
    "window_size_corpus = 4 #use this window size for the co-occurrence matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "### Co-occurrence Matrix\n",
    "Use the provided code to load the \"Alice in Wonderland\" text document. \n",
    "1. Implement the word-word co-occurrence matrix for “Alice in Wonderland”\n",
    "2. Normalize the words such that every value lies within a range of 0 and 1\n",
    "3. Compute the cosine distance between the given words:\n",
    "    - Alice \n",
    "    - Dinah\n",
    "    - Rabbit\n",
    "4. List the 5 closest words to 'Alice'. Discuss the results.\n",
    "5. Discuss what the main drawbacks are of a term-term co-occurence matrix solutions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 \n",
    "### Implement the word-word co-occurrence matrix for “Alice in Wonderland”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 0. 8. ... 0. 0. 0.]\n",
      " [1. 8. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse, numpy\n",
    "\n",
    "\n",
    "vocabulary={}\n",
    "data=[]\n",
    "row=[]\n",
    "col=[]\n",
    "for sentence in corpus:\n",
    "    for pos,word in enumerate(sentence):\n",
    "        i=vocabulary.setdefault(word,len(vocabulary))\n",
    "        start=max(0,pos-window_size_corpus)\n",
    "        end=min(len(sentence),pos+window_size_corpus+1)\n",
    "        for pos2 in range(start,end):\n",
    "            if pos2==pos: \n",
    "                continue\n",
    "            j=vocabulary.setdefault(sentence[pos2],len(vocabulary))\n",
    "            if(j!=i):\n",
    "                data.append(1.); row.append(i); col.append(j);\n",
    "            \n",
    "cooccurrence_matrix=scipy.sparse.coo_matrix((data,(row,col)))\n",
    "#print(cooccurrence_matrix.T * cooccurrence_matrix)\n",
    "print(cooccurrence_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 \n",
    "### Normalize the words such that every value lies within a range of 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.0625     0.0625     ... 0.         0.         0.        ]\n",
      " [0.00105485 0.         0.00843882 ... 0.         0.         0.        ]\n",
      " [0.00381679 0.03053435 0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#We use TF for normalization\n",
    "\n",
    "cooc=cooccurrence_matrix.toarray()\n",
    "tf_cooc=numpy.zeros((V-1, V-1))\n",
    "for i, sentence in enumerate(cooc):\n",
    "    sumf=0\n",
    "    for wordf in sentence:\n",
    "        sumf+=wordf\n",
    "    for j,wordf in enumerate(sentence):\n",
    "        if(sumf>0):\n",
    "            tf_cooc[i][j]=cooc[i][j]/sumf\n",
    "        else:\n",
    "            continue\n",
    "print(tf_cooc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 \n",
    "### Compute the cosine distance between the given words: Alice, Dinah, Rabbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "87\n",
      "63\n",
      "Cosine similarity of Alice and Dinah: 0.48967327730053256\n",
      "Cosine similarity of Alice and Rabbit: 0.08862667920586557\n",
      "Cosine similarity of Dinah and Rabbit: 0.13969968905677818\n"
     ]
    }
   ],
   "source": [
    "#find cosine similarity to Alice, Dinah and Rabbit\n",
    "import math\n",
    "def cos_sim(a,b):\n",
    "    return cosine_similarity([a],[b])[0][0]\n",
    "    #sum_c=0;len_c=len(a);sum_as=0;sum_bs=0;\n",
    "    #for ii in range(len_c):\n",
    "    #    sum_c=sum_c+(a[ii]*b[ii])\n",
    "    #    sum_as=sum_as+(a[ii]*a[ii])\n",
    "    #    sum_bs=sum_bs+(b[ii]*b[ii])\n",
    "    #if(sum_as==0 and sum_bs==0):\n",
    "    #    return 1\n",
    "    #else:\n",
    "    #    return sum_c/(math.sqrt(sum_as)*(math.sqrt(sum_bs)))\n",
    "\n",
    "\n",
    "print(tokenizer.word_index['alice'])  #11-1=10, since word_index starting at index 1\n",
    "print(tokenizer.word_index['dinah'])  #87-1=86\n",
    "print(tokenizer.word_index['rabbit']) #63-1=62\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#print(cosine_similarity(tf_cooc[10:11], tf_cooc[86:87]))\n",
    "print(\"Cosine similarity of Alice and Dinah: {}\".format(cos_sim(tf_cooc[10],tf_cooc[86])))                 \n",
    "#print(cosine_similarity(tf_cooc[10:11], tf_cooc[62:63]))\n",
    "print(\"Cosine similarity of Alice and Rabbit: {}\".format(cos_sim(tf_cooc[10],tf_cooc[62])))\n",
    "#print(cosine_similarity(tf_cooc[86:87], tf_cooc[62:63]))\n",
    "print(\"Cosine similarity of Dinah and Rabbit: {}\".format(cos_sim(tf_cooc[62],tf_cooc[86])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4\n",
    "### List the 5 closest words to 'Alice'. Discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closest word= t, had, question, say, to\n",
      "Cosine similarity of Alice and t: 0.7033898864296415\n",
      "Cosine similarity of Alice and had: 0.6995182846911174\n",
      "Cosine similarity of Alice and question: 0.6726422527548841\n",
      "Cosine similarity of Alice and say: 0.6685274041392557\n",
      "Cosine similarity of Alice and to: 0.6544770424322105\n"
     ]
    }
   ],
   "source": [
    "#find the closest words to Alice\n",
    "maxid=0\n",
    "maxval=0\n",
    "simi=np.zeros(V-1)\n",
    "for i in range(V-1):\n",
    "    simi[i]=cosine_similarity(tf_cooc[10:11], tf_cooc[i:i+1])[0][0]\n",
    "indices=simi.argsort()[-6:][::-1]\n",
    "print(\"closest word= {}, {}, {}, {}, {}\".format(list(tokenizer.word_index)[indices[1]],list(tokenizer.word_index)[indices[2]],list(tokenizer.word_index)[indices[3]],list(tokenizer.word_index)[indices[4]],list(tokenizer.word_index)[indices[5]]))            \n",
    "for i in range(1,6):\n",
    "    print(\"Cosine similarity of Alice and {}: {}\".format(list(tokenizer.word_index)[indices[i]],cosine_similarity(tf_cooc[10:11], tf_cooc[indices[i]:indices[i]+1])[0][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "The closest words from alice are mainly verbs (had, question, say) and preposition (such as to). This is expected since a sentence usually have subject then followed by verb and sometimes preposition. In most cases, Alice is commonly appear as subject in the text. That is why 'had', 'question', 'say', 'to' are close to 'Alice'. The most frequent one is 't' because it is an abbreviation of 'not'. Usually the sentence goes like \"Alice doesn't ...\" or \"Alice wouldn't...\" and the 't' in this case was parsed into a word. Thus it is not surpising it becomes the closest word to Alice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5\n",
    "### Discuss what the main drawbacks are of a term-term co-occurence matrix solutions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main drawbacks of co-occurance matrix is the resulting matrix is sparse (contains a lot of 0 values). This is not an efficient representation since it costs a lot of memory (VxV, where V is the number of unique word) to store a lot of 0 values. Moreover, if we add a new word to corpus, then the amount of table value that will be added is $V^2-(V-1)^2$ which is a lot for big number of V. The resulting matrix also storing the same values on the upper and lower side of main diagonal, which is somewhat redundant.  Lastly the frequency of occurrence can be skewed and non discriminative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save your all the vector representations of your word embeddings in this way\n",
    "#Change when necessary the sizes of the vocabulary/embedding dimension\n",
    "\n",
    "f = open('vectors_co_occurrence.txt',\"w\")\n",
    "f.write(\" \".join([str(V-1),str(V-1)]))\n",
    "f.write(\"\\n\")\n",
    "\n",
    "#vectors = your word co-occurrence matrix\n",
    "vectors = tf_cooc\n",
    "for word, i in tokenizer.word_index.items():    \n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i-1,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reopen your file as follows\n",
    "\n",
    "co_occurrence = KeyedVectors.load_word2vec_format('./vectors_co_occurrence.txt', binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "### Word embeddings\n",
    "Build embeddings with a keras implementation where the embedding vector is of length 50, 150 and 300. Use the Alice in Wonderland text book for training.\n",
    "1. Using the CBOW model\n",
    "2. Using Skipgram model\n",
    "3. Add extra hidden dense layer to CBow and Skipgram implementations. Choose an activation function for that layer and justify your answer.\n",
    "4. Analyze the four different word embeddings\n",
    "    - Implement your own function to perform the analogy task with. Do not use existing libraries for this task such as Gensim. Your function should be able to answer whether an anaology as in the example given in the pdf-file is true.\n",
    "    - Compare the performance on the analogy task between the word embeddings that you have trained in 2.1, 2.2 and 2.3.  \n",
    "    - Visualize your results and interpret your results\n",
    "5. Use the word co-occurence matrix from Question 1. Compare the performance on the analogy task with the performance of your trained word embeddings.  \n",
    "6. Discuss:\n",
    "    - What are the main advantages of CBOW and Skipgram?\n",
    "    - What is the advantage of negative sampling?\n",
    "    - What are the main drawbacks of CBOW and Skipgram?\n",
    "7. Load pre-trained embeddings on large corpuses (see the pdf file). You only have to consider the word embeddings with an embedding size of 300\n",
    "    - Compare performance on the analogy task with your own trained embeddings from \"Alice in Wonderland\". You can limit yourself to the vocabulary of Alice in Wonderland. Visualize the pre-trained word embeddings and compare these with the results of your own trained word embeddings. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1\n",
    "### Using the CBOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17896, 4)\n",
      "(17896, 2557)\n",
      "2557\n"
     ]
    }
   ],
   "source": [
    "#prepare data for cbow\n",
    "path = 'alice.txt'\n",
    "corpus = open(path).readlines()\n",
    "corpus = [sentence for sentence in corpus if sentence.count(\" \") >= 2]\n",
    "\n",
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'+\"'\")\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "corpus = tokenizer.texts_to_sequences(corpus)\n",
    "nb_samples = sum(len(s) for s in corpus)\n",
    "V = len(tokenizer.word_index) + 1\n",
    "\n",
    "def prep_cbow_data(corpus=corpus,window_size=window_size,V=V):\n",
    "    x = []\n",
    "    y = []\n",
    "    w = window_size\n",
    "    for sentence in corpus:\n",
    "        word_length = len(sentence)\n",
    "        if word_length >4:\n",
    "            start = w\n",
    "            for i in range(w,word_length-w):\n",
    "                context_before = sentence[i-w:i]\n",
    "                target = np.zeros(V,dtype=int)\n",
    "                target[sentence[i]] = 1\n",
    "                context_after = sentence[i+1:i+1+start]\n",
    "                context = context_before + context_after\n",
    "                if len(context) == 4:\n",
    "                    #onehot_context = np.asarray(onehot_context)\n",
    "                    x.append(context)\n",
    "                    y.append(target)\n",
    "        else:\n",
    "            pass\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    return x,y\n",
    "\n",
    "print(prep_cbow_data()[0].shape)\n",
    "print(prep_cbow_data()[1].shape)\n",
    "print(V)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 4, 50)             127850    \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2557)              513957    \n",
      "=================================================================\n",
      "Total params: 641,807\n",
      "Trainable params: 641,807\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 4, 150)            383550    \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2557)              1536757   \n",
      "=================================================================\n",
      "Total params: 1,920,307\n",
      "Trainable params: 1,920,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 4, 300)            767100    \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2557)              3070957   \n",
      "=================================================================\n",
      "Total params: 3,838,057\n",
      "Trainable params: 3,838,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(input_dim=2557, output_dim=50, input_length=4, embeddings_initializer=\"glorot_uniform\")`\n",
      "  \n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2557, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(input_dim=2557, output_dim=150, input_length=4, embeddings_initializer=\"glorot_uniform\")`\n",
      "  \n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2557, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")`\n",
      "  app.launch_new_instance()\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(input_dim=2557, output_dim=300, input_length=4, embeddings_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2557, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")`\n"
     ]
    }
   ],
   "source": [
    "#create CBOW model\n",
    "from keras.layers import Flatten\n",
    "#X,Y = prep_cbow_data()\n",
    "#features = len(X)\n",
    "#print(\"size X: {},size Y:{}\".format(len(X),len(Y)))\n",
    "#print(X.shape,Y.shape)\n",
    "cbow_50 = Sequential(name=\"cbow50\")\n",
    "cbow_50.add(Embedding(input_dim=V, output_dim=50, init='glorot_uniform',input_length=4))\n",
    "cbow_50.add(Flatten())\n",
    "cbow_50.add(Dense(V, init='glorot_uniform', activation='softmax'))\n",
    "\n",
    "cbow_50.summary()\n",
    "cbow_150 = Sequential(name=\"cbow150\")\n",
    "cbow_150.add(Embedding(input_dim=V, output_dim=150, init='glorot_uniform',input_length=4))\n",
    "cbow_150.add(Flatten())\n",
    "cbow_150.add(Dense(V, init='glorot_uniform', activation='softmax'))\n",
    "cbow_150.summary()\n",
    "\n",
    "cbow_300 = Sequential(name=\"cbow300\")\n",
    "cbow_300.add(Embedding(input_dim=V, output_dim=300, init='glorot_uniform',input_length=4))\n",
    "cbow_300.add(Flatten())\n",
    "cbow_300.add(Dense(V, init='glorot_uniform', activation='softmax'))\n",
    "cbow_300.summary()\n",
    "\n",
    "cbow_models = [cbow_50,cbow_150,cbow_300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function\n",
    "for cbow in cbow_models:\n",
    "    cbow.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cbow50\n",
      "Train on 16404 samples, validate on 1492 samples\n",
      "Epoch 1/100\n",
      "16404/16404 [==============================] - 6s 340us/step - loss: 7.8331 - val_loss: 7.8205\n",
      "Epoch 2/100\n",
      "16404/16404 [==============================] - 5s 294us/step - loss: 7.8028 - val_loss: 7.7908\n",
      "Epoch 3/100\n",
      "16404/16404 [==============================] - 5s 295us/step - loss: 7.7638 - val_loss: 7.7437\n",
      "Epoch 4/100\n",
      "16404/16404 [==============================] - 5s 295us/step - loss: 7.6958 - val_loss: 7.6447\n",
      "Epoch 5/100\n",
      "16404/16404 [==============================] - 5s 295us/step - loss: 7.5512 - val_loss: 7.4205\n",
      "Epoch 6/100\n",
      "16404/16404 [==============================] - 5s 296us/step - loss: 7.2535 - val_loss: 7.0241\n",
      "Epoch 7/100\n",
      "16404/16404 [==============================] - 5s 296us/step - loss: 6.8873 - val_loss: 6.7400\n",
      "Epoch 8/100\n",
      "16404/16404 [==============================] - 5s 297us/step - loss: 6.6217 - val_loss: 6.5538\n",
      "Epoch 9/100\n",
      "16404/16404 [==============================] - 5s 297us/step - loss: 6.4229 - val_loss: 6.4112\n",
      "Epoch 10/100\n",
      "16404/16404 [==============================] - 5s 297us/step - loss: 6.2597 - val_loss: 6.2930\n",
      "Epoch 11/100\n",
      "16404/16404 [==============================] - 5s 297us/step - loss: 6.1194 - val_loss: 6.1929\n",
      "Epoch 12/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 5.9962 - val_loss: 6.1085\n",
      "Epoch 13/100\n",
      "16404/16404 [==============================] - 5s 298us/step - loss: 5.8862 - val_loss: 6.0352\n",
      "Epoch 14/100\n",
      "16404/16404 [==============================] - 5s 298us/step - loss: 5.7871 - val_loss: 5.9719\n",
      "Epoch 15/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 5.6966 - val_loss: 5.9140\n",
      "Epoch 16/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 5.6131 - val_loss: 5.8622\n",
      "Epoch 17/100\n",
      "16404/16404 [==============================] - 5s 298us/step - loss: 5.5355 - val_loss: 5.8150\n",
      "Epoch 18/100\n",
      "16404/16404 [==============================] - 5s 297us/step - loss: 5.4627 - val_loss: 5.7726\n",
      "Epoch 19/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 5.3941 - val_loss: 5.7321\n",
      "Epoch 20/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 5.3291 - val_loss: 5.6944\n",
      "Epoch 21/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 5.2676 - val_loss: 5.6595\n",
      "Epoch 22/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 5.2091 - val_loss: 5.6265\n",
      "Epoch 23/100\n",
      "16404/16404 [==============================] - 5s 305us/step - loss: 5.1533 - val_loss: 5.5959\n",
      "Epoch 24/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 5.0998 - val_loss: 5.5668\n",
      "Epoch 25/100\n",
      "16404/16404 [==============================] - 5s 315us/step - loss: 5.0485 - val_loss: 5.5392\n",
      "Epoch 26/100\n",
      "16404/16404 [==============================] - 5s 303us/step - loss: 4.9992 - val_loss: 5.5128\n",
      "Epoch 27/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 4.9516 - val_loss: 5.4877\n",
      "Epoch 28/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.9057 - val_loss: 5.4635\n",
      "Epoch 29/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 4.8613 - val_loss: 5.4411\n",
      "Epoch 30/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 4.8185 - val_loss: 5.4197\n",
      "Epoch 31/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.7769 - val_loss: 5.3987\n",
      "Epoch 32/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 4.7367 - val_loss: 5.3794\n",
      "Epoch 33/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.6974 - val_loss: 5.3602\n",
      "Epoch 34/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.6592 - val_loss: 5.3423\n",
      "Epoch 35/100\n",
      "16404/16404 [==============================] - 5s 304us/step - loss: 4.6221 - val_loss: 5.3248\n",
      "Epoch 36/100\n",
      "16404/16404 [==============================] - 5s 305us/step - loss: 4.5859 - val_loss: 5.3073\n",
      "Epoch 37/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.5506 - val_loss: 5.2914\n",
      "Epoch 38/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 4.5162 - val_loss: 5.2754\n",
      "Epoch 39/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.4825 - val_loss: 5.2599\n",
      "Epoch 40/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 4.4495 - val_loss: 5.2460\n",
      "Epoch 41/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 4.4172 - val_loss: 5.2323\n",
      "Epoch 42/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 4.3856 - val_loss: 5.2192\n",
      "Epoch 43/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 4.3547 - val_loss: 5.2062\n",
      "Epoch 44/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 4.3242 - val_loss: 5.1924\n",
      "Epoch 45/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 4.2944 - val_loss: 5.1807\n",
      "Epoch 46/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 4.2651 - val_loss: 5.1688\n",
      "Epoch 47/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.2363 - val_loss: 5.1577\n",
      "Epoch 48/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.2079 - val_loss: 5.1460\n",
      "Epoch 49/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.1800 - val_loss: 5.1364\n",
      "Epoch 50/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.1525 - val_loss: 5.1269\n",
      "Epoch 51/100\n",
      "16404/16404 [==============================] - 5s 303us/step - loss: 4.1255 - val_loss: 5.1175\n",
      "Epoch 52/100\n",
      "16404/16404 [==============================] - 5s 302us/step - loss: 4.0989 - val_loss: 5.1071\n",
      "Epoch 53/100\n",
      "16404/16404 [==============================] - 5s 303us/step - loss: 4.0726 - val_loss: 5.0992\n",
      "Epoch 54/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 4.0467 - val_loss: 5.0903\n",
      "Epoch 55/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 4.0212 - val_loss: 5.0810\n",
      "Epoch 56/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 3.9960 - val_loss: 5.0736\n",
      "Epoch 57/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 3.9712 - val_loss: 5.0666\n",
      "Epoch 58/100\n",
      "16404/16404 [==============================] - 5s 303us/step - loss: 3.9465 - val_loss: 5.0595\n",
      "Epoch 59/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 3.9224 - val_loss: 5.0524\n",
      "Epoch 60/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 3.8984 - val_loss: 5.0454\n",
      "Epoch 61/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 3.8747 - val_loss: 5.0387\n",
      "Epoch 62/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 3.8513 - val_loss: 5.0318\n",
      "Epoch 63/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 3.8282 - val_loss: 5.0259\n",
      "Epoch 64/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 3.8052 - val_loss: 5.0201\n",
      "Epoch 65/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 3.7827 - val_loss: 5.0151\n",
      "Epoch 66/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 3.7602 - val_loss: 5.0089\n",
      "Epoch 67/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 3.7381 - val_loss: 5.0043\n",
      "Epoch 68/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 3.7161 - val_loss: 4.9988\n",
      "Epoch 69/100\n",
      "16404/16404 [==============================] - 5s 300us/step - loss: 3.6945 - val_loss: 4.9943\n",
      "Epoch 70/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 3.6729 - val_loss: 4.9904\n",
      "Epoch 71/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 3.6516 - val_loss: 4.9864\n",
      "Epoch 72/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 3.6304 - val_loss: 4.9834\n",
      "Epoch 73/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 3.6095 - val_loss: 4.9807\n",
      "Epoch 74/100\n",
      "16404/16404 [==============================] - 5s 301us/step - loss: 3.5886 - val_loss: 4.9765\n",
      "Epoch 75/100\n",
      "16404/16404 [==============================] - 5s 315us/step - loss: 3.5681 - val_loss: 4.9729\n",
      "Epoch 76/100\n",
      "16404/16404 [==============================] - 5s 294us/step - loss: 3.5477 - val_loss: 4.9687\n",
      "Epoch 77/100\n",
      "16404/16404 [==============================] - 5s 293us/step - loss: 3.5274 - val_loss: 4.9644\n",
      "Epoch 78/100\n",
      "16404/16404 [==============================] - 5s 294us/step - loss: 3.5073 - val_loss: 4.9626\n",
      "Epoch 79/100\n",
      "16404/16404 [==============================] - 5s 294us/step - loss: 3.4875 - val_loss: 4.9581\n",
      "Epoch 80/100\n",
      "16404/16404 [==============================] - 5s 296us/step - loss: 3.4677 - val_loss: 4.9551\n",
      "Epoch 81/100\n",
      "16404/16404 [==============================] - 5s 294us/step - loss: 3.4482 - val_loss: 4.9530\n",
      "Epoch 82/100\n",
      "16404/16404 [==============================] - 5s 295us/step - loss: 3.4287 - val_loss: 4.9502\n",
      "Epoch 83/100\n",
      "16404/16404 [==============================] - 5s 294us/step - loss: 3.4095 - val_loss: 4.9482\n",
      "Epoch 84/100\n",
      "16404/16404 [==============================] - 5s 295us/step - loss: 3.3903 - val_loss: 4.9464\n",
      "Epoch 85/100\n",
      "16404/16404 [==============================] - 5s 299us/step - loss: 3.3713 - val_loss: 4.9436\n",
      "Epoch 86/100\n",
      "16404/16404 [==============================] - 5s 294us/step - loss: 3.3524 - val_loss: 4.9412\n",
      "Epoch 87/100\n",
      "16404/16404 [==============================] - 5s 296us/step - loss: 3.3336 - val_loss: 4.9400\n",
      "Epoch 88/100\n",
      "16404/16404 [==============================] - 5s 295us/step - loss: 3.3150 - val_loss: 4.9365\n",
      "Epoch 89/100\n",
      "16404/16404 [==============================] - 5s 295us/step - loss: 3.2964 - val_loss: 4.9345\n",
      "Epoch 90/100\n",
      "16404/16404 [==============================] - 5s 295us/step - loss: 3.2779 - val_loss: 4.9340\n",
      "Running cbow150\n",
      "Train on 16404 samples, validate on 1492 samples\n",
      "Epoch 1/100\n",
      "16404/16404 [==============================] - 8s 474us/step - loss: 7.8289 - val_loss: 7.8105\n",
      "Epoch 2/100\n",
      "16404/16404 [==============================] - 7s 455us/step - loss: 7.7838 - val_loss: 7.7597\n",
      "Epoch 3/100\n",
      "16404/16404 [==============================] - 7s 454us/step - loss: 7.7090 - val_loss: 7.6509\n",
      "Epoch 4/100\n",
      "16404/16404 [==============================] - 7s 457us/step - loss: 7.5418 - val_loss: 7.3802\n",
      "Epoch 5/100\n",
      "16404/16404 [==============================] - 7s 454us/step - loss: 7.1741 - val_loss: 6.9076\n",
      "Epoch 6/100\n",
      "16404/16404 [==============================] - 8s 460us/step - loss: 6.7454 - val_loss: 6.5931\n",
      "Epoch 7/100\n",
      "16404/16404 [==============================] - 7s 454us/step - loss: 6.4313 - val_loss: 6.3760\n",
      "Epoch 8/100\n",
      "16404/16404 [==============================] - 7s 451us/step - loss: 6.1890 - val_loss: 6.2081\n",
      "Epoch 9/100\n",
      "16404/16404 [==============================] - 7s 453us/step - loss: 5.9903 - val_loss: 6.0740\n",
      "Epoch 10/100\n",
      "16404/16404 [==============================] - 7s 453us/step - loss: 5.8213 - val_loss: 5.9657\n",
      "Epoch 11/100\n",
      "16404/16404 [==============================] - 7s 453us/step - loss: 5.6741 - val_loss: 5.8748\n",
      "Epoch 12/100\n",
      "16404/16404 [==============================] - 7s 453us/step - loss: 5.5432 - val_loss: 5.7962\n",
      "Epoch 13/100\n",
      "16404/16404 [==============================] - 8s 458us/step - loss: 5.4247 - val_loss: 5.7273\n",
      "Epoch 14/100\n",
      "16404/16404 [==============================] - 7s 455us/step - loss: 5.3167 - val_loss: 5.6671\n",
      "Epoch 15/100\n",
      "16404/16404 [==============================] - 7s 454us/step - loss: 5.2174 - val_loss: 5.6118\n",
      "Epoch 16/100\n",
      "16404/16404 [==============================] - 7s 453us/step - loss: 5.1253 - val_loss: 5.5596\n",
      "Epoch 17/100\n",
      "16404/16404 [==============================] - 7s 454us/step - loss: 5.0392 - val_loss: 5.5127\n",
      "Epoch 18/100\n",
      "16404/16404 [==============================] - 7s 455us/step - loss: 4.9586 - val_loss: 5.4707\n",
      "Epoch 19/100\n",
      "16404/16404 [==============================] - 7s 453us/step - loss: 4.8822 - val_loss: 5.4316\n",
      "Epoch 20/100\n",
      "16404/16404 [==============================] - 7s 454us/step - loss: 4.8101 - val_loss: 5.3958\n",
      "Epoch 21/100\n",
      "16404/16404 [==============================] - 7s 455us/step - loss: 4.7419 - val_loss: 5.3614\n",
      "Epoch 22/100\n",
      "16404/16404 [==============================] - 7s 455us/step - loss: 4.6765 - val_loss: 5.3298\n",
      "Epoch 23/100\n",
      "16404/16404 [==============================] - 7s 455us/step - loss: 4.6141 - val_loss: 5.3031\n",
      "Epoch 24/100\n",
      "16404/16404 [==============================] - 7s 454us/step - loss: 4.5540 - val_loss: 5.2739\n",
      "Epoch 25/100\n",
      "16404/16404 [==============================] - 7s 452us/step - loss: 4.4962 - val_loss: 5.2485\n",
      "Epoch 26/100\n",
      "16404/16404 [==============================] - 7s 456us/step - loss: 4.4406 - val_loss: 5.2216\n",
      "Epoch 27/100\n",
      "16404/16404 [==============================] - 7s 456us/step - loss: 4.3869 - val_loss: 5.1998\n",
      "Epoch 28/100\n",
      "16404/16404 [==============================] - 7s 455us/step - loss: 4.3347 - val_loss: 5.1782\n",
      "Epoch 29/100\n",
      "16404/16404 [==============================] - 8s 459us/step - loss: 4.2842 - val_loss: 5.1586\n",
      "Epoch 30/100\n",
      "16404/16404 [==============================] - 7s 456us/step - loss: 4.2352 - val_loss: 5.1385\n",
      "Epoch 31/100\n",
      "16404/16404 [==============================] - 7s 454us/step - loss: 4.1875 - val_loss: 5.1200\n",
      "Epoch 32/100\n",
      "16404/16404 [==============================] - 8s 458us/step - loss: 4.1409 - val_loss: 5.1042\n",
      "Epoch 33/100\n",
      "16404/16404 [==============================] - 7s 454us/step - loss: 4.0954 - val_loss: 5.0889\n",
      "Epoch 34/100\n",
      "16404/16404 [==============================] - 7s 457us/step - loss: 4.0510 - val_loss: 5.0720\n",
      "Epoch 35/100\n",
      "16404/16404 [==============================] - 7s 455us/step - loss: 4.0076 - val_loss: 5.0589\n",
      "Epoch 36/100\n",
      "16404/16404 [==============================] - 7s 456us/step - loss: 3.9649 - val_loss: 5.0441\n",
      "Epoch 37/100\n",
      "16404/16404 [==============================] - 7s 456us/step - loss: 3.9233 - val_loss: 5.0317\n",
      "Epoch 38/100\n",
      "16404/16404 [==============================] - 7s 456us/step - loss: 3.8822 - val_loss: 5.0209\n",
      "Epoch 39/100\n",
      "16404/16404 [==============================] - 7s 457us/step - loss: 3.8420 - val_loss: 5.0129\n",
      "Epoch 40/100\n",
      "16404/16404 [==============================] - 8s 459us/step - loss: 3.8025 - val_loss: 4.9975\n",
      "Epoch 41/100\n",
      "16404/16404 [==============================] - 7s 456us/step - loss: 3.7636 - val_loss: 4.9891\n",
      "Epoch 42/100\n",
      "16404/16404 [==============================] - 8s 458us/step - loss: 3.7254 - val_loss: 4.9806\n",
      "Epoch 43/100\n",
      "16404/16404 [==============================] - 7s 457us/step - loss: 3.6875 - val_loss: 4.9733\n",
      "Epoch 44/100\n",
      "16404/16404 [==============================] - 8s 463us/step - loss: 3.6505 - val_loss: 4.9634\n",
      "Epoch 45/100\n",
      "16404/16404 [==============================] - 8s 460us/step - loss: 3.6136 - val_loss: 4.9567\n",
      "Epoch 46/100\n",
      "16404/16404 [==============================] - 8s 457us/step - loss: 3.5771 - val_loss: 4.9474\n",
      "Epoch 47/100\n",
      "16404/16404 [==============================] - 7s 454us/step - loss: 3.5414 - val_loss: 4.9409\n",
      "Epoch 48/100\n",
      "16404/16404 [==============================] - 8s 458us/step - loss: 3.5058 - val_loss: 4.9346\n",
      "Epoch 49/100\n",
      "16404/16404 [==============================] - 8s 457us/step - loss: 3.4709 - val_loss: 4.9299\n",
      "Epoch 50/100\n",
      "16404/16404 [==============================] - 8s 460us/step - loss: 3.4361 - val_loss: 4.9231\n",
      "Epoch 51/100\n",
      "16404/16404 [==============================] - 7s 456us/step - loss: 3.4019 - val_loss: 4.9184\n",
      "Epoch 52/100\n",
      "16404/16404 [==============================] - 8s 460us/step - loss: 3.3679 - val_loss: 4.9115\n",
      "Epoch 53/100\n",
      "16404/16404 [==============================] - 8s 457us/step - loss: 3.3344 - val_loss: 4.9089\n",
      "Epoch 54/100\n",
      "16404/16404 [==============================] - 8s 460us/step - loss: 3.3011 - val_loss: 4.9038\n",
      "Epoch 55/100\n",
      "16404/16404 [==============================] - 8s 460us/step - loss: 3.2680 - val_loss: 4.9032\n",
      "Running cbow300\n",
      "Train on 16404 samples, validate on 1492 samples\n",
      "Epoch 1/100\n",
      "16404/16404 [==============================] - 11s 693us/step - loss: 7.8236 - val_loss: 7.7991\n",
      "Epoch 2/100\n",
      "16404/16404 [==============================] - 11s 677us/step - loss: 7.7593 - val_loss: 7.7175\n",
      "Epoch 3/100\n",
      "16404/16404 [==============================] - 11s 677us/step - loss: 7.6295 - val_loss: 7.5086\n",
      "Epoch 4/100\n",
      "16404/16404 [==============================] - 11s 680us/step - loss: 7.3109 - val_loss: 7.0307\n",
      "Epoch 5/100\n",
      "16404/16404 [==============================] - 11s 680us/step - loss: 6.8238 - val_loss: 6.6302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "16404/16404 [==============================] - 11s 669us/step - loss: 6.4301 - val_loss: 6.3627\n",
      "Epoch 7/100\n",
      "16404/16404 [==============================] - 11s 673us/step - loss: 6.1293 - val_loss: 6.1634\n",
      "Epoch 8/100\n",
      "16404/16404 [==============================] - 11s 671us/step - loss: 5.8904 - val_loss: 6.0110\n",
      "Epoch 9/100\n",
      "16404/16404 [==============================] - 11s 673us/step - loss: 5.6911 - val_loss: 5.8874\n",
      "Epoch 10/100\n",
      "16404/16404 [==============================] - 11s 674us/step - loss: 5.5191 - val_loss: 5.7851\n",
      "Epoch 11/100\n",
      "16404/16404 [==============================] - 11s 673us/step - loss: 5.3677 - val_loss: 5.6999\n",
      "Epoch 12/100\n",
      "16404/16404 [==============================] - 11s 674us/step - loss: 5.2318 - val_loss: 5.6226\n",
      "Epoch 13/100\n",
      "16404/16404 [==============================] - 11s 674us/step - loss: 5.1090 - val_loss: 5.5536\n",
      "Epoch 14/100\n",
      "16404/16404 [==============================] - 11s 672us/step - loss: 4.9963 - val_loss: 5.4946\n",
      "Epoch 15/100\n",
      "16404/16404 [==============================] - 11s 676us/step - loss: 4.8925 - val_loss: 5.4398\n",
      "Epoch 16/100\n",
      "16404/16404 [==============================] - 11s 674us/step - loss: 4.7953 - val_loss: 5.3893\n",
      "Epoch 17/100\n",
      "16404/16404 [==============================] - 11s 673us/step - loss: 4.7048 - val_loss: 5.3450\n",
      "Epoch 18/100\n",
      "16404/16404 [==============================] - 11s 670us/step - loss: 4.6198 - val_loss: 5.3043\n",
      "Epoch 19/100\n",
      "16404/16404 [==============================] - 11s 679us/step - loss: 4.5394 - val_loss: 5.2669\n",
      "Epoch 20/100\n",
      "16404/16404 [==============================] - 11s 673us/step - loss: 4.4629 - val_loss: 5.2296\n",
      "Epoch 21/100\n",
      "16404/16404 [==============================] - 11s 675us/step - loss: 4.3901 - val_loss: 5.1984\n",
      "Epoch 22/100\n",
      "16404/16404 [==============================] - 11s 672us/step - loss: 4.3202 - val_loss: 5.1692\n",
      "Epoch 23/100\n",
      "16404/16404 [==============================] - 11s 673us/step - loss: 4.2531 - val_loss: 5.1407\n",
      "Epoch 24/100\n",
      "16404/16404 [==============================] - 11s 670us/step - loss: 4.1884 - val_loss: 5.1168\n",
      "Epoch 25/100\n",
      "16404/16404 [==============================] - 11s 671us/step - loss: 4.1260 - val_loss: 5.0924\n",
      "Epoch 26/100\n",
      "16404/16404 [==============================] - 11s 678us/step - loss: 4.0654 - val_loss: 5.0715\n",
      "Epoch 27/100\n",
      "16404/16404 [==============================] - 11s 669us/step - loss: 4.0067 - val_loss: 5.0493\n",
      "Epoch 28/100\n",
      "16404/16404 [==============================] - 11s 678us/step - loss: 3.9497 - val_loss: 5.0318\n",
      "Epoch 29/100\n",
      "16404/16404 [==============================] - 11s 671us/step - loss: 3.8939 - val_loss: 5.0144\n",
      "Epoch 30/100\n",
      "16404/16404 [==============================] - 11s 671us/step - loss: 3.8395 - val_loss: 4.9980\n",
      "Epoch 31/100\n",
      "16404/16404 [==============================] - 11s 675us/step - loss: 3.7864 - val_loss: 4.9838\n",
      "Epoch 32/100\n",
      "16404/16404 [==============================] - 11s 675us/step - loss: 3.7341 - val_loss: 4.9695\n",
      "Epoch 33/100\n",
      "16404/16404 [==============================] - 11s 670us/step - loss: 3.6830 - val_loss: 4.9555\n",
      "Epoch 34/100\n",
      "16404/16404 [==============================] - 11s 676us/step - loss: 3.6327 - val_loss: 4.9468\n",
      "Epoch 35/100\n",
      "16404/16404 [==============================] - 11s 673us/step - loss: 3.5833 - val_loss: 4.9354\n",
      "Epoch 36/100\n",
      "16404/16404 [==============================] - 11s 674us/step - loss: 3.5344 - val_loss: 4.9252\n",
      "Epoch 37/100\n",
      "16404/16404 [==============================] - 11s 677us/step - loss: 3.4866 - val_loss: 4.9145\n",
      "Epoch 38/100\n",
      "16404/16404 [==============================] - 11s 675us/step - loss: 3.4392 - val_loss: 4.9057\n",
      "Epoch 39/100\n",
      "16404/16404 [==============================] - 11s 672us/step - loss: 3.3924 - val_loss: 4.8979\n",
      "Epoch 40/100\n",
      "16404/16404 [==============================] - 11s 676us/step - loss: 3.3465 - val_loss: 4.8914\n",
      "Epoch 41/100\n",
      "16404/16404 [==============================] - 11s 673us/step - loss: 3.3006 - val_loss: 4.8814\n",
      "Epoch 42/100\n",
      "16404/16404 [==============================] - 11s 673us/step - loss: 3.2556 - val_loss: 4.8760\n",
      "Epoch 43/100\n",
      "16404/16404 [==============================] - 11s 674us/step - loss: 3.2112 - val_loss: 4.8712\n",
      "Epoch 44/100\n",
      "16404/16404 [==============================] - 11s 670us/step - loss: 3.1668 - val_loss: 4.8662\n",
      "Epoch 45/100\n",
      "16404/16404 [==============================] - 11s 668us/step - loss: 3.1235 - val_loss: 4.8602\n",
      "Epoch 46/100\n",
      "16404/16404 [==============================] - 11s 676us/step - loss: 3.0802 - val_loss: 4.8550\n",
      "Epoch 47/100\n",
      "16404/16404 [==============================] - 11s 679us/step - loss: 3.0375 - val_loss: 4.8518\n",
      "Epoch 48/100\n",
      "16404/16404 [==============================] - 11s 675us/step - loss: 2.9954 - val_loss: 4.8480\n",
      "Epoch 49/100\n",
      "16404/16404 [==============================] - 11s 683us/step - loss: 2.9533 - val_loss: 4.8435\n",
      "Epoch 50/100\n",
      "16404/16404 [==============================] - 11s 675us/step - loss: 2.9122 - val_loss: 4.8373\n",
      "Epoch 51/100\n",
      "16404/16404 [==============================] - 11s 675us/step - loss: 2.8711 - val_loss: 4.8377\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "from keras import callbacks\n",
    "X,Y = prep_cbow_data()\n",
    "epochs=100\n",
    "b_size = 250\n",
    "earlyStopping=callbacks.EarlyStopping(monitor='val_loss',min_delta=0.001, patience=0, verbose=0, mode='auto')\n",
    "trained_models = []\n",
    "for cbow in cbow_models:\n",
    "    print(\"Running {}\".format(cbow.name))\n",
    "    cbow.fit(X,Y,batch_size=b_size,epochs=epochs,validation_split=1/12, callbacks=[earlyStopping])\n",
    "    cbow.save(cbow.name+\".h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in trained_models:\n",
    "    model.save(model.name +'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 \n",
    "## Using the Skipgram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data for Skipgram\n",
    "def generate_data_skipgram(corpus, window_size, V):\n",
    "    maxlen = window_size*2\n",
    "    all_in = []\n",
    "    all_out = []\n",
    "    for words in corpus:\n",
    "        L = len(words)\n",
    "        for index, word in enumerate(words):\n",
    "            p = index - window_size\n",
    "            n = index + window_size + 1\n",
    "                    \n",
    "            in_words = []\n",
    "            labels = []\n",
    "            for i in range(p, n):\n",
    "                if i != index and 0 <= i < L:\n",
    "                    in_words.append([word])\n",
    "                    labels.append(words[i])\n",
    "            if in_words != []:\n",
    "                all_in.append(np.array(in_words,dtype=np.int32))\n",
    "                all_out.append(np_utils.to_categorical(labels, V))\n",
    "    return (all_in,all_out)\n",
    "\n",
    "#get x and y's for data\n",
    "x,y = generate_data_skipgram(corpus,window_size,V)\n",
    "\n",
    "#save the preprocessed data of Skipgram\n",
    "f = open('data_skipgram.txt' ,'w')\n",
    "\n",
    "for input,outcome  in zip(x,y):\n",
    "    input = np.concatenate(input)\n",
    "    f.write(\" \".join(map(str, list(input))))\n",
    "    f.write(\",\")\n",
    "    outcome = np.concatenate(outcome)\n",
    "    f.write(\" \".join(map(str,list(outcome))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "#load the preprocessed Skipgram data\n",
    "def generate_data_skipgram_from_file():\n",
    "    f = open('data_skipgram.txt' ,'r')\n",
    "    for row in f:\n",
    "        inputs,outputs = row.split(\",\")\n",
    "        inputs = np.fromstring(inputs, dtype=int, sep=' ')\n",
    "        inputs = np.asarray(np.split(inputs, len(inputs)))\n",
    "        outputs = np.fromstring(outputs, dtype=float, sep=' ')\n",
    "        outputs = np.asarray(np.split(outputs, len(inputs)))\n",
    "        yield (inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Skipgram model\n",
    "\n",
    "dim1=50\n",
    "dim2=150\n",
    "dim3=300\n",
    "skipgram_50 = Sequential()\n",
    "skipgram_50.add(Embedding(input_dim=V, output_dim=dim1, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram_50.add(Reshape((dim1, )))\n",
    "skipgram_50.add(Dense(input_dim=dim1, units=V, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "skipgram_150 = Sequential()\n",
    "skipgram_150.add(Embedding(input_dim=V, output_dim=dim2, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram_150.add(Reshape((dim2, )))\n",
    "skipgram_150.add(Dense(input_dim=dim2, units=V, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "skipgram_300 = Sequential()\n",
    "skipgram_300.add(Embedding(input_dim=V, output_dim=dim3, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram_300.add(Reshape((dim3, )))\n",
    "skipgram_300.add(Dense(input_dim=dim3, units=V, kernel_initializer='uniform', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function for Skipgram\n",
    "skipgram_50.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
    "skipgram_150.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
    "skipgram_300.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 42020.850971221924\n",
      "1 38379.24893140793\n",
      "2 39009.6740334034\n",
      "3 39515.18972373009\n",
      "4 39694.606760025024\n",
      "5 39879.188750982285\n",
      "6 40052.81768655777\n",
      "7 40222.94297456741\n",
      "8 40406.03855037689\n",
      "9 40601.82211446762\n",
      "0 41999.72671556473\n",
      "1 38329.860137462616\n",
      "2 38863.99836754799\n",
      "3 39224.9512283802\n",
      "4 39388.4169280529\n",
      "5 39532.090304374695\n",
      "6 39681.889948129654\n",
      "7 39846.23095178604\n",
      "8 40013.75022268295\n",
      "9 40184.366864323616\n",
      "0 41972.11958169937\n",
      "1 38265.37358021736\n",
      "2 38667.456391334534\n",
      "3 38952.51325392723\n",
      "4 39107.2551445961\n",
      "5 39254.421288490295\n",
      "6 39401.511434555054\n",
      "7 39544.53228521347\n",
      "8 39688.97990846634\n",
      "9 39832.670347929\n"
     ]
    }
   ],
   "source": [
    "#train Skipgram model\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += skipgram_50.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)\n",
    "    \n",
    "f = open('vectors_skipgram_50.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim1)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = skipgram_50.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += skipgram_150.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)\n",
    "    \n",
    "f = open('vectors_skipgram_150.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim2)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = skipgram_150.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += skipgram_300.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)\n",
    "    \n",
    "f = open('vectors_skipgram_300.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim3)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = skipgram_300.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3\n",
    "### Add extra hidden dense layer to CBow and Skipgram implementations. Choose an activation function for that layer and justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(input_dim=1183, output_dim=100, input_length=4, embeddings_initializer=\"glorot_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1183, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#create CBOW model with additional dense layer\n",
    "dims = [50,150,300]\n",
    "extended_models = []\n",
    "for dim in dims:\n",
    "    cbow = Sequential(name=\"cbow_extended_\"+str(dim))\n",
    "    cbow.add(Embedding(input_dim=V, output_dim=dim, init='glorot_uniform',input_length=4))\n",
    "    cbow.add(Flatten())\n",
    "    cbow.add(Dense(V,activation='relu',name=\"dense1\"))\n",
    "    cbow.add(Dense(V, init='glorot_uniform', activation='softmax'))\n",
    "    extended_models.append(cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function for CBOW + dense\n",
    "for model in extended_models:\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5903 samples, validate on 656 samples\n",
      "Epoch 1/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 6.7766 - val_loss: 6.1094\n",
      "Epoch 2/100\n",
      "5903/5903 [==============================] - 9s 1ms/step - loss: 5.8327 - val_loss: 5.7606\n",
      "Epoch 3/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 5.5145 - val_loss: 5.5747\n",
      "Epoch 4/100\n",
      "5903/5903 [==============================] - 8s 1ms/step - loss: 5.2639 - val_loss: 5.4150\n",
      "Epoch 5/100\n",
      "5903/5903 [==============================] - 8s 1ms/step - loss: 5.0215 - val_loss: 5.2781\n",
      "Epoch 6/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 4.7894 - val_loss: 5.1477\n",
      "Epoch 7/100\n",
      "5903/5903 [==============================] - 11s 2ms/step - loss: 4.5724 - val_loss: 5.0567\n",
      "Epoch 8/100\n",
      "5903/5903 [==============================] - 10s 2ms/step - loss: 4.3716 - val_loss: 4.9879\n",
      "Epoch 9/100\n",
      "5903/5903 [==============================] - 10s 2ms/step - loss: 4.1812 - val_loss: 4.9395\n",
      "Epoch 10/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 3.9998 - val_loss: 4.8841\n",
      "Epoch 11/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 3.8235 - val_loss: 4.8715\n",
      "Epoch 12/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 3.6504 - val_loss: 4.8396\n",
      "Epoch 13/100\n",
      "5903/5903 [==============================] - 9s 2ms/step - loss: 3.4827 - val_loss: 4.8171\n",
      "Epoch 14/100\n",
      "5903/5903 [==============================] - 10s 2ms/step - loss: 3.3142 - val_loss: 4.8193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bafacd8668>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model for CBOW + dense\n",
    "from keras import callbacks\n",
    "X,Y = prep_cbow_data()\n",
    "features = len(X)\n",
    "print(\"size X: {},size Y:{}\".format(len(X),len(Y)))\n",
    "print(X.shape,Y.shape)\n",
    "epochs=50\n",
    "for model in extended_models:\n",
    "    earlyStopping=callbacks.EarlyStopping(monitor='val_loss', patience=2, verbose=0, mode='auto')\n",
    "    print(\"training {}\".format(model.name))\n",
    "    model.fit(X,Y,epochs=epochs,validation_split=0.1, callbacks=[earlyStopping])\n",
    "    model.save(model.name+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Skipgram with additional dense layer\n",
    "\n",
    "#create Skipgram model\n",
    "\n",
    "skipgram_50_dense = Sequential()\n",
    "skipgram_50_dense.add(Embedding(input_dim=V, output_dim=dim1, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram_50_dense.add(Reshape((dim1, )))\n",
    "skipgram_50_dense.add(Dense(V,activation='relu'))\n",
    "skipgram_50_dense.add(Dense(input_dim=dim1, units=V, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "skipgram_150_dense = Sequential()\n",
    "skipgram_150_dense.add(Embedding(input_dim=V, output_dim=dim2, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram_150_dense.add(Reshape((dim2, )))\n",
    "skipgram_150_dense.add(Dense(V,activation='relu'))\n",
    "skipgram_150_dense.add(Dense(input_dim=dim2, units=V, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "skipgram_300_dense = Sequential()\n",
    "skipgram_300_dense.add(Embedding(input_dim=V, output_dim=dim3, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "skipgram_300_dense.add(Reshape((dim3, )))\n",
    "skipgram_300_dense.add(Dense(V,activation='relu'))\n",
    "skipgram_300_dense.add(Dense(input_dim=dim3, units=V, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "#skipgram2 = Sequential()\n",
    "#skipgram2.add(Embedding(input_dim=V, output_dim=dim, embeddings_initializer='glorot_uniform', input_length=1))\n",
    "#skipgram2.add(Reshape((dim, )))\n",
    "#skipgram2.add(Dense(input_dim=dim, units=V, kernel_initializer='uniform', activation='softmax'))\n",
    "#skipgram2.add(Dense(input_dim=dim, units=V, kernel_initializer='uniform', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function for Skipgram + dense\n",
    "skipgram_50_dense.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
    "skipgram_150_dense.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
    "skipgram_300_dense.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 39444.32987213135\n",
      "1 38264.48951482773\n",
      "2 37948.66480302811\n",
      "3 37769.99622249603\n",
      "4 37750.78943347931\n",
      "5 37725.23108911514\n",
      "6 37674.930666565895\n",
      "7 37620.79466640949\n",
      "8 37566.527002334595\n",
      "9 37519.70512115955\n",
      "0 39471.03422307968\n",
      "1 38220.93018221855\n",
      "2 37718.286794900894\n",
      "3 37538.61131024361\n",
      "4 37493.13153910637\n",
      "5 37456.600872159004\n",
      "6 37402.676347732544\n",
      "7 37335.5792144537\n",
      "8 37265.79830777645\n",
      "9 37196.82523834705\n",
      "0 39445.47623085976\n",
      "1 38082.24569654465\n",
      "2 37592.96987724304\n",
      "3 37330.86567401886\n",
      "4 37259.75267124176\n",
      "5 37224.620362997055\n",
      "6 37161.21744906902\n",
      "7 37086.09090960026\n",
      "8 37002.261269927025\n",
      "9 36925.072355270386\n"
     ]
    }
   ],
   "source": [
    "#train model for Skipgram + dense\n",
    "#train Skipgram model\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += skipgram_50_dense.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)\n",
    "    \n",
    "f = open('vectors_skipgram_50_dense.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim1)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = skipgram_50_dense.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += skipgram_150_dense.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)\n",
    "    \n",
    "f = open('vectors_skipgram_150_dense.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim2)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = skipgram_150_dense.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data_skipgram_from_file():\n",
    "        loss += skipgram_300_dense.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)\n",
    "    \n",
    "f = open('vectors_skipgram_300_dense.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim3)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = skipgram_300_dense.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "skipgram_50.save('skipgram_50.h5')\n",
    "skipgram_150.save('skipgram_150.h5')\n",
    "skipgram_300.save('skipgram_300.h5')\n",
    "skipgram_50_dense.save('skipgram_50_dense.h5')\n",
    "skipgram_150_dense.save('skipgram_150_dense.h5')\n",
    "skipgram_300_dense.save('skipgram_300_dense.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Layer\n",
    "\n",
    "Rectified linear units, $max(x,0)$, have either a value 0 or the value x itself.\n",
    "This results in a function which if $x>0$ has a derivative of 1.\n",
    "Thus ReLu's are incredibly simple resulting in fast training times. \n",
    "A problem with ReLu's can be that they \"die\" which could happen when x gets to a negative value.\n",
    "The problem of \"Dieing\" neurons can partly be combated with a sufficiently slow learning rate.\n",
    "For the case in this assignment with such a simple shallow network ReLu's are most likely sufficient.\n",
    "More complex versions like smooth ReLu or PRelu are not needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4\n",
    "### Analyze the four different word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement your own analogy function\n",
    "\n",
    "key_cbow_50 ={}\n",
    "key_cbow_150 ={}\n",
    "key_cbow_300 ={}\n",
    "key_cbow_50_dense ={}\n",
    "key_cbow_150_dense ={}\n",
    "key_cbow_300_dense ={}\n",
    "key_skipgram_50 ={}\n",
    "key_skipgram_150 ={}\n",
    "key_skipgram_300 ={}\n",
    "key_skipgram_50_dense ={}\n",
    "key_skipgram_150_dense ={}\n",
    "key_skipgram_300_dense ={}\n",
    "\n",
    "embed_cbow_50 =[]\n",
    "embed_cbow_150 =[]\n",
    "embed_cbow_300 =[]\n",
    "embed_cbow_50_dense =[]\n",
    "embed_cbow_150_dense =[]\n",
    "embed_cbow_300_dense =[]\n",
    "embed_skipgram_50 =[]\n",
    "embed_skipgram_150 =[]\n",
    "embed_skipgram_300 =[]\n",
    "embed_skipgram_50_dense =[]\n",
    "embed_skipgram_150_dense =[]\n",
    "embed_skipgram_300_dense =[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_from_file(a):\n",
    "    f = open(a ,'r')\n",
    "    key_dict={}\n",
    "    vect=[]\n",
    "    for row in f:\n",
    "        dimention=0\n",
    "        inp = row.split(\"\\n\")[0].split(\" \")\n",
    "        if(len(inp)==2):\n",
    "            dimention=inp[1]\n",
    "        else:\n",
    "            key_dict.update({inp[0]:len(key_dict)})\n",
    "            vect.append(np.asarray(inp[1:],dtype=float))\n",
    "    return (vect,key_dict)\n",
    "\n",
    "(embed_cbow_50,key_cbow_50)=load_from_file('vectors_cbow_50.txt')\n",
    "(embed_cbow_150,key_cbow_150)=load_from_file('vectors_cbow_150.txt')\n",
    "(embed_cbow_300,key_cbow_300)=load_from_file('vectors_cbow_300.txt')\n",
    "(embed_cbow_50_dense,key_cbow_50_dense)=load_from_file('vectors_cbow_50_dense.txt')\n",
    "(embed_cbow_150_dense,key_cbow_150_dense)=load_from_file('vectors_cbow_150_dense.txt')\n",
    "(embed_cbow_300_dense,key_cbow_300_dense)=load_from_file('vectors_cbow_300_dense.txt')\n",
    "(embed_skipgram_50,key_skipgram_50)=load_from_file('vectors_skipgram_50.txt')\n",
    "(embed_skipgram_150,key_skipgram_150)=load_from_file('vectors_skipgram_150.txt')\n",
    "(embed_skipgram_300,key_skipgram_300)=load_from_file('vectors_skipgram_300.txt')\n",
    "(embed_skipgram_50_dense,key_skipgram_50_dense)=load_from_file('vectors_skipgram_50_dense.txt')\n",
    "(embed_skipgram_150_dense,key_skipgram_150_dense)=load_from_file('vectors_skipgram_150_dense.txt')\n",
    "(embed_skipgram_300_dense,key_skipgram_300_dense)=load_from_file('vectors_skipgram_300_dense.txt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2366986027145685\n",
      "box\n",
      "which\n"
     ]
    }
   ],
   "source": [
    "import operator \n",
    "\n",
    "def add_matrix(a,b):\n",
    "    return [a[i]+b[i] for i in range(len(a))]\n",
    "def sub_matrix(a,b):\n",
    "    return [a[i]-b[i] for i in range(len(a))]\n",
    "\n",
    "\n",
    "def load_analogy():\n",
    "    f = open('analogy_alice.txt' ,'r')\n",
    "    analogy_list=[]\n",
    "    for row in f:\n",
    "        a = row.split(\"\\n\")[0].split(\" \")\n",
    "        analogy_list.append(np.asarray(a))\n",
    "    return analogy_list\n",
    "\n",
    "def analogy_check(analogy_list,embed_matrix,dictionary):\n",
    "    v=[[],[],[],[]]\n",
    "    for i in range(4):\n",
    "        if(analogy_list[i] in dictionary):\n",
    "            v[i]=embed_matrix[dictionary[analogy_list[i]] -1]\n",
    "        else:\n",
    "            v[i]=np.zeros(len(embed_matrix[0]))\n",
    "    #print(dictionary)\n",
    "    #return abs(cos_sim(v[0],v[2])-cos_sim(v[1],v[3]))\n",
    "    #return 1-abs(cos_sim(v[0],v[1])-cos_sim(v[2],v[3]))\n",
    "    #return cos_sim( list(map(sum, zip(list(map(operator.sub, v[0],v[1]))), v[2])),v[3])\n",
    "    #return abs(cos_sim(v[0]-v[2]+v[1],v[3]))\n",
    "    #return abs(cos_sim( (v[0]+v[1]),(v[2]+v[3])))\n",
    "    return abs(cos_sim( (add_matrix(v[0],v[1])),(add_matrix(v[2],v[3]))))\n",
    "def analogy_predict(analogy_list,embed_matrix,dictionary):\n",
    "    v=[[],[],[],[]]\n",
    "    for i in range(4):\n",
    "        if(analogy_list[i] in dictionary):\n",
    "            v[i]=embed_matrix[dictionary[analogy_list[i]]-1]\n",
    "        else:\n",
    "            v[i]=np.zeros(len(embed_matrix[0]))\n",
    "    #target=cos_sim(v[0],v[1])\n",
    "    #print(cos_sim(v[0]+v[1],v[2]+v[3]))\n",
    "    #print(cos_sim(v[0]+v[2],v[1]+v[3]))  \n",
    "    target=v[0]+v[1]-v[0]\n",
    "    #target=sub_matrix(add_matrix(v[0],v[1]),v[2])\n",
    "    maxid=0\n",
    "    maxval=0\n",
    "    simi=np.zeros(V-1)\n",
    "    for i in range(V-1):\n",
    "        #simi[i]=(cos_sim(embed_matrix[dictionary[analogy_list[2]]-1], embed_matrix[i])-target)\n",
    "        simi[i]=(cos_sim(target, embed_matrix[i]))\n",
    "    indices=simi.argsort()[-4:][::-1]\n",
    "    for i in range(4):\n",
    "        if(not((list(tokenizer.word_index)[indices[i]] == analogy_list[0]) or (list(tokenizer.word_index)[indices[i]] == analogy_list[1]) or (list(tokenizer.word_index)[indices[i]] == analogy_list[2]))):\n",
    "            return(list(tokenizer.word_index)[indices[i]])           \n",
    "\n",
    "analogy_list=load_analogy()\n",
    "#print(analogy_list[0])\n",
    "print(analogy_check([\"go\",\"going\",\"look\",\"looking\"],embed_skipgram_150, tokenizer.word_index ))\n",
    "print(analogy_predict([\"say\",\"saying\",\"sit\",\"sitting\"],cooccurrence_matrix.toarray(), tokenizer.word_index ))\n",
    "print(analogy_predict([\"sudden\",\"suddenly\",\"usual\",\"usually\"],embed_skipgram_300_dense, tokenizer.word_index ))\n",
    "#print(analogy_check([\"king\",\"queen\",\"man\",\"woman\"],embed_cbow_50, tokenizer.word_index ))\n",
    "\n",
    "#analogy_check([\"fancy\",\"fancying\",\"alice\",\"rabbit\"],embed_skipgram_150, tokenizer.word_index )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"king\" in tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read model from tim\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "dim1=50\n",
    "dim2=150\n",
    "dim3=300\n",
    "cbow_50 = load_model('cbow50.h5')\n",
    "cbow_150 = load_model('cbow150.h5')\n",
    "cbow_300 = load_model('cbow300.h5')\n",
    "cbow_50_dense = load_model('cbow_extended_50.h5')\n",
    "cbow_150_dense = load_model('cbow_extended_150.h5')\n",
    "cbow_300_dense = load_model('cbow_extended_300.h5')\n",
    "\n",
    "f = open('vectors_cbow_50.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim1)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = cbow_50.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open('vectors_cbow_150.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim2)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = cbow_150.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open('vectors_cbow_300.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim3)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = cbow_300.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open('vectors_cbow_50_dense.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim1)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = cbow_50_dense.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open('vectors_cbow_150_dense.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim2)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = cbow_150_dense.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open('vectors_cbow_300_dense.txt' ,'w')\n",
    "f.write(\" \".join([str(V-1),str(dim3)]))\n",
    "f.write(\"\\n\")\n",
    "vectors = cbow_300_dense.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(\" \")\n",
    "    f.write(\" \".join(map(str, list(vectors[i,:]))))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbow_50: sudden, suddenly, usual, usually: 0.2145599465610109\n",
      "cbow_150: sudden, suddenly, usual, usually: 0.16464666681544313\n",
      "cbow_300: sudden, suddenly, usual, usually: 0.04262983580543956\n",
      "cbow_50_dense: sudden, suddenly, usual, usually: 0.024934976086477847\n",
      "cbow_150_dense: sudden, suddenly, usual, usually: 0.06584301080295592\n",
      "cbow_300_dense: sudden, suddenly, usual, usually: 0.057512587300851306\n",
      "skipgram_50: sudden, suddenly, usual, usually: 0.2756882855493019\n",
      "skipgram_150: sudden, suddenly, usual, usually: 0.0437688865904095\n",
      "skipgram_300: sudden, suddenly, usual, usually: 0.12027916002446541\n",
      "skipgram_50_dense: sudden, suddenly, usual, usually: 0.11550091531896342\n",
      "skipgram_150_dense: sudden, suddenly, usual, usually: 0.09122986493247628\n",
      "skipgram_300_dense: sudden, suddenly, usual, usually: 0.0379434827632857\n",
      "\n",
      "cbow_50: bad, worse, good, better: 0.007139452508570647\n",
      "cbow_150: bad, worse, good, better: 0.04960375886754415\n",
      "cbow_300: bad, worse, good, better: 0.08364212988123694\n",
      "cbow_50_dense: bad, worse, good, better: 0.026874943420956886\n",
      "cbow_150_dense: bad, worse, good, better: 0.12296815517749676\n",
      "cbow_300_dense: bad, worse, good, better: 0.022567480791767187\n",
      "skipgram_50: bad, worse, good, better: 0.09587694529005604\n",
      "skipgram_150: bad, worse, good, better: 0.01997792110150503\n",
      "skipgram_300: bad, worse, good, better: 0.05282783225651509\n",
      "skipgram_50_dense: bad, worse, good, better: 0.07730987059232503\n",
      "skipgram_150_dense: bad, worse, good, better: 0.11583589719793469\n",
      "skipgram_300_dense: bad, worse, good, better: 0.06542767465641082\n",
      "\n",
      "cbow_50: go, going, look, looking: 0.04482878540457188\n",
      "cbow_150: go, going, look, looking: 0.13521208123901596\n",
      "cbow_300: go, going, look, looking: 0.11739576262876612\n",
      "cbow_50_dense: go, going, look, looking: 0.2275989682841857\n",
      "cbow_150_dense: go, going, look, looking: 0.08095648478867602\n",
      "cbow_300_dense: go, going, look, looking: 0.014954370905789528\n",
      "skipgram_50: go, going, look, looking: 0.19612565040854993\n",
      "skipgram_150: go, going, look, looking: 0.2366986027145685\n",
      "skipgram_300: go, going, look, looking: 0.2300817760171532\n",
      "skipgram_50_dense: go, going, look, looking: 0.14061684371374158\n",
      "skipgram_150_dense: go, going, look, looking: 0.14720249473774485\n",
      "skipgram_300_dense: go, going, look, looking: 0.002864495321771528\n",
      "\n",
      "cbow_50: he, she, his, her: 0.08099932963910215\n",
      "cbow_150: he, she, his, her: 0.03569783846020872\n",
      "cbow_300: he, she, his, her: 0.022474709476888687\n",
      "cbow_50_dense: he, she, his, her: 0.25305776920456663\n",
      "cbow_150_dense: he, she, his, her: 0.05257730241374489\n",
      "cbow_300_dense: he, she, his, her: 0.12253203367780965\n",
      "skipgram_50: he, she, his, her: 0.6315077702042393\n",
      "skipgram_150: he, she, his, her: 0.30525691255592236\n",
      "skipgram_300: he, she, his, her: 0.21834270821319915\n",
      "skipgram_50_dense: he, she, his, her: 0.2154861486119754\n",
      "skipgram_150_dense: he, she, his, her: 0.14655767256694316\n",
      "skipgram_300_dense: he, she, his, her: 0.1511302407262479\n",
      "\n",
      "cbow_50: brother, sister, his, her: 0.3216747204943751\n",
      "cbow_150: brother, sister, his, her: 0.23105893917756617\n",
      "cbow_300: brother, sister, his, her: 0.07589060484117083\n",
      "cbow_50_dense: brother, sister, his, her: 0.08839213138780096\n",
      "cbow_150_dense: brother, sister, his, her: 0.03201457747498062\n",
      "cbow_300_dense: brother, sister, his, her: 0.010614877330893632\n",
      "skipgram_50: brother, sister, his, her: 0.2784751503552196\n",
      "skipgram_150: brother, sister, his, her: 0.05926938209585694\n",
      "skipgram_300: brother, sister, his, her: 0.017768418713980348\n",
      "skipgram_50_dense: brother, sister, his, her: 0.16731238470239565\n",
      "skipgram_150_dense: brother, sister, his, her: 0.1600951228220338\n",
      "skipgram_300_dense: brother, sister, his, her: 0.10670694926142113\n",
      "\n",
      "cbow_50: listen, listening, look, looking: 0.3802069701610734\n",
      "cbow_150: listen, listening, look, looking: 0.36921053308958424\n",
      "cbow_300: listen, listening, look, looking: 0.23802999618462123\n",
      "cbow_50_dense: listen, listening, look, looking: 0.03956834867672034\n",
      "cbow_150_dense: listen, listening, look, looking: 0.025226025836383444\n",
      "cbow_300_dense: listen, listening, look, looking: 0.08170528413458206\n",
      "skipgram_50: listen, listening, look, looking: 0.16071493864813735\n",
      "skipgram_150: listen, listening, look, looking: 0.08121301306304535\n",
      "skipgram_300: listen, listening, look, looking: 0.028332544949943285\n",
      "skipgram_50_dense: listen, listening, look, looking: 0.3328211143150717\n",
      "skipgram_150_dense: listen, listening, look, looking: 0.0595487007636639\n",
      "skipgram_300_dense: listen, listening, look, looking: 0.0406596642434014\n",
      "\n",
      "cbow_50: saying, said, thinking, thought: 0.3083834417108346\n",
      "cbow_150: saying, said, thinking, thought: 0.30258397528363445\n",
      "cbow_300: saying, said, thinking, thought: 0.3385169623849108\n",
      "cbow_50_dense: saying, said, thinking, thought: 0.27146892652097987\n",
      "cbow_150_dense: saying, said, thinking, thought: 0.26399041172107607\n",
      "cbow_300_dense: saying, said, thinking, thought: 0.12383424063284779\n",
      "skipgram_50: saying, said, thinking, thought: 0.47844005126731487\n",
      "skipgram_150: saying, said, thinking, thought: 0.3302187165569458\n",
      "skipgram_300: saying, said, thinking, thought: 0.3447016003046785\n",
      "skipgram_50_dense: saying, said, thinking, thought: 0.032715337214361935\n",
      "skipgram_150_dense: saying, said, thinking, thought: 0.03265436792557913\n",
      "skipgram_300_dense: saying, said, thinking, thought: 0.08585073444779104\n",
      "\n",
      "cbow_50: bird, birds, cat, cats: 0.25155843706819225\n",
      "cbow_150: bird, birds, cat, cats: 0.11949157172847855\n",
      "cbow_300: bird, birds, cat, cats: 0.1781694964528609\n",
      "cbow_50_dense: bird, birds, cat, cats: 0.2320395959316713\n",
      "cbow_150_dense: bird, birds, cat, cats: 0.0884316106458272\n",
      "cbow_300_dense: bird, birds, cat, cats: 0.14467242053834647\n",
      "skipgram_50: bird, birds, cat, cats: 0.09811743589493657\n",
      "skipgram_150: bird, birds, cat, cats: 0.07479503054987136\n",
      "skipgram_300: bird, birds, cat, cats: 0.12625871403801467\n",
      "skipgram_50_dense: bird, birds, cat, cats: 0.012887874151781279\n",
      "skipgram_150_dense: bird, birds, cat, cats: 0.07353652983537766\n",
      "skipgram_300_dense: bird, birds, cat, cats: 0.05631322940932175\n",
      "\n",
      "cbow_50: good, better, old, older: 0.28356033517821916\n",
      "cbow_150: good, better, old, older: 0.3367662060157432\n",
      "cbow_300: good, better, old, older: 0.24294226160000545\n",
      "cbow_50_dense: good, better, old, older: 0.12562361925379575\n",
      "cbow_150_dense: good, better, old, older: 0.10944203217062437\n",
      "cbow_300_dense: good, better, old, older: 0.18656535061624072\n",
      "skipgram_50: good, better, old, older: 0.08069563744902247\n",
      "skipgram_150: good, better, old, older: 0.10060746006827065\n",
      "skipgram_300: good, better, old, older: 0.14252044931840813\n",
      "skipgram_50_dense: good, better, old, older: 0.006715441594898397\n",
      "skipgram_150_dense: good, better, old, older: 0.05311411308035306\n",
      "skipgram_300_dense: good, better, old, older: 0.05186729010261828\n",
      "\n",
      "cbow_50: good, better, quick, quicker: 0.12513511819856912\n",
      "cbow_150: good, better, quick, quicker: 0.10664919624378821\n",
      "cbow_300: good, better, quick, quicker: 0.03208647290314115\n",
      "cbow_50_dense: good, better, quick, quicker: 0.12567182118934672\n",
      "cbow_150_dense: good, better, quick, quicker: 0.06164886348505986\n",
      "cbow_300_dense: good, better, quick, quicker: 0.051326262550663464\n",
      "skipgram_50: good, better, quick, quicker: 0.17399304028369653\n",
      "skipgram_150: good, better, quick, quicker: 0.1366727017042409\n",
      "skipgram_300: good, better, quick, quicker: 0.013046449432128392\n",
      "skipgram_50_dense: good, better, quick, quicker: 0.033102714983078194\n",
      "skipgram_150_dense: good, better, quick, quicker: 0.03085308262693412\n",
      "skipgram_300_dense: good, better, quick, quicker: 0.0796093389770551\n",
      "\n",
      "cbow_50: large, largest, good, best: 0.055252841538935865\n",
      "cbow_150: large, largest, good, best: 0.14962042649321572\n",
      "cbow_300: large, largest, good, best: 0.13627840091820803\n",
      "cbow_50_dense: large, largest, good, best: 0.1395942175402173\n",
      "cbow_150_dense: large, largest, good, best: 0.11470696113616369\n",
      "cbow_300_dense: large, largest, good, best: 0.05309922636686337\n",
      "skipgram_50: large, largest, good, best: 0.2635602102832999\n",
      "skipgram_150: large, largest, good, best: 0.2500863831230385\n",
      "skipgram_300: large, largest, good, best: 0.16575460309601556\n",
      "skipgram_50_dense: large, largest, good, best: 0.12473340544962884\n",
      "skipgram_150_dense: large, largest, good, best: 0.06615579167947909\n",
      "skipgram_300_dense: large, largest, good, best: 0.053627787932685286\n",
      "\n",
      "cbow_50: falling, fell, knowing, knew: 0.34969637290903044\n",
      "cbow_150: falling, fell, knowing, knew: 0.16103343892183927\n",
      "cbow_300: falling, fell, knowing, knew: 0.01912836021160874\n",
      "cbow_50_dense: falling, fell, knowing, knew: 0.018394198007298426\n",
      "cbow_150_dense: falling, fell, knowing, knew: 0.05989618949756096\n",
      "cbow_300_dense: falling, fell, knowing, knew: 0.037205425222480805\n",
      "skipgram_50: falling, fell, knowing, knew: 0.17557797488377444\n",
      "skipgram_150: falling, fell, knowing, knew: 0.007951683766348392\n",
      "skipgram_300: falling, fell, knowing, knew: 0.018869195113530815\n",
      "skipgram_50_dense: falling, fell, knowing, knew: 0.16193351261122524\n",
      "skipgram_150_dense: falling, fell, knowing, knew: 0.03656470212890241\n",
      "skipgram_300_dense: falling, fell, knowing, knew: 0.03872969424142178\n",
      "\n",
      "cbow_50: walk, walking, think, thinking: 0.23305398188264462\n",
      "cbow_150: walk, walking, think, thinking: 0.16217284732039994\n",
      "cbow_300: walk, walking, think, thinking: 0.1371422823556235\n",
      "cbow_50_dense: walk, walking, think, thinking: 0.441744421903988\n",
      "cbow_150_dense: walk, walking, think, thinking: 0.27691568613316025\n",
      "cbow_300_dense: walk, walking, think, thinking: 0.25241882965411033\n",
      "skipgram_50: walk, walking, think, thinking: 0.08699870386228876\n",
      "skipgram_150: walk, walking, think, thinking: 0.048164187216711285\n",
      "skipgram_300: walk, walking, think, thinking: 0.042193790238127006\n",
      "skipgram_50_dense: walk, walking, think, thinking: 0.11086919505279523\n",
      "skipgram_150_dense: walk, walking, think, thinking: 0.039340863036024035\n",
      "skipgram_300_dense: walk, walking, think, thinking: 0.020751693251079326\n",
      "\n",
      "cbow_50: child, children, cat, cats: 0.5761045501314452\n",
      "cbow_150: child, children, cat, cats: 0.6283387407761182\n",
      "cbow_300: child, children, cat, cats: 0.4224878099785585\n",
      "cbow_50_dense: child, children, cat, cats: 0.13089713945022188\n",
      "cbow_150_dense: child, children, cat, cats: 0.31170060389105086\n",
      "cbow_300_dense: child, children, cat, cats: 0.15971883179637444\n",
      "skipgram_50: child, children, cat, cats: 0.16421092031258114\n",
      "skipgram_150: child, children, cat, cats: 0.09861341942503546\n",
      "skipgram_300: child, children, cat, cats: 0.19210569119480972\n",
      "skipgram_50_dense: child, children, cat, cats: 0.11475457926841195\n",
      "skipgram_150_dense: child, children, cat, cats: 0.07555755343684083\n",
      "skipgram_300_dense: child, children, cat, cats: 0.08558659954598827\n",
      "\n",
      "cbow_50: dog, dogs, eye, eyes: 0.048068004590513976\n",
      "cbow_150: dog, dogs, eye, eyes: 0.18301195503900555\n",
      "cbow_300: dog, dogs, eye, eyes: 0.08293971404713851\n",
      "cbow_50_dense: dog, dogs, eye, eyes: 0.009944152990215106\n",
      "cbow_150_dense: dog, dogs, eye, eyes: 0.00018806916728422024\n",
      "cbow_300_dense: dog, dogs, eye, eyes: 0.04959143883742041\n",
      "skipgram_50: dog, dogs, eye, eyes: 0.3073735203911106\n",
      "skipgram_150: dog, dogs, eye, eyes: 0.03872548838907464\n",
      "skipgram_300: dog, dogs, eye, eyes: 0.11077085600100203\n",
      "skipgram_50_dense: dog, dogs, eye, eyes: 0.014302918123874776\n",
      "skipgram_150_dense: dog, dogs, eye, eyes: 0.04161267376478868\n",
      "skipgram_300_dense: dog, dogs, eye, eyes: 0.09854696917931136\n",
      "\n",
      "cbow_50: hand, hands, rat, rats: 0.20928379513093132\n",
      "cbow_150: hand, hands, rat, rats: 0.08922689088034921\n",
      "cbow_300: hand, hands, rat, rats: 0.06167524716738153\n",
      "cbow_50_dense: hand, hands, rat, rats: 0.2241956513486761\n",
      "cbow_150_dense: hand, hands, rat, rats: 0.08479348857676028\n",
      "cbow_300_dense: hand, hands, rat, rats: 0.21763028239299223\n",
      "skipgram_50: hand, hands, rat, rats: 0.05868043068041718\n",
      "skipgram_150: hand, hands, rat, rats: 0.0023784410273843502\n",
      "skipgram_300: hand, hands, rat, rats: 0.04039324863447219\n",
      "skipgram_50_dense: hand, hands, rat, rats: 0.000745369944340421\n",
      "skipgram_150_dense: hand, hands, rat, rats: 0.18282660345720494\n",
      "skipgram_300_dense: hand, hands, rat, rats: 0.07454463081175015\n",
      "\n",
      "cbow_50: eat, eats, find, finds: 0.6344386909160316\n",
      "cbow_150: eat, eats, find, finds: 0.6230622716693793\n",
      "cbow_300: eat, eats, find, finds: 0.38332741252697833\n",
      "cbow_50_dense: eat, eats, find, finds: 0.11014595751932027\n",
      "cbow_150_dense: eat, eats, find, finds: 0.022188421800295247\n",
      "cbow_300_dense: eat, eats, find, finds: 0.02799474581397439\n",
      "skipgram_50: eat, eats, find, finds: 0.006328331663710655\n",
      "skipgram_150: eat, eats, find, finds: 0.13826781398968432\n",
      "skipgram_300: eat, eats, find, finds: 0.06159956716563862\n",
      "skipgram_50_dense: eat, eats, find, finds: 0.022223655143363493\n",
      "skipgram_150_dense: eat, eats, find, finds: 0.04586212657365139\n",
      "skipgram_300_dense: eat, eats, find, finds: 0.004353422652560424\n",
      "\n",
      "cbow_50: find, finds, say, says: 0.19636398876648298\n",
      "cbow_150: find, finds, say, says: 0.3493458745768275\n",
      "cbow_300: find, finds, say, says: 0.4225110412871306\n",
      "cbow_50_dense: find, finds, say, says: 0.10255216118966275\n",
      "cbow_150_dense: find, finds, say, says: 0.04139482654371349\n",
      "cbow_300_dense: find, finds, say, says: 0.09204581834643971\n",
      "skipgram_50: find, finds, say, says: 0.3008822241971264\n",
      "skipgram_150: find, finds, say, says: 0.27305728189763656\n",
      "skipgram_300: find, finds, say, says: 0.2117274946468136\n",
      "skipgram_50_dense: find, finds, say, says: 0.21955934322292522\n",
      "skipgram_150_dense: find, finds, say, says: 0.02131875144526285\n",
      "skipgram_300_dense: find, finds, say, says: 0.024942033757297807\n",
      "\n",
      "cbow_50: old, older, good, better: 0.28356033517821916\n",
      "cbow_150: old, older, good, better: 0.3367662060157432\n",
      "cbow_300: old, older, good, better: 0.24294226160000545\n",
      "cbow_50_dense: old, older, good, better: 0.12562361925379575\n",
      "cbow_150_dense: old, older, good, better: 0.10944203217062437\n",
      "cbow_300_dense: old, older, good, better: 0.18656535061624072\n",
      "skipgram_50: old, older, good, better: 0.08069563744902247\n",
      "skipgram_150: old, older, good, better: 0.10060746006827065\n",
      "skipgram_300: old, older, good, better: 0.14252044931840813\n",
      "skipgram_50_dense: old, older, good, better: 0.006715441594898397\n",
      "skipgram_150_dense: old, older, good, better: 0.05311411308035306\n",
      "skipgram_300_dense: old, older, good, better: 0.05186729010261828\n",
      "\n",
      "cbow_50: large, larger, quick, quicker: 0.15041247724164664\n",
      "cbow_150: large, larger, quick, quicker: 0.23806847996439426\n",
      "cbow_300: large, larger, quick, quicker: 0.04205617897711103\n",
      "cbow_50_dense: large, larger, quick, quicker: 0.14810958793009651\n",
      "cbow_150_dense: large, larger, quick, quicker: 0.12186104289525825\n",
      "cbow_300_dense: large, larger, quick, quicker: 0.09311372510784723\n",
      "skipgram_50: large, larger, quick, quicker: 0.007782517555859513\n",
      "skipgram_150: large, larger, quick, quicker: 0.07206240388614367\n",
      "skipgram_300: large, larger, quick, quicker: 0.02962600187265431\n",
      "skipgram_50_dense: large, larger, quick, quicker: 0.12221104436704669\n",
      "skipgram_150_dense: large, larger, quick, quicker: 0.053115179996420764\n",
      "skipgram_300_dense: large, larger, quick, quicker: 0.06817445995579048\n",
      "\n",
      "cbow_50: go, going, listen, listening: 0.004348558915977116\n",
      "cbow_150: go, going, listen, listening: 0.04591844648923439\n",
      "cbow_300: go, going, listen, listening: 0.028175657728302012\n",
      "cbow_50_dense: go, going, listen, listening: 0.019190198412343568\n",
      "cbow_150_dense: go, going, listen, listening: 0.13541379022058453\n",
      "cbow_300_dense: go, going, listen, listening: 0.08877512926435754\n",
      "skipgram_50: go, going, listen, listening: 0.1458218536917652\n",
      "skipgram_150: go, going, listen, listening: 0.010557247628522618\n",
      "skipgram_300: go, going, listen, listening: 0.03259419484187035\n",
      "skipgram_50_dense: go, going, listen, listening: 0.14996689018468176\n",
      "skipgram_150_dense: go, going, listen, listening: 0.04243841588618983\n",
      "skipgram_300_dense: go, going, listen, listening: 0.010873228635317379\n",
      "\n",
      "cbow_50: run, running, walk, walking: 0.43239444601331156\n",
      "cbow_150: run, running, walk, walking: 0.17316018462778576\n",
      "cbow_300: run, running, walk, walking: 0.06752979323171769\n",
      "cbow_50_dense: run, running, walk, walking: 0.19041077959930008\n",
      "cbow_150_dense: run, running, walk, walking: 0.08575569090759745\n",
      "cbow_300_dense: run, running, walk, walking: 0.13319373973395193\n",
      "skipgram_50: run, running, walk, walking: 0.061131275157370074\n",
      "skipgram_150: run, running, walk, walking: 0.07226312041817572\n",
      "skipgram_300: run, running, walk, walking: 0.027382636632413446\n",
      "skipgram_50_dense: run, running, walk, walking: 0.10158365041561519\n",
      "skipgram_150_dense: run, running, walk, walking: 0.03850630114665086\n",
      "skipgram_300_dense: run, running, walk, walking: 0.036897706755464\n",
      "\n",
      "cbow_50: run, running, think, thinking: 0.12738615012738252\n",
      "cbow_150: run, running, think, thinking: 0.1885880627853949\n",
      "cbow_300: run, running, think, thinking: 0.13662853663187174\n",
      "cbow_50_dense: run, running, think, thinking: 0.09327913484627907\n",
      "cbow_150_dense: run, running, think, thinking: 0.09934669415267226\n",
      "cbow_300_dense: run, running, think, thinking: 0.013760378794701674\n",
      "skipgram_50: run, running, think, thinking: 0.22735648389480612\n",
      "skipgram_150: run, running, think, thinking: 0.1613294128885081\n",
      "skipgram_300: run, running, think, thinking: 0.11307505983692813\n",
      "skipgram_50_dense: run, running, think, thinking: 0.012145371455604355\n",
      "skipgram_150_dense: run, running, think, thinking: 0.06641353890075766\n",
      "skipgram_300_dense: run, running, think, thinking: 0.13502023716520042\n",
      "\n",
      "cbow_50: say, saying, sit, sitting: 0.13290110049743256\n",
      "cbow_150: say, saying, sit, sitting: 0.13794787877818132\n",
      "cbow_300: say, saying, sit, sitting: 0.1255869428992714\n",
      "cbow_50_dense: say, saying, sit, sitting: 0.08854998828125173\n",
      "cbow_150_dense: say, saying, sit, sitting: 0.08481168346115567\n",
      "cbow_300_dense: say, saying, sit, sitting: 0.002778512915029485\n",
      "skipgram_50: say, saying, sit, sitting: 0.034907572539578484\n",
      "skipgram_150: say, saying, sit, sitting: 0.12000329896836949\n",
      "skipgram_300: say, saying, sit, sitting: 0.022278989764921892\n",
      "skipgram_50_dense: say, saying, sit, sitting: 0.2291511923882307\n",
      "skipgram_150_dense: say, saying, sit, sitting: 0.08249327141657764\n",
      "skipgram_300_dense: say, saying, sit, sitting: 0.031370623390230355\n",
      "\n",
      "cbow_50: alice, she, rabbit, he: 0.3032260713980009\n",
      "cbow_150: alice, she, rabbit, he: 0.28750781874194553\n",
      "cbow_300: alice, she, rabbit, he: 0.23737374549441895\n",
      "cbow_50_dense: alice, she, rabbit, he: 0.37400362858646385\n",
      "cbow_150_dense: alice, she, rabbit, he: 0.2604214341177389\n",
      "cbow_300_dense: alice, she, rabbit, he: 0.22134533492778896\n",
      "skipgram_50: alice, she, rabbit, he: 0.5426801245234731\n",
      "skipgram_150: alice, she, rabbit, he: 0.22598356754298\n",
      "skipgram_300: alice, she, rabbit, he: 0.10919359344013549\n",
      "skipgram_50_dense: alice, she, rabbit, he: 0.08122499625428377\n",
      "skipgram_150_dense: alice, she, rabbit, he: 0.19001593659421726\n",
      "skipgram_300_dense: alice, she, rabbit, he: 0.1196936498430301\n",
      "\n",
      "cbow_50: alice, her, rabbit, him: 0.4245334730572496\n",
      "cbow_150: alice, her, rabbit, him: 0.3949279690641324\n",
      "cbow_300: alice, her, rabbit, him: 0.4694802520899805\n",
      "cbow_50_dense: alice, her, rabbit, him: 0.37489014507553303\n",
      "cbow_150_dense: alice, her, rabbit, him: 0.2922573512779353\n",
      "cbow_300_dense: alice, her, rabbit, him: 0.3085777141782657\n",
      "skipgram_50: alice, her, rabbit, him: 0.47631211185659833\n",
      "skipgram_150: alice, her, rabbit, him: 0.16850111255729083\n",
      "skipgram_300: alice, her, rabbit, him: 0.1471057818985327\n",
      "skipgram_50_dense: alice, her, rabbit, him: 0.003912821913825373\n",
      "skipgram_150_dense: alice, her, rabbit, him: 0.079360369362521\n",
      "skipgram_300_dense: alice, her, rabbit, him: 0.004352950260186055\n",
      "\n",
      "cbow_50: alice, girl, rabbit, sir: 0.38352821418807104\n",
      "cbow_150: alice, girl, rabbit, sir: 0.3037741386102526\n",
      "cbow_300: alice, girl, rabbit, sir: 0.29111823565411055\n",
      "cbow_50_dense: alice, girl, rabbit, sir: 0.296456905787305\n",
      "cbow_150_dense: alice, girl, rabbit, sir: 0.18437463780691493\n",
      "cbow_300_dense: alice, girl, rabbit, sir: 0.17745145079999616\n",
      "skipgram_50: alice, girl, rabbit, sir: 0.20881831983410187\n",
      "skipgram_150: alice, girl, rabbit, sir: 0.06086273438062511\n",
      "skipgram_300: alice, girl, rabbit, sir: 0.043377803272707655\n",
      "skipgram_50_dense: alice, girl, rabbit, sir: 0.007664461700388371\n",
      "skipgram_150_dense: alice, girl, rabbit, sir: 0.013923791377918283\n",
      "skipgram_300_dense: alice, girl, rabbit, sir: 0.16162886469339285\n",
      "\n",
      "cbow_50: dinah, cat, alice, girl: 0.18871490618643927\n",
      "cbow_150: dinah, cat, alice, girl: 0.1988998323029214\n",
      "cbow_300: dinah, cat, alice, girl: 0.21994575208961464\n",
      "cbow_50_dense: dinah, cat, alice, girl: 0.01817282196713359\n",
      "cbow_150_dense: dinah, cat, alice, girl: 0.12974284936731623\n",
      "cbow_300_dense: dinah, cat, alice, girl: 0.0973591792683185\n",
      "skipgram_50: dinah, cat, alice, girl: 0.3257029643937467\n",
      "skipgram_150: dinah, cat, alice, girl: 0.2983575332887626\n",
      "skipgram_300: dinah, cat, alice, girl: 0.12466987631479041\n",
      "skipgram_50_dense: dinah, cat, alice, girl: 0.06226421184792411\n",
      "skipgram_150_dense: dinah, cat, alice, girl: 0.04952489944505424\n",
      "skipgram_300_dense: dinah, cat, alice, girl: 0.016715979149657174\n",
      "\n",
      "cbow_50: his, her, he, she: 0.08099932963910215\n",
      "cbow_150: his, her, he, she: 0.03569783846020872\n",
      "cbow_300: his, her, he, she: 0.022474709476888687\n",
      "cbow_50_dense: his, her, he, she: 0.25305776920456663\n",
      "cbow_150_dense: his, her, he, she: 0.05257730241374489\n",
      "cbow_300_dense: his, her, he, she: 0.12253203367780965\n",
      "skipgram_50: his, her, he, she: 0.6315077702042393\n",
      "skipgram_150: his, her, he, she: 0.30525691255592236\n",
      "skipgram_300: his, her, he, she: 0.21834270821319915\n",
      "skipgram_50_dense: his, her, he, she: 0.2154861486119754\n",
      "skipgram_150_dense: his, her, he, she: 0.14655767256694316\n",
      "skipgram_300_dense: his, her, he, she: 0.1511302407262479\n",
      "\n",
      "cbow_50: long, longer, quick, quicker: 0.4120102891993884\n",
      "cbow_150: long, longer, quick, quicker: 0.23017015273506933\n",
      "cbow_300: long, longer, quick, quicker: 0.09401260595447117\n",
      "cbow_50_dense: long, longer, quick, quicker: 0.01408052840685802\n",
      "cbow_150_dense: long, longer, quick, quicker: 0.007133586407366825\n",
      "cbow_300_dense: long, longer, quick, quicker: 0.07831883522036924\n",
      "skipgram_50: long, longer, quick, quicker: 0.21263578353266288\n",
      "skipgram_150: long, longer, quick, quicker: 0.0713668253047118\n",
      "skipgram_300: long, longer, quick, quicker: 0.03475701071170782\n",
      "skipgram_50_dense: long, longer, quick, quicker: 0.05400072789551662\n",
      "skipgram_150_dense: long, longer, quick, quicker: 0.11150849188104847\n",
      "skipgram_300_dense: long, longer, quick, quicker: 0.03754801662507641\n",
      "\n",
      "cbow_50: long, longer, small, smaller: 0.4318003131750905\n",
      "cbow_150: long, longer, small, smaller: 0.3554968324347603\n",
      "cbow_300: long, longer, small, smaller: 0.19269746490298645\n",
      "cbow_50_dense: long, longer, small, smaller: 0.5372986667713919\n",
      "cbow_150_dense: long, longer, small, smaller: 0.3725341328264276\n",
      "cbow_300_dense: long, longer, small, smaller: 0.35016791043829654\n",
      "skipgram_50: long, longer, small, smaller: 0.30926336324955456\n",
      "skipgram_150: long, longer, small, smaller: 0.11679533580010204\n",
      "skipgram_300: long, longer, small, smaller: 0.17801511863882985\n",
      "skipgram_50_dense: long, longer, small, smaller: 0.06976419471060234\n",
      "skipgram_150_dense: long, longer, small, smaller: 0.008430045436527846\n",
      "skipgram_300_dense: long, longer, small, smaller: 0.02207475087097485\n",
      "\n",
      "cbow_50: long, longer, bad, worse: 0.3260491473042464\n",
      "cbow_150: long, longer, bad, worse: 0.15212735080104456\n",
      "cbow_300: long, longer, bad, worse: 0.20373219592586617\n",
      "cbow_50_dense: long, longer, bad, worse: 0.08853810932159445\n",
      "cbow_150_dense: long, longer, bad, worse: 0.02362576370261302\n",
      "cbow_300_dense: long, longer, bad, worse: 0.02967005557613777\n",
      "skipgram_50: long, longer, bad, worse: 0.13720585542509073\n",
      "skipgram_150: long, longer, bad, worse: 0.17892863936691286\n",
      "skipgram_300: long, longer, bad, worse: 0.10039588396824377\n",
      "skipgram_50_dense: long, longer, bad, worse: 0.0591265043266381\n",
      "skipgram_150_dense: long, longer, bad, worse: 0.026776340215094604\n",
      "skipgram_300_dense: long, longer, bad, worse: 0.0009287152378468827\n",
      "\n",
      "cbow_50: go, going, look, looking: 0.04482878540457188\n",
      "cbow_150: go, going, look, looking: 0.13521208123901596\n",
      "cbow_300: go, going, look, looking: 0.11739576262876612\n",
      "cbow_50_dense: go, going, look, looking: 0.2275989682841857\n",
      "cbow_150_dense: go, going, look, looking: 0.08095648478867602\n",
      "cbow_300_dense: go, going, look, looking: 0.014954370905789528\n",
      "skipgram_50: go, going, look, looking: 0.19612565040854993\n",
      "skipgram_150: go, going, look, looking: 0.2366986027145685\n",
      "skipgram_300: go, going, look, looking: 0.2300817760171532\n",
      "skipgram_50_dense: go, going, look, looking: 0.14061684371374158\n",
      "skipgram_150_dense: go, going, look, looking: 0.14720249473774485\n",
      "skipgram_300_dense: go, going, look, looking: 0.002864495321771528\n",
      "\n",
      "cbow_50: listen, listening, look, looking: 0.3802069701610734\n",
      "cbow_150: listen, listening, look, looking: 0.36921053308958424\n",
      "cbow_300: listen, listening, look, looking: 0.23802999618462123\n",
      "cbow_50_dense: listen, listening, look, looking: 0.03956834867672034\n",
      "cbow_150_dense: listen, listening, look, looking: 0.025226025836383444\n",
      "cbow_300_dense: listen, listening, look, looking: 0.08170528413458206\n",
      "skipgram_50: listen, listening, look, looking: 0.16071493864813735\n",
      "skipgram_150: listen, listening, look, looking: 0.08121301306304535\n",
      "skipgram_300: listen, listening, look, looking: 0.028332544949943285\n",
      "skipgram_50_dense: listen, listening, look, looking: 0.3328211143150717\n",
      "skipgram_150_dense: listen, listening, look, looking: 0.0595487007636639\n",
      "skipgram_300_dense: listen, listening, look, looking: 0.0406596642434014\n",
      "\n",
      "cbow_50: swim, swimming, sit, sitting: 0.48978575850663114\n",
      "cbow_150: swim, swimming, sit, sitting: 0.22129192423968272\n",
      "cbow_300: swim, swimming, sit, sitting: 0.04745686624994828\n",
      "cbow_50_dense: swim, swimming, sit, sitting: 0.021958860917220397\n",
      "cbow_150_dense: swim, swimming, sit, sitting: 0.17068327726846955\n",
      "cbow_300_dense: swim, swimming, sit, sitting: 0.03918166245483594\n",
      "skipgram_50: swim, swimming, sit, sitting: 0.11537361617847666\n",
      "skipgram_150: swim, swimming, sit, sitting: 0.04493825332961289\n",
      "skipgram_300: swim, swimming, sit, sitting: 0.013933906731029667\n",
      "skipgram_50_dense: swim, swimming, sit, sitting: 0.03028533116032402\n",
      "skipgram_150_dense: swim, swimming, sit, sitting: 0.05055787779525484\n",
      "skipgram_300_dense: swim, swimming, sit, sitting: 0.03563140413128219\n",
      "\n",
      "cbow_50: run, running, listen, listening: 0.7591559036884049\n",
      "cbow_150: run, running, listen, listening: 0.500506534222073\n",
      "cbow_300: run, running, listen, listening: 0.2172115315370583\n",
      "cbow_50_dense: run, running, listen, listening: 0.1839417128743973\n",
      "cbow_150_dense: run, running, listen, listening: 0.22631221236606874\n",
      "cbow_300_dense: run, running, listen, listening: 0.16730155288174092\n",
      "skipgram_50: run, running, listen, listening: 0.09140670488699115\n",
      "skipgram_150: run, running, listen, listening: 0.15598901932548082\n",
      "skipgram_300: run, running, listen, listening: 0.005648185183561339\n",
      "skipgram_50_dense: run, running, listen, listening: 0.0398748541017174\n",
      "skipgram_150_dense: run, running, listen, listening: 0.012654900797069137\n",
      "skipgram_300_dense: run, running, listen, listening: 0.052294495200113054\n",
      "\n",
      "cbow_50: think, thinking, read, reading: 0.2990498498151042\n",
      "cbow_150: think, thinking, read, reading: 0.2330940450897781\n",
      "cbow_300: think, thinking, read, reading: 0.16911559484697625\n",
      "cbow_50_dense: think, thinking, read, reading: 0.3787095492702201\n",
      "cbow_150_dense: think, thinking, read, reading: 0.3078049519115134\n",
      "cbow_300_dense: think, thinking, read, reading: 0.08962903058811725\n",
      "skipgram_50: think, thinking, read, reading: 0.013209059752715389\n",
      "skipgram_150: think, thinking, read, reading: 0.21845893070743158\n",
      "skipgram_300: think, thinking, read, reading: 0.04166652322420212\n",
      "skipgram_50_dense: think, thinking, read, reading: 0.126542806632079\n",
      "skipgram_150_dense: think, thinking, read, reading: 0.0181158051746606\n",
      "skipgram_300_dense: think, thinking, read, reading: 0.03892256124563785\n",
      "\n",
      "cbow_50: up, down, close, far: 0.36010716857066855\n",
      "cbow_150: up, down, close, far: 0.36598875609203435\n",
      "cbow_300: up, down, close, far: 0.21333871878277946\n",
      "cbow_50_dense: up, down, close, far: 0.19196383523652996\n",
      "cbow_150_dense: up, down, close, far: 0.009307886939470968\n",
      "cbow_300_dense: up, down, close, far: 0.007063529840594001\n",
      "skipgram_50: up, down, close, far: 0.1748337104403164\n",
      "skipgram_150: up, down, close, far: 0.16686136569449184\n",
      "skipgram_300: up, down, close, far: 0.10413951869465775\n",
      "skipgram_50_dense: up, down, close, far: 0.04473971846960458\n",
      "skipgram_150_dense: up, down, close, far: 0.14023607002769808\n",
      "skipgram_300_dense: up, down, close, far: 0.018702310370623847\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#cbow and skipgram analogy performance (cosine similarity)\n",
    "cbow50analogylist=[]\n",
    "cbow50denseanalogylist=[]\n",
    "cbow150analogylist=[]\n",
    "cbow150denseanalogylist=[]\n",
    "cbow300analogylist=[]\n",
    "cbow300denseanalogylist=[]\n",
    "skipgram50analogylist=[]\n",
    "skipgram50denseanalogylist=[]\n",
    "skipgram150analogylist=[]\n",
    "skipgram150denseanalogylist=[]\n",
    "skipgram300analogylist=[]\n",
    "skipgram300denseanalogylist=[]\n",
    "co_occurrencelist=[]\n",
    "\n",
    "\n",
    "for analogy in analogy_list:\n",
    "    if(analogy[0] in tokenizer.word_index and analogy[1] in tokenizer.word_index and analogy[2] in tokenizer.word_index and analogy[3] in tokenizer.word_index):\n",
    "        try:\n",
    "            co_occurrenceanalogy=analogy_check(analogy,tf_cooc, tokenizer.word_index )\n",
    "            cbow50analogy=analogy_check(analogy,embed_cbow_50, tokenizer.word_index )\n",
    "            cbow150analogy=analogy_check(analogy,embed_cbow_150, tokenizer.word_index )\n",
    "            cbow300analogy=analogy_check(analogy,embed_cbow_300, tokenizer.word_index )\n",
    "            cbow50denseanalogy=analogy_check(analogy,embed_cbow_50_dense, tokenizer.word_index )\n",
    "            cbow150denseanalogy=analogy_check(analogy,embed_cbow_150_dense, tokenizer.word_index )\n",
    "            cbow300denseanalogy=analogy_check(analogy,embed_cbow_300_dense, tokenizer.word_index )\n",
    "            skipgram50analogy=analogy_check(analogy,embed_skipgram_50, tokenizer.word_index )\n",
    "            skipgram150analogy=analogy_check(analogy,embed_skipgram_150, tokenizer.word_index )\n",
    "            skipgram300analogy=analogy_check(analogy,embed_skipgram_300, tokenizer.word_index )\n",
    "            skipgram50denseanalogy=analogy_check(analogy,embed_skipgram_50_dense, tokenizer.word_index )\n",
    "            skipgram150denseanalogy=analogy_check(analogy,embed_skipgram_150_dense, tokenizer.word_index )\n",
    "            skipgram300denseanalogy=analogy_check(analogy,embed_skipgram_300_dense, tokenizer.word_index )\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(\"cbow_50: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow50analogy))\n",
    "            print(\"cbow_150: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow150analogy))\n",
    "            print(\"cbow_300: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow300analogy))\n",
    "            print(\"cbow_50_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow50denseanalogy))\n",
    "            print(\"cbow_150_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow150denseanalogy))\n",
    "            print(\"cbow_300_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow300denseanalogy))\n",
    "            print(\"skipgram_50: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram50analogy))\n",
    "            print(\"skipgram_150: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram150analogy))\n",
    "            print(\"skipgram_300: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram300analogy))\n",
    "            print(\"skipgram_50_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram50denseanalogy))\n",
    "            print(\"skipgram_150_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram150denseanalogy))\n",
    "            print(\"skipgram_300_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram300denseanalogy))\n",
    "            \n",
    "            \n",
    "            co_occurrencelist.append(co_occurrenceanalogy)\n",
    "            cbow50analogylist.append(cbow50analogy)\n",
    "            cbow150analogylist.append(cbow150analogy)\n",
    "            cbow300analogylist.append(cbow300analogy)\n",
    "            cbow50denseanalogylist.append(cbow50denseanalogy)\n",
    "            cbow150denseanalogylist.append(cbow150denseanalogy)\n",
    "            cbow300denseanalogylist.append(cbow300denseanalogy)\n",
    "            skipgram50analogylist.append(skipgram50analogy)\n",
    "            skipgram150analogylist.append(skipgram150analogy)\n",
    "            skipgram300analogylist.append(skipgram300analogy)\n",
    "            skipgram50denseanalogylist.append(skipgram50denseanalogy)\n",
    "            skipgram150denseanalogylist.append(skipgram150denseanalogy)\n",
    "            skipgram300denseanalogylist.append(skipgram300denseanalogy)\n",
    "            \n",
    "            \n",
    "            print()\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbow_50: sudden, suddenly, usual, usually: come\n",
      "cbow_150: sudden, suddenly, usual, usually: come\n",
      "cbow_300: sudden, suddenly, usual, usually: come\n",
      "cbow_50_dense: sudden, suddenly, usual, usually: so\n",
      "cbow_150_dense: sudden, suddenly, usual, usually: so\n",
      "cbow_300_dense: sudden, suddenly, usual, usually: so\n",
      "skipgram_50: sudden, suddenly, usual, usually: air\n",
      "skipgram_150: sudden, suddenly, usual, usually: he\n",
      "skipgram_300: sudden, suddenly, usual, usually: shall\n",
      "skipgram_50_dense: sudden, suddenly, usual, usually: ringlets\n",
      "skipgram_150_dense: sudden, suddenly, usual, usually: offer\n",
      "skipgram_300_dense: sudden, suddenly, usual, usually: which\n",
      "\n",
      "cbow_50: bad, worse, good, better: now\n",
      "cbow_150: bad, worse, good, better: thump\n",
      "cbow_300: bad, worse, good, better: the\n",
      "cbow_50_dense: bad, worse, good, better: shore\n",
      "cbow_150_dense: bad, worse, good, better: girl\n",
      "cbow_300_dense: bad, worse, good, better: the\n",
      "skipgram_50: bad, worse, good, better: miles\n",
      "skipgram_150: bad, worse, good, better: question\n",
      "skipgram_300: bad, worse, good, better: throw\n",
      "skipgram_50_dense: bad, worse, good, better: waited\n",
      "skipgram_150_dense: bad, worse, good, better: find\n",
      "skipgram_300_dense: bad, worse, good, better: splendidly\n",
      "\n",
      "cbow_50: go, going, look, looking: found\n",
      "cbow_150: go, going, look, looking: found\n",
      "cbow_300: go, going, look, looking: have\n",
      "cbow_50_dense: go, going, look, looking: fancy\n",
      "cbow_150_dense: go, going, look, looking: why\n",
      "cbow_300_dense: go, going, look, looking: have\n",
      "skipgram_50: go, going, look, looking: on\n",
      "skipgram_150: go, going, look, looking: her\n",
      "skipgram_300: go, going, look, looking: thing\n",
      "skipgram_50_dense: go, going, look, looking: her\n",
      "skipgram_150_dense: go, going, look, looking: cunning\n",
      "skipgram_300_dense: go, going, look, looking: avoid\n",
      "\n",
      "cbow_50: he, she, his, her: off\n",
      "cbow_150: he, she, his, her: off\n",
      "cbow_300: he, she, his, her: off\n",
      "cbow_50_dense: he, she, his, her: off\n",
      "cbow_150_dense: he, she, his, her: off\n",
      "cbow_300_dense: he, she, his, her: off\n",
      "skipgram_50: he, she, his, her: it\n",
      "skipgram_150: he, she, his, her: it\n",
      "skipgram_300: he, she, his, her: it\n",
      "skipgram_50_dense: he, she, his, her: bank\n",
      "skipgram_150_dense: he, she, his, her: idea\n",
      "skipgram_300_dense: he, she, his, her: alice\n",
      "\n",
      "cbow_50: brother, sister, his, her: ask\n",
      "cbow_150: brother, sister, his, her: ask\n",
      "cbow_300: brother, sister, his, her: away\n",
      "cbow_50_dense: brother, sister, his, her: leave\n",
      "cbow_150_dense: brother, sister, his, her: sure\n",
      "cbow_300_dense: brother, sister, his, her: was\n",
      "skipgram_50: brother, sister, his, her: pardon\n",
      "skipgram_150: brother, sister, his, her: through\n",
      "skipgram_300: brother, sister, his, her: shoulders\n",
      "skipgram_50_dense: brother, sister, his, her: seen\n",
      "skipgram_150_dense: brother, sister, his, her: throat\n",
      "skipgram_300_dense: brother, sister, his, her: come\n",
      "\n",
      "cbow_50: listen, listening, look, looking: filled\n",
      "cbow_150: listen, listening, look, looking: filled\n",
      "cbow_300: listen, listening, look, looking: its\n",
      "cbow_50_dense: listen, listening, look, looking: girl\n",
      "cbow_150_dense: listen, listening, look, looking: currants\n",
      "cbow_300_dense: listen, listening, look, looking: into\n",
      "skipgram_50: listen, listening, look, looking: pair\n",
      "skipgram_150: listen, listening, look, looking: crab\n",
      "skipgram_300: listen, listening, look, looking: dull\n",
      "skipgram_50_dense: listen, listening, look, looking: water\n",
      "skipgram_150_dense: listen, listening, look, looking: won\n",
      "skipgram_300_dense: listen, listening, look, looking: calling\n",
      "\n",
      "cbow_50: saying, said, thinking, thought: quite\n",
      "cbow_150: saying, said, thinking, thought: quite\n",
      "cbow_300: saying, said, thinking, thought: quite\n",
      "cbow_50_dense: saying, said, thinking, thought: quite\n",
      "cbow_150_dense: saying, said, thinking, thought: quite\n",
      "cbow_300_dense: saying, said, thinking, thought: quite\n",
      "skipgram_50: saying, said, thinking, thought: or\n",
      "skipgram_150: saying, said, thinking, thought: with\n",
      "skipgram_300: saying, said, thinking, thought: s\n",
      "skipgram_50_dense: saying, said, thinking, thought: usually\n",
      "skipgram_150_dense: saying, said, thinking, thought: maps\n",
      "skipgram_300_dense: saying, said, thinking, thought: had\n",
      "\n",
      "cbow_50: bird, birds, cat, cats: our\n",
      "cbow_150: bird, birds, cat, cats: our\n",
      "cbow_300: bird, birds, cat, cats: our\n",
      "cbow_50_dense: bird, birds, cat, cats: see\n",
      "cbow_150_dense: bird, birds, cat, cats: our\n",
      "cbow_300_dense: bird, birds, cat, cats: see\n",
      "skipgram_50: bird, birds, cat, cats: said\n",
      "skipgram_150: bird, birds, cat, cats: up\n",
      "skipgram_300: bird, birds, cat, cats: high\n",
      "skipgram_50_dense: bird, birds, cat, cats: tidy\n",
      "skipgram_150_dense: bird, birds, cat, cats: skurried\n",
      "skipgram_300_dense: bird, birds, cat, cats: improve\n",
      "\n",
      "cbow_50: good, better, old, older: never\n",
      "cbow_150: good, better, old, older: coming\n",
      "cbow_300: good, better, old, older: no\n",
      "cbow_50_dense: good, better, old, older: never\n",
      "cbow_150_dense: good, better, old, older: never\n",
      "cbow_300_dense: good, better, old, older: never\n",
      "skipgram_50: good, better, old, older: after\n",
      "skipgram_150: good, better, old, older: despair\n",
      "skipgram_300: good, better, old, older: have\n",
      "skipgram_50_dense: good, better, old, older: your\n",
      "skipgram_150_dense: good, better, old, older: absurd\n",
      "skipgram_300_dense: good, better, old, older: mice\n",
      "\n",
      "cbow_50: good, better, quick, quicker: never\n",
      "cbow_150: good, better, quick, quicker: coming\n",
      "cbow_300: good, better, quick, quicker: no\n",
      "cbow_50_dense: good, better, quick, quicker: never\n",
      "cbow_150_dense: good, better, quick, quicker: never\n",
      "cbow_300_dense: good, better, quick, quicker: never\n",
      "skipgram_50: good, better, quick, quicker: after\n",
      "skipgram_150: good, better, quick, quicker: despair\n",
      "skipgram_300: good, better, quick, quicker: have\n",
      "skipgram_50_dense: good, better, quick, quicker: your\n",
      "skipgram_150_dense: good, better, quick, quicker: absurd\n",
      "skipgram_300_dense: good, better, quick, quicker: mice\n",
      "\n",
      "cbow_50: large, largest, good, best: rules\n",
      "cbow_150: large, largest, good, best: rules\n",
      "cbow_300: large, largest, good, best: slowly\n",
      "cbow_50_dense: large, largest, good, best: have\n",
      "cbow_150_dense: large, largest, good, best: his\n",
      "cbow_300_dense: large, largest, good, best: rules\n",
      "skipgram_50: large, largest, good, best: door\n",
      "skipgram_150: large, largest, good, best: cool\n",
      "skipgram_300: large, largest, good, best: rabbit\n",
      "skipgram_50_dense: large, largest, good, best: dripping\n",
      "skipgram_150_dense: large, largest, good, best: deep\n",
      "skipgram_300_dense: large, largest, good, best: reach\n",
      "\n",
      "cbow_50: falling, fell, knowing, knew: trouble\n",
      "cbow_150: falling, fell, knowing, knew: trouble\n",
      "cbow_300: falling, fell, knowing, knew: small\n",
      "cbow_50_dense: falling, fell, knowing, knew: small\n",
      "cbow_150_dense: falling, fell, knowing, knew: small\n",
      "cbow_300_dense: falling, fell, knowing, knew: looked\n",
      "skipgram_50: falling, fell, knowing, knew: hour\n",
      "skipgram_150: falling, fell, knowing, knew: engraved\n",
      "skipgram_300: falling, fell, knowing, knew: bed\n",
      "skipgram_50_dense: falling, fell, knowing, knew: open\n",
      "skipgram_150_dense: falling, fell, knowing, knew: confused\n",
      "skipgram_300_dense: falling, fell, knowing, knew: or\n",
      "\n",
      "cbow_50: walk, walking, think, thinking: almost\n",
      "cbow_150: walk, walking, think, thinking: almost\n",
      "cbow_300: walk, walking, think, thinking: into\n",
      "cbow_50_dense: walk, walking, think, thinking: into\n",
      "cbow_150_dense: walk, walking, think, thinking: gloves\n",
      "cbow_300_dense: walk, walking, think, thinking: head\n",
      "skipgram_50: walk, walking, think, thinking: fountains\n",
      "skipgram_150: walk, walking, think, thinking: poky\n",
      "skipgram_300: walk, walking, think, thinking: hair\n",
      "skipgram_50_dense: walk, walking, think, thinking: fall\n",
      "skipgram_150_dense: walk, walking, think, thinking: history\n",
      "skipgram_300_dense: walk, walking, think, thinking: them\n",
      "\n",
      "cbow_50: child, children, cat, cats: mixed\n",
      "cbow_150: child, children, cat, cats: door\n",
      "cbow_300: child, children, cat, cats: find\n",
      "cbow_50_dense: child, children, cat, cats: morning\n",
      "cbow_150_dense: child, children, cat, cats: histories\n",
      "cbow_300_dense: child, children, cat, cats: know\n",
      "skipgram_50: child, children, cat, cats: refused\n",
      "skipgram_150: child, children, cat, cats: more\n",
      "skipgram_300: child, children, cat, cats: over\n",
      "skipgram_50_dense: child, children, cat, cats: wondered\n",
      "skipgram_150_dense: child, children, cat, cats: solid\n",
      "skipgram_300_dense: child, children, cat, cats: caused\n",
      "\n",
      "cbow_50: dog, dogs, eye, eyes: started\n",
      "cbow_150: dog, dogs, eye, eyes: who\n",
      "cbow_300: dog, dogs, eye, eyes: who\n",
      "cbow_50_dense: dog, dogs, eye, eyes: lory\n",
      "cbow_150_dense: dog, dogs, eye, eyes: another\n",
      "cbow_300_dense: dog, dogs, eye, eyes: grow\n",
      "skipgram_50: dog, dogs, eye, eyes: people\n",
      "skipgram_150: dog, dogs, eye, eyes: sort\n",
      "skipgram_300: dog, dogs, eye, eyes: one\n",
      "skipgram_50_dense: dog, dogs, eye, eyes: ugh\n",
      "skipgram_150_dense: dog, dogs, eye, eyes: lest\n",
      "skipgram_300_dense: dog, dogs, eye, eyes: houses\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbow_50: hand, hands, rat, rats: daisy\n",
      "cbow_150: hand, hands, rat, rats: daisy\n",
      "cbow_300: hand, hands, rat, rats: have\n",
      "cbow_50_dense: hand, hands, rat, rats: more\n",
      "cbow_150_dense: hand, hands, rat, rats: shall\n",
      "cbow_300_dense: hand, hands, rat, rats: shall\n",
      "skipgram_50: hand, hands, rat, rats: always\n",
      "skipgram_150: hand, hands, rat, rats: reach\n",
      "skipgram_300: hand, hands, rat, rats: whiskers\n",
      "skipgram_50_dense: hand, hands, rat, rats: whether\n",
      "skipgram_150_dense: hand, hands, rat, rats: window\n",
      "skipgram_300_dense: hand, hands, rat, rats: sister\n",
      "\n",
      "cbow_50: eat, eats, find, finds: room\n",
      "cbow_150: eat, eats, find, finds: face\n",
      "cbow_300: eat, eats, find, finds: getting\n",
      "cbow_50_dense: eat, eats, find, finds: foot\n",
      "cbow_150_dense: eat, eats, find, finds: ve\n",
      "cbow_300_dense: eat, eats, find, finds: ve\n",
      "skipgram_50: eat, eats, find, finds: narrow\n",
      "skipgram_150: eat, eats, find, finds: violently\n",
      "skipgram_300: eat, eats, find, finds: dipped\n",
      "skipgram_50_dense: eat, eats, find, finds: call\n",
      "skipgram_150_dense: eat, eats, find, finds: happen\n",
      "skipgram_300_dense: eat, eats, find, finds: alas\n",
      "\n",
      "cbow_50: find, finds, say, says: while\n",
      "cbow_150: find, finds, say, says: morning\n",
      "cbow_300: find, finds, say, says: yes\n",
      "cbow_50_dense: find, finds, say, says: middle\n",
      "cbow_150_dense: find, finds, say, says: up\n",
      "cbow_300_dense: find, finds, say, says: fell\n",
      "skipgram_50: find, finds, say, says: left\n",
      "skipgram_150: find, finds, say, says: pardon\n",
      "skipgram_300: find, finds, say, says: then\n",
      "skipgram_50_dense: find, finds, say, says: tidy\n",
      "skipgram_150_dense: find, finds, say, says: pity\n",
      "skipgram_300_dense: find, finds, say, says: natural\n",
      "\n",
      "cbow_50: old, older, good, better: cold\n",
      "cbow_150: old, older, good, better: perhaps\n",
      "cbow_300: old, older, good, better: its\n",
      "cbow_50_dense: old, older, good, better: something\n",
      "cbow_150_dense: old, older, good, better: don\n",
      "cbow_300_dense: old, older, good, better: don\n",
      "skipgram_50: old, older, good, better: grand\n",
      "skipgram_150: old, older, good, better: presented\n",
      "skipgram_300: old, older, good, better: than\n",
      "skipgram_50_dense: old, older, good, better: allow\n",
      "skipgram_150_dense: old, older, good, better: patriotic\n",
      "skipgram_300_dense: old, older, good, better: face\n",
      "\n",
      "cbow_50: large, larger, quick, quicker: speed\n",
      "cbow_150: large, larger, quick, quicker: nasty\n",
      "cbow_300: large, larger, quick, quicker: altogether\n",
      "cbow_50_dense: large, larger, quick, quicker: particular\n",
      "cbow_150_dense: large, larger, quick, quicker: seemed\n",
      "cbow_300_dense: large, larger, quick, quicker: your\n",
      "skipgram_50: large, larger, quick, quicker: saw\n",
      "skipgram_150: large, larger, quick, quicker: eat\n",
      "skipgram_300: large, larger, quick, quicker: upon\n",
      "skipgram_50_dense: large, larger, quick, quicker: voices\n",
      "skipgram_150_dense: large, larger, quick, quicker: fall\n",
      "skipgram_300_dense: large, larger, quick, quicker: authority\n",
      "\n",
      "cbow_50: go, going, listen, listening: found\n",
      "cbow_150: go, going, listen, listening: found\n",
      "cbow_300: go, going, listen, listening: have\n",
      "cbow_50_dense: go, going, listen, listening: fancy\n",
      "cbow_150_dense: go, going, listen, listening: why\n",
      "cbow_300_dense: go, going, listen, listening: have\n",
      "skipgram_50: go, going, listen, listening: on\n",
      "skipgram_150: go, going, listen, listening: her\n",
      "skipgram_300: go, going, listen, listening: thing\n",
      "skipgram_50_dense: go, going, listen, listening: her\n",
      "skipgram_150_dense: go, going, listen, listening: cunning\n",
      "skipgram_300_dense: go, going, listen, listening: avoid\n",
      "\n",
      "cbow_50: run, running, walk, walking: us\n",
      "cbow_150: run, running, walk, walking: moment\n",
      "cbow_300: run, running, walk, walking: than\n",
      "cbow_50_dense: run, running, walk, walking: tunnel\n",
      "cbow_150_dense: run, running, walk, walking: used\n",
      "cbow_300_dense: run, running, walk, walking: beds\n",
      "skipgram_50: run, running, walk, walking: happens\n",
      "skipgram_150: run, running, walk, walking: latin\n",
      "skipgram_300: run, running, walk, walking: our\n",
      "skipgram_50_dense: run, running, walk, walking: splashing\n",
      "skipgram_150_dense: run, running, walk, walking: eat\n",
      "skipgram_300_dense: run, running, walk, walking: her\n",
      "\n",
      "cbow_50: run, running, think, thinking: us\n",
      "cbow_150: run, running, think, thinking: moment\n",
      "cbow_300: run, running, think, thinking: than\n",
      "cbow_50_dense: run, running, think, thinking: tunnel\n",
      "cbow_150_dense: run, running, think, thinking: used\n",
      "cbow_300_dense: run, running, think, thinking: beds\n",
      "skipgram_50: run, running, think, thinking: happens\n",
      "skipgram_150: run, running, think, thinking: latin\n",
      "skipgram_300: run, running, think, thinking: our\n",
      "skipgram_50_dense: run, running, think, thinking: splashing\n",
      "skipgram_150_dense: run, running, think, thinking: eat\n",
      "skipgram_300_dense: run, running, think, thinking: her\n",
      "\n",
      "cbow_50: say, saying, sit, sitting: see\n",
      "cbow_150: say, saying, sit, sitting: having\n",
      "cbow_300: say, saying, sit, sitting: ever\n",
      "cbow_50_dense: say, saying, sit, sitting: sooner\n",
      "cbow_150_dense: say, saying, sit, sitting: white\n",
      "cbow_300_dense: say, saying, sit, sitting: herself\n",
      "skipgram_50: say, saying, sit, sitting: enough\n",
      "skipgram_150: say, saying, sit, sitting: them\n",
      "skipgram_300: say, saying, sit, sitting: her\n",
      "skipgram_50_dense: say, saying, sit, sitting: sitting\n",
      "skipgram_150_dense: say, saying, sit, sitting: explain\n",
      "skipgram_300_dense: say, saying, sit, sitting: young\n",
      "\n",
      "cbow_50: alice, she, rabbit, he: off\n",
      "cbow_150: alice, she, rabbit, he: off\n",
      "cbow_300: alice, she, rabbit, he: off\n",
      "cbow_50_dense: alice, she, rabbit, he: off\n",
      "cbow_150_dense: alice, she, rabbit, he: off\n",
      "cbow_300_dense: alice, she, rabbit, he: off\n",
      "skipgram_50: alice, she, rabbit, he: it\n",
      "skipgram_150: alice, she, rabbit, he: it\n",
      "skipgram_300: alice, she, rabbit, he: it\n",
      "skipgram_50_dense: alice, she, rabbit, he: bank\n",
      "skipgram_150_dense: alice, she, rabbit, he: he\n",
      "skipgram_300_dense: alice, she, rabbit, he: it\n",
      "\n",
      "cbow_50: alice, her, rabbit, him: sat\n",
      "cbow_150: alice, her, rabbit, him: pocket\n",
      "cbow_300: alice, her, rabbit, him: out\n",
      "cbow_50_dense: alice, her, rabbit, him: pocket\n",
      "cbow_150_dense: alice, her, rabbit, him: over\n",
      "cbow_300_dense: alice, her, rabbit, him: over\n",
      "skipgram_50: alice, her, rabbit, him: herself\n",
      "skipgram_150: alice, her, rabbit, him: herself\n",
      "skipgram_300: alice, her, rabbit, him: this\n",
      "skipgram_50_dense: alice, her, rabbit, him: declare\n",
      "skipgram_150_dense: alice, her, rabbit, him: burn\n",
      "skipgram_300_dense: alice, her, rabbit, him: notion\n",
      "\n",
      "cbow_50: alice, girl, rabbit, sir: worth\n",
      "cbow_150: alice, girl, rabbit, sir: next\n",
      "cbow_300: alice, girl, rabbit, sir: made\n",
      "cbow_50_dense: alice, girl, rabbit, sir: off\n",
      "cbow_150_dense: alice, girl, rabbit, sir: off\n",
      "cbow_300_dense: alice, girl, rabbit, sir: off\n",
      "skipgram_50: alice, girl, rabbit, sir: ate\n",
      "skipgram_150: alice, girl, rabbit, sir: milk\n",
      "skipgram_300: alice, girl, rabbit, sir: too\n",
      "skipgram_50_dense: alice, girl, rabbit, sir: delight\n",
      "skipgram_150_dense: alice, girl, rabbit, sir: dreamy\n",
      "skipgram_300_dense: alice, girl, rabbit, sir: wonder\n",
      "\n",
      "cbow_50: dinah, cat, alice, girl: william\n",
      "cbow_150: dinah, cat, alice, girl: william\n",
      "cbow_300: dinah, cat, alice, girl: are\n",
      "cbow_50_dense: dinah, cat, alice, girl: are\n",
      "cbow_150_dense: dinah, cat, alice, girl: are\n",
      "cbow_300_dense: dinah, cat, alice, girl: william\n",
      "skipgram_50: dinah, cat, alice, girl: live\n",
      "skipgram_150: dinah, cat, alice, girl: from\n",
      "skipgram_300: dinah, cat, alice, girl: come\n",
      "skipgram_50_dense: dinah, cat, alice, girl: bottle\n",
      "skipgram_150_dense: dinah, cat, alice, girl: sooner\n",
      "skipgram_300_dense: dinah, cat, alice, girl: love\n",
      "\n",
      "cbow_50: his, her, he, she: sat\n",
      "cbow_150: his, her, he, she: pocket\n",
      "cbow_300: his, her, he, she: out\n",
      "cbow_50_dense: his, her, he, she: pocket\n",
      "cbow_150_dense: his, her, he, she: over\n",
      "cbow_300_dense: his, her, he, she: over\n",
      "skipgram_50: his, her, he, she: herself\n",
      "skipgram_150: his, her, he, she: herself\n",
      "skipgram_300: his, her, he, she: this\n",
      "skipgram_50_dense: his, her, he, she: declare\n",
      "skipgram_150_dense: his, her, he, she: burn\n",
      "skipgram_300_dense: his, her, he, she: notion\n",
      "\n",
      "cbow_50: long, longer, quick, quicker: am\n",
      "cbow_150: long, longer, quick, quicker: am\n",
      "cbow_300: long, longer, quick, quicker: say\n",
      "cbow_50_dense: long, longer, quick, quicker: shall\n",
      "cbow_150_dense: long, longer, quick, quicker: gave\n",
      "cbow_300_dense: long, longer, quick, quicker: noticed\n",
      "skipgram_50: long, longer, quick, quicker: declared\n",
      "skipgram_150: long, longer, quick, quicker: glad\n",
      "skipgram_300: long, longer, quick, quicker: making\n",
      "skipgram_50_dense: long, longer, quick, quicker: reach\n",
      "skipgram_150_dense: long, longer, quick, quicker: sulky\n",
      "skipgram_300_dense: long, longer, quick, quicker: pale\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbow_50: long, longer, small, smaller: am\n",
      "cbow_150: long, longer, small, smaller: am\n",
      "cbow_300: long, longer, small, smaller: say\n",
      "cbow_50_dense: long, longer, small, smaller: shall\n",
      "cbow_150_dense: long, longer, small, smaller: gave\n",
      "cbow_300_dense: long, longer, small, smaller: noticed\n",
      "skipgram_50: long, longer, small, smaller: declared\n",
      "skipgram_150: long, longer, small, smaller: glad\n",
      "skipgram_300: long, longer, small, smaller: making\n",
      "skipgram_50_dense: long, longer, small, smaller: reach\n",
      "skipgram_150_dense: long, longer, small, smaller: sulky\n",
      "skipgram_300_dense: long, longer, small, smaller: pale\n",
      "\n",
      "cbow_50: long, longer, bad, worse: am\n",
      "cbow_150: long, longer, bad, worse: am\n",
      "cbow_300: long, longer, bad, worse: say\n",
      "cbow_50_dense: long, longer, bad, worse: shall\n",
      "cbow_150_dense: long, longer, bad, worse: gave\n",
      "cbow_300_dense: long, longer, bad, worse: noticed\n",
      "skipgram_50: long, longer, bad, worse: declared\n",
      "skipgram_150: long, longer, bad, worse: glad\n",
      "skipgram_300: long, longer, bad, worse: making\n",
      "skipgram_50_dense: long, longer, bad, worse: reach\n",
      "skipgram_150_dense: long, longer, bad, worse: sulky\n",
      "skipgram_300_dense: long, longer, bad, worse: pale\n",
      "\n",
      "cbow_50: go, going, look, looking: found\n",
      "cbow_150: go, going, look, looking: found\n",
      "cbow_300: go, going, look, looking: have\n",
      "cbow_50_dense: go, going, look, looking: fancy\n",
      "cbow_150_dense: go, going, look, looking: why\n",
      "cbow_300_dense: go, going, look, looking: have\n",
      "skipgram_50: go, going, look, looking: on\n",
      "skipgram_150: go, going, look, looking: her\n",
      "skipgram_300: go, going, look, looking: thing\n",
      "skipgram_50_dense: go, going, look, looking: her\n",
      "skipgram_150_dense: go, going, look, looking: cunning\n",
      "skipgram_300_dense: go, going, look, looking: avoid\n",
      "\n",
      "cbow_50: listen, listening, look, looking: filled\n",
      "cbow_150: listen, listening, look, looking: filled\n",
      "cbow_300: listen, listening, look, looking: its\n",
      "cbow_50_dense: listen, listening, look, looking: girl\n",
      "cbow_150_dense: listen, listening, look, looking: currants\n",
      "cbow_300_dense: listen, listening, look, looking: into\n",
      "skipgram_50: listen, listening, look, looking: pair\n",
      "skipgram_150: listen, listening, look, looking: crab\n",
      "skipgram_300: listen, listening, look, looking: dull\n",
      "skipgram_50_dense: listen, listening, look, looking: water\n",
      "skipgram_150_dense: listen, listening, look, looking: won\n",
      "skipgram_300_dense: listen, listening, look, looking: calling\n",
      "\n",
      "cbow_50: swim, swimming, sit, sitting: re\n",
      "cbow_150: swim, swimming, sit, sitting: re\n",
      "cbow_300: swim, swimming, sit, sitting: things\n",
      "cbow_50_dense: swim, swimming, sit, sitting: up\n",
      "cbow_150_dense: swim, swimming, sit, sitting: was\n",
      "cbow_300_dense: swim, swimming, sit, sitting: was\n",
      "skipgram_50: swim, swimming, sit, sitting: rabbit\n",
      "skipgram_150: swim, swimming, sit, sitting: world\n",
      "skipgram_300: swim, swimming, sit, sitting: herself\n",
      "skipgram_50_dense: swim, swimming, sit, sitting: noticed\n",
      "skipgram_150_dense: swim, swimming, sit, sitting: desperate\n",
      "skipgram_300_dense: swim, swimming, sit, sitting: sticks\n",
      "\n",
      "cbow_50: run, running, listen, listening: us\n",
      "cbow_150: run, running, listen, listening: moment\n",
      "cbow_300: run, running, listen, listening: than\n",
      "cbow_50_dense: run, running, listen, listening: tunnel\n",
      "cbow_150_dense: run, running, listen, listening: used\n",
      "cbow_300_dense: run, running, listen, listening: beds\n",
      "skipgram_50: run, running, listen, listening: happens\n",
      "skipgram_150: run, running, listen, listening: latin\n",
      "skipgram_300: run, running, listen, listening: our\n",
      "skipgram_50_dense: run, running, listen, listening: splashing\n",
      "skipgram_150_dense: run, running, listen, listening: eat\n",
      "skipgram_300_dense: run, running, listen, listening: her\n",
      "\n",
      "cbow_50: think, thinking, read, reading: change\n",
      "cbow_150: think, thinking, read, reading: re\n",
      "cbow_300: think, thinking, read, reading: avoid\n",
      "cbow_50_dense: think, thinking, read, reading: tired\n",
      "cbow_150_dense: think, thinking, read, reading: doing\n",
      "cbow_300_dense: think, thinking, read, reading: was\n",
      "skipgram_50: think, thinking, read, reading: puzzle\n",
      "skipgram_150: think, thinking, read, reading: dry\n",
      "skipgram_300: think, thinking, read, reading: remembered\n",
      "skipgram_50_dense: think, thinking, read, reading: play\n",
      "skipgram_150_dense: think, thinking, read, reading: somewhere\n",
      "skipgram_300_dense: think, thinking, read, reading: half\n",
      "\n",
      "cbow_50: up, down, close, far: however\n",
      "cbow_150: up, down, close, far: however\n",
      "cbow_300: up, down, close, far: at\n",
      "cbow_50_dense: up, down, close, far: at\n",
      "cbow_150_dense: up, down, close, far: at\n",
      "cbow_300_dense: up, down, close, far: however\n",
      "skipgram_50: up, down, close, far: not\n",
      "skipgram_150: up, down, close, far: me\n",
      "skipgram_300: up, down, close, far: s\n",
      "skipgram_50_dense: up, down, close, far: again\n",
      "skipgram_150_dense: up, down, close, far: locked\n",
      "skipgram_300_dense: up, down, close, far: calling\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#analogy word guessing, take the first three of analogy, and guess the fourth\n",
    "cbow50analogylist=[]\n",
    "cbow50denseanalogylist=[]\n",
    "cbow150analogylist=[]\n",
    "cbow150denseanalogylist=[]\n",
    "cbow300analogylist=[]\n",
    "cbow300denseanalogylist=[]\n",
    "skipgram50analogylist=[]\n",
    "skipgram50denseanalogylist=[]\n",
    "skipgram150analogylist=[]\n",
    "skipgram150denseanalogylist=[]\n",
    "skipgram300analogylist=[]\n",
    "skipgram300denseanalogylist=[]\n",
    "co_occurrencelist=[]\n",
    "\n",
    "\n",
    "for analogy in analogy_list:\n",
    "    if(analogy[0] in tokenizer.word_index and analogy[1] in tokenizer.word_index and analogy[2] in tokenizer.word_index and analogy[3] in tokenizer.word_index):\n",
    "        try:\n",
    "            co_occurrenceanalogy=analogy_predict(analogy,tf_cooc, tokenizer.word_index )\n",
    "            cbow50analogy=analogy_predict(analogy,embed_cbow_50, tokenizer.word_index )\n",
    "            cbow150analogy=analogy_predict(analogy,embed_cbow_150, tokenizer.word_index )\n",
    "            cbow300analogy=analogy_predict(analogy,embed_cbow_300, tokenizer.word_index )\n",
    "            cbow50denseanalogy=analogy_predict(analogy,embed_cbow_50_dense, tokenizer.word_index )\n",
    "            cbow150denseanalogy=analogy_predict(analogy,embed_cbow_150_dense, tokenizer.word_index )\n",
    "            cbow300denseanalogy=analogy_predict(analogy,embed_cbow_300_dense, tokenizer.word_index )\n",
    "            skipgram50analogy=analogy_predict(analogy,embed_skipgram_50, tokenizer.word_index )\n",
    "            skipgram150analogy=analogy_predict(analogy,embed_skipgram_150, tokenizer.word_index )\n",
    "            skipgram300analogy=analogy_predict(analogy,embed_skipgram_300, tokenizer.word_index )\n",
    "            skipgram50denseanalogy=analogy_predict(analogy,embed_skipgram_50_dense, tokenizer.word_index )\n",
    "            skipgram150denseanalogy=analogy_predict(analogy,embed_skipgram_150_dense, tokenizer.word_index )\n",
    "            skipgram300denseanalogy=analogy_predict(analogy,embed_skipgram_300_dense, tokenizer.word_index )\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(\"cbow_50: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow50analogy))\n",
    "            print(\"cbow_150: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow150analogy))\n",
    "            print(\"cbow_300: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow300analogy))\n",
    "            print(\"cbow_50_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow50denseanalogy))\n",
    "            print(\"cbow_150_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow150denseanalogy))\n",
    "            print(\"cbow_300_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow300denseanalogy))\n",
    "            print(\"skipgram_50: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram50analogy))\n",
    "            print(\"skipgram_150: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram150analogy))\n",
    "            print(\"skipgram_300: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram300analogy))\n",
    "            print(\"skipgram_50_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram50denseanalogy))\n",
    "            print(\"skipgram_150_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram150denseanalogy))\n",
    "            print(\"skipgram_300_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram300denseanalogy))\n",
    "            \n",
    "            \n",
    "            co_occurrencelist.append(co_occurrenceanalogy)\n",
    "            cbow50analogylist.append(cbow50analogy)\n",
    "            cbow150analogylist.append(cbow150analogy)\n",
    "            cbow300analogylist.append(cbow300analogy)\n",
    "            cbow50denseanalogylist.append(cbow50denseanalogy)\n",
    "            cbow150denseanalogylist.append(cbow150denseanalogy)\n",
    "            cbow300denseanalogylist.append(cbow300denseanalogy)\n",
    "            skipgram50analogylist.append(skipgram50analogy)\n",
    "            skipgram150analogylist.append(skipgram150analogy)\n",
    "            skipgram300analogylist.append(skipgram300analogy)\n",
    "            skipgram50denseanalogylist.append(skipgram50denseanalogy)\n",
    "            skipgram150denseanalogylist.append(skipgram150denseanalogy)\n",
    "            skipgram300denseanalogylist.append(skipgram300denseanalogy)\n",
    "            \n",
    "            \n",
    "            print()\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization results trained word embeddings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def draw_word_vecs(X,strings):\n",
    "        col = ['r','b','g','y']\n",
    "        if len(X)!= len(strings):\n",
    "            print(\"mismatch in lengths between labels and vectors\")\n",
    "\n",
    "        X_embedded = TSNE(n_components=2,method='exact',n_iter=5000).fit_transform(X)\n",
    "        for i in range(len(X_embedded)):\n",
    "            if (i==0 or i==2):\n",
    "                dx = X_embedded[i+1][0]- X_embedded[i][0] \n",
    "                dy = X_embedded[i+1][1] - X_embedded[i][1]  \n",
    "                plt.annotate(\"\",\n",
    "                xytext=(X_embedded[i][0] , X_embedded[i][1] ), xycoords='data',\n",
    "                xy=(X_embedded[i+1][0] , X_embedded[i+1][1] ),textcoords='data',arrowprops=dict(arrowstyle=\"->\",\n",
    "                            connectionstyle=\"arc3\"))\n",
    "            plt.scatter(X_embedded[i][0],X_embedded[i][1])\n",
    "        plt.legend(strings)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20d0c290b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run' 'running' 'listen' 'listening']\n"
     ]
    }
   ],
   "source": [
    "#cbow 50\n",
    "\n",
    "w2visualize=analogy_list[42]\n",
    "embedlist=[]\n",
    "for i in range(4):\n",
    "    #embedlist.append(word2vec[analogy_list[1][i]])\n",
    "    embedlist.append(embed_cbow_50[tokenizer.word_index[w2visualize[i]]-1])\n",
    "plt.title(\"cbow 50\")\n",
    "draw_word_vecs(embedlist,w2visualize)    \n",
    "print(w2visualize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20d0c66ae10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alice' 'girl' 'rabbit' 'sir']\n"
     ]
    }
   ],
   "source": [
    "#skipgram_50_dense\n",
    "\n",
    "w2visualize=analogy_list[30]\n",
    "embedlist=[]\n",
    "for i in range(4):\n",
    "    #embedlist.append(word2vec[analogy_list[1][i]])\n",
    "    embedlist.append(embed_skipgram_50_dense[tokenizer.word_index[w2visualize[i]]-1])\n",
    "plt.title(\"skipgram 50 dense\")\n",
    "draw_word_vecs(embedlist,w2visualize)    \n",
    "print(w2visualize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "We made a function analogy_check() for checking how similar a set of analogy is. For an analogy, we will have a set of embedding vector (v0, v1, v2, v3). The way we checked it by checking cosine_similarity of (v0+v1) and (v2+v3). If it is an analogy, then the cosine should be high because (v0+v1) and (v2+v3) should be closed (in terms of cosine angle) with each other.\n",
    "\n",
    "Overall, the performance is not satisfying. This could be caused by several factors: inadequate training sample, the world in analogy is not frequently appear, etc. Adding more dimension in embedding vector also doesn't prove to increase the similarity. Most of the analogy works better for n=50 compared to n=150 or 300. Adding dense layer also doens not prove to increase similarity. The extra training time for adding dense layer is not improving the similarity of an analogy (but there is few that improves such as (large, largest, good, best) on cbow_50 and cbow_50_dense)\n",
    "\n",
    "CBOW works better on frequent word. For example (eat, eats, find, finds) cbow_50 is better than skipgram_50. In alice.txt there are more than 100 occurance of 'eat' word. CBOW better in this case because context words are averaged before predicting the targeted word, and since it has more sample then it works better in this case. This means Skipgram is better on rare words.\n",
    "\n",
    "One of the highest one (run, running, listen, listening) by cbow with dim=50. As we can see in the first picture above, the resultant of the analogy vector is almost paralel with each orthe. So when the cosine_similarity was used for the resultant of both vectors, then it should produce a close similarity (high value). For the analogy that has low similarity, for ecample (alice, girl, rabbit, sir), as shown in the second plot, it is almost perpendicular with each other, so the cosine similarity will be close to 0 (the cos_similarity of this analogy is 0.007)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5\n",
    "### Use the word co-occurence matrix from Question 1. Compare the performance on the analogy task with the performance of your trained word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "co-occurance: sudden, suddenly, usual, usually: 0.20341951009664783\n",
      "cbow_50: sudden, suddenly, usual, usually: 0.2145599465610109\n",
      "cbow_150: sudden, suddenly, usual, usually: 0.16464666681544313\n",
      "cbow_300: sudden, suddenly, usual, usually: 0.04262983580543956\n",
      "cbow_50_dense: sudden, suddenly, usual, usually: 0.024934976086477847\n",
      "cbow_150_dense: sudden, suddenly, usual, usually: 0.06584301080295592\n",
      "cbow_300_dense: sudden, suddenly, usual, usually: 0.057512587300851306\n",
      "skipgram_50: sudden, suddenly, usual, usually: 0.051247048932523284\n",
      "skipgram_150: sudden, suddenly, usual, usually: 0.11488630353144216\n",
      "skipgram_300: sudden, suddenly, usual, usually: 0.025398620492292738\n",
      "skipgram_50_dense: sudden, suddenly, usual, usually: 0.11550091531896342\n",
      "skipgram_150_dense: sudden, suddenly, usual, usually: 0.09122986493247628\n",
      "skipgram_300_dense: sudden, suddenly, usual, usually: 0.0379434827632857\n",
      "\n",
      "co-occurance: bad, worse, good, better: 0.340842718662506\n",
      "cbow_50: bad, worse, good, better: 0.007139452508570647\n",
      "cbow_150: bad, worse, good, better: 0.04960375886754415\n",
      "cbow_300: bad, worse, good, better: 0.08364212988123694\n",
      "cbow_50_dense: bad, worse, good, better: 0.026874943420956886\n",
      "cbow_150_dense: bad, worse, good, better: 0.12296815517749676\n",
      "cbow_300_dense: bad, worse, good, better: 0.022567480791767187\n",
      "skipgram_50: bad, worse, good, better: 0.14242828767090374\n",
      "skipgram_150: bad, worse, good, better: 0.06110748320636268\n",
      "skipgram_300: bad, worse, good, better: 0.014283902125049552\n",
      "skipgram_50_dense: bad, worse, good, better: 0.07730987059232503\n",
      "skipgram_150_dense: bad, worse, good, better: 0.11583589719793469\n",
      "skipgram_300_dense: bad, worse, good, better: 0.06542767465641082\n",
      "\n",
      "co-occurance: go, going, look, looking: 0.5257224725382912\n",
      "cbow_50: go, going, look, looking: 0.04482878540457188\n",
      "cbow_150: go, going, look, looking: 0.13521208123901596\n",
      "cbow_300: go, going, look, looking: 0.11739576262876612\n",
      "cbow_50_dense: go, going, look, looking: 0.2275989682841857\n",
      "cbow_150_dense: go, going, look, looking: 0.08095648478867602\n",
      "cbow_300_dense: go, going, look, looking: 0.014954370905789528\n",
      "skipgram_50: go, going, look, looking: 0.04897776970140745\n",
      "skipgram_150: go, going, look, looking: 0.3108869698881552\n",
      "skipgram_300: go, going, look, looking: 0.1897161720304399\n",
      "skipgram_50_dense: go, going, look, looking: 0.14061684371374158\n",
      "skipgram_150_dense: go, going, look, looking: 0.14720249473774485\n",
      "skipgram_300_dense: go, going, look, looking: 0.002864495321771528\n",
      "\n",
      "co-occurance: he, she, his, her: 0.7385962387549866\n",
      "cbow_50: he, she, his, her: 0.08099932963910215\n",
      "cbow_150: he, she, his, her: 0.03569783846020872\n",
      "cbow_300: he, she, his, her: 0.022474709476888687\n",
      "cbow_50_dense: he, she, his, her: 0.25305776920456663\n",
      "cbow_150_dense: he, she, his, her: 0.05257730241374489\n",
      "cbow_300_dense: he, she, his, her: 0.12253203367780965\n",
      "skipgram_50: he, she, his, her: 0.5350455025860693\n",
      "skipgram_150: he, she, his, her: 0.4214261528756635\n",
      "skipgram_300: he, she, his, her: 0.1928937824570437\n",
      "skipgram_50_dense: he, she, his, her: 0.2154861486119754\n",
      "skipgram_150_dense: he, she, his, her: 0.14655767256694316\n",
      "skipgram_300_dense: he, she, his, her: 0.1511302407262479\n",
      "\n",
      "co-occurance: brother, sister, his, her: 0.6112346949924595\n",
      "cbow_50: brother, sister, his, her: 0.3216747204943751\n",
      "cbow_150: brother, sister, his, her: 0.23105893917756617\n",
      "cbow_300: brother, sister, his, her: 0.07589060484117083\n",
      "cbow_50_dense: brother, sister, his, her: 0.08839213138780096\n",
      "cbow_150_dense: brother, sister, his, her: 0.03201457747498062\n",
      "cbow_300_dense: brother, sister, his, her: 0.010614877330893632\n",
      "skipgram_50: brother, sister, his, her: 0.08925583606036332\n",
      "skipgram_150: brother, sister, his, her: 0.11066786236035159\n",
      "skipgram_300: brother, sister, his, her: 0.15242621645498913\n",
      "skipgram_50_dense: brother, sister, his, her: 0.16731238470239565\n",
      "skipgram_150_dense: brother, sister, his, her: 0.1600951228220338\n",
      "skipgram_300_dense: brother, sister, his, her: 0.10670694926142113\n",
      "\n",
      "co-occurance: listen, listening, look, looking: 0.26481698509308443\n",
      "cbow_50: listen, listening, look, looking: 0.3802069701610734\n",
      "cbow_150: listen, listening, look, looking: 0.36921053308958424\n",
      "cbow_300: listen, listening, look, looking: 0.23802999618462123\n",
      "cbow_50_dense: listen, listening, look, looking: 0.03956834867672034\n",
      "cbow_150_dense: listen, listening, look, looking: 0.025226025836383444\n",
      "cbow_300_dense: listen, listening, look, looking: 0.08170528413458206\n",
      "skipgram_50: listen, listening, look, looking: 0.21922497121328843\n",
      "skipgram_150: listen, listening, look, looking: 0.11884336654412271\n",
      "skipgram_300: listen, listening, look, looking: 0.012053642266116044\n",
      "skipgram_50_dense: listen, listening, look, looking: 0.3328211143150717\n",
      "skipgram_150_dense: listen, listening, look, looking: 0.0595487007636639\n",
      "skipgram_300_dense: listen, listening, look, looking: 0.0406596642434014\n",
      "\n",
      "co-occurance: saying, said, thinking, thought: 0.35946825219809\n",
      "cbow_50: saying, said, thinking, thought: 0.3083834417108346\n",
      "cbow_150: saying, said, thinking, thought: 0.30258397528363445\n",
      "cbow_300: saying, said, thinking, thought: 0.3385169623849108\n",
      "cbow_50_dense: saying, said, thinking, thought: 0.27146892652097987\n",
      "cbow_150_dense: saying, said, thinking, thought: 0.26399041172107607\n",
      "cbow_300_dense: saying, said, thinking, thought: 0.12383424063284779\n",
      "skipgram_50: saying, said, thinking, thought: 0.565914284020611\n",
      "skipgram_150: saying, said, thinking, thought: 0.3787360042101855\n",
      "skipgram_300: saying, said, thinking, thought: 0.30719562937336314\n",
      "skipgram_50_dense: saying, said, thinking, thought: 0.032715337214361935\n",
      "skipgram_150_dense: saying, said, thinking, thought: 0.03265436792557913\n",
      "skipgram_300_dense: saying, said, thinking, thought: 0.08585073444779104\n",
      "\n",
      "co-occurance: bird, birds, cat, cats: 0.26944042644259525\n",
      "cbow_50: bird, birds, cat, cats: 0.25155843706819225\n",
      "cbow_150: bird, birds, cat, cats: 0.11949157172847855\n",
      "cbow_300: bird, birds, cat, cats: 0.1781694964528609\n",
      "cbow_50_dense: bird, birds, cat, cats: 0.2320395959316713\n",
      "cbow_150_dense: bird, birds, cat, cats: 0.0884316106458272\n",
      "cbow_300_dense: bird, birds, cat, cats: 0.14467242053834647\n",
      "skipgram_50: bird, birds, cat, cats: 0.4165848617676572\n",
      "skipgram_150: bird, birds, cat, cats: 0.12949779747079\n",
      "skipgram_300: bird, birds, cat, cats: 0.12433095616959039\n",
      "skipgram_50_dense: bird, birds, cat, cats: 0.012887874151781279\n",
      "skipgram_150_dense: bird, birds, cat, cats: 0.07353652983537766\n",
      "skipgram_300_dense: bird, birds, cat, cats: 0.05631322940932175\n",
      "\n",
      "co-occurance: good, better, old, older: 0.30714575708258646\n",
      "cbow_50: good, better, old, older: 0.28356033517821916\n",
      "cbow_150: good, better, old, older: 0.3367662060157432\n",
      "cbow_300: good, better, old, older: 0.24294226160000545\n",
      "cbow_50_dense: good, better, old, older: 0.12562361925379575\n",
      "cbow_150_dense: good, better, old, older: 0.10944203217062437\n",
      "cbow_300_dense: good, better, old, older: 0.18656535061624072\n",
      "skipgram_50: good, better, old, older: 0.006747658278795679\n",
      "skipgram_150: good, better, old, older: 0.2613328446046628\n",
      "skipgram_300: good, better, old, older: 0.16584128942361212\n",
      "skipgram_50_dense: good, better, old, older: 0.006715441594898397\n",
      "skipgram_150_dense: good, better, old, older: 0.05311411308035306\n",
      "skipgram_300_dense: good, better, old, older: 0.05186729010261828\n",
      "\n",
      "co-occurance: good, better, quick, quicker: 0.34107029029906366\n",
      "cbow_50: good, better, quick, quicker: 0.12513511819856912\n",
      "cbow_150: good, better, quick, quicker: 0.10664919624378821\n",
      "cbow_300: good, better, quick, quicker: 0.03208647290314115\n",
      "cbow_50_dense: good, better, quick, quicker: 0.12567182118934672\n",
      "cbow_150_dense: good, better, quick, quicker: 0.06164886348505986\n",
      "cbow_300_dense: good, better, quick, quicker: 0.051326262550663464\n",
      "skipgram_50: good, better, quick, quicker: 0.037811205524927546\n",
      "skipgram_150: good, better, quick, quicker: 0.011419143924304096\n",
      "skipgram_300: good, better, quick, quicker: 0.026034704557969784\n",
      "skipgram_50_dense: good, better, quick, quicker: 0.033102714983078194\n",
      "skipgram_150_dense: good, better, quick, quicker: 0.03085308262693412\n",
      "skipgram_300_dense: good, better, quick, quicker: 0.0796093389770551\n",
      "\n",
      "co-occurance: large, largest, good, best: 0.1395444089352949\n",
      "cbow_50: large, largest, good, best: 0.055252841538935865\n",
      "cbow_150: large, largest, good, best: 0.14962042649321572\n",
      "cbow_300: large, largest, good, best: 0.13627840091820803\n",
      "cbow_50_dense: large, largest, good, best: 0.1395942175402173\n",
      "cbow_150_dense: large, largest, good, best: 0.11470696113616369\n",
      "cbow_300_dense: large, largest, good, best: 0.05309922636686337\n",
      "skipgram_50: large, largest, good, best: 0.0076305093982703895\n",
      "skipgram_150: large, largest, good, best: 0.1707115412567479\n",
      "skipgram_300: large, largest, good, best: 0.1725711060097743\n",
      "skipgram_50_dense: large, largest, good, best: 0.12473340544962884\n",
      "skipgram_150_dense: large, largest, good, best: 0.06615579167947909\n",
      "skipgram_300_dense: large, largest, good, best: 0.053627787932685286\n",
      "\n",
      "co-occurance: falling, fell, knowing, knew: 0.11600348176198484\n",
      "cbow_50: falling, fell, knowing, knew: 0.34969637290903044\n",
      "cbow_150: falling, fell, knowing, knew: 0.16103343892183927\n",
      "cbow_300: falling, fell, knowing, knew: 0.01912836021160874\n",
      "cbow_50_dense: falling, fell, knowing, knew: 0.018394198007298426\n",
      "cbow_150_dense: falling, fell, knowing, knew: 0.05989618949756096\n",
      "cbow_300_dense: falling, fell, knowing, knew: 0.037205425222480805\n",
      "skipgram_50: falling, fell, knowing, knew: 0.06791467768999672\n",
      "skipgram_150: falling, fell, knowing, knew: 0.09136214862017362\n",
      "skipgram_300: falling, fell, knowing, knew: 0.01463649822550943\n",
      "skipgram_50_dense: falling, fell, knowing, knew: 0.16193351261122524\n",
      "skipgram_150_dense: falling, fell, knowing, knew: 0.03656470212890241\n",
      "skipgram_300_dense: falling, fell, knowing, knew: 0.03872969424142178\n",
      "\n",
      "co-occurance: walk, walking, think, thinking: 0.06948063618614567\n",
      "cbow_50: walk, walking, think, thinking: 0.23305398188264462\n",
      "cbow_150: walk, walking, think, thinking: 0.16217284732039994\n",
      "cbow_300: walk, walking, think, thinking: 0.1371422823556235\n",
      "cbow_50_dense: walk, walking, think, thinking: 0.441744421903988\n",
      "cbow_150_dense: walk, walking, think, thinking: 0.27691568613316025\n",
      "cbow_300_dense: walk, walking, think, thinking: 0.25241882965411033\n",
      "skipgram_50: walk, walking, think, thinking: 0.1326619778939263\n",
      "skipgram_150: walk, walking, think, thinking: 0.1950671462577301\n",
      "skipgram_300: walk, walking, think, thinking: 0.05063676675719801\n",
      "skipgram_50_dense: walk, walking, think, thinking: 0.11086919505279523\n",
      "skipgram_150_dense: walk, walking, think, thinking: 0.039340863036024035\n",
      "skipgram_300_dense: walk, walking, think, thinking: 0.020751693251079326\n",
      "\n",
      "co-occurance: child, children, cat, cats: 0.12887794267338276\n",
      "cbow_50: child, children, cat, cats: 0.5761045501314452\n",
      "cbow_150: child, children, cat, cats: 0.6283387407761182\n",
      "cbow_300: child, children, cat, cats: 0.4224878099785585\n",
      "cbow_50_dense: child, children, cat, cats: 0.13089713945022188\n",
      "cbow_150_dense: child, children, cat, cats: 0.31170060389105086\n",
      "cbow_300_dense: child, children, cat, cats: 0.15971883179637444\n",
      "skipgram_50: child, children, cat, cats: 0.18690841970146993\n",
      "skipgram_150: child, children, cat, cats: 0.15727020501279124\n",
      "skipgram_300: child, children, cat, cats: 0.1633643593580084\n",
      "skipgram_50_dense: child, children, cat, cats: 0.11475457926841195\n",
      "skipgram_150_dense: child, children, cat, cats: 0.07555755343684083\n",
      "skipgram_300_dense: child, children, cat, cats: 0.08558659954598827\n",
      "\n",
      "co-occurance: dog, dogs, eye, eyes: 0.2349695309752005\n",
      "cbow_50: dog, dogs, eye, eyes: 0.048068004590513976\n",
      "cbow_150: dog, dogs, eye, eyes: 0.18301195503900555\n",
      "cbow_300: dog, dogs, eye, eyes: 0.08293971404713851\n",
      "cbow_50_dense: dog, dogs, eye, eyes: 0.009944152990215106\n",
      "cbow_150_dense: dog, dogs, eye, eyes: 0.00018806916728422024\n",
      "cbow_300_dense: dog, dogs, eye, eyes: 0.04959143883742041\n",
      "skipgram_50: dog, dogs, eye, eyes: 0.5401933619978343\n",
      "skipgram_150: dog, dogs, eye, eyes: 0.011997018957234177\n",
      "skipgram_300: dog, dogs, eye, eyes: 0.036955218552049134\n",
      "skipgram_50_dense: dog, dogs, eye, eyes: 0.014302918123874776\n",
      "skipgram_150_dense: dog, dogs, eye, eyes: 0.04161267376478868\n",
      "skipgram_300_dense: dog, dogs, eye, eyes: 0.09854696917931136\n",
      "\n",
      "co-occurance: hand, hands, rat, rats: 0.33242520863352953\n",
      "cbow_50: hand, hands, rat, rats: 0.20928379513093132\n",
      "cbow_150: hand, hands, rat, rats: 0.08922689088034921\n",
      "cbow_300: hand, hands, rat, rats: 0.06167524716738153\n",
      "cbow_50_dense: hand, hands, rat, rats: 0.2241956513486761\n",
      "cbow_150_dense: hand, hands, rat, rats: 0.08479348857676028\n",
      "cbow_300_dense: hand, hands, rat, rats: 0.21763028239299223\n",
      "skipgram_50: hand, hands, rat, rats: 0.029477426759401692\n",
      "skipgram_150: hand, hands, rat, rats: 0.13241202071518388\n",
      "skipgram_300: hand, hands, rat, rats: 0.056338820916069676\n",
      "skipgram_50_dense: hand, hands, rat, rats: 0.000745369944340421\n",
      "skipgram_150_dense: hand, hands, rat, rats: 0.18282660345720494\n",
      "skipgram_300_dense: hand, hands, rat, rats: 0.07454463081175015\n",
      "\n",
      "co-occurance: eat, eats, find, finds: 0.11861436543909255\n",
      "cbow_50: eat, eats, find, finds: 0.6344386909160316\n",
      "cbow_150: eat, eats, find, finds: 0.6230622716693793\n",
      "cbow_300: eat, eats, find, finds: 0.38332741252697833\n",
      "cbow_50_dense: eat, eats, find, finds: 0.11014595751932027\n",
      "cbow_150_dense: eat, eats, find, finds: 0.022188421800295247\n",
      "cbow_300_dense: eat, eats, find, finds: 0.02799474581397439\n",
      "skipgram_50: eat, eats, find, finds: 0.26850222986801453\n",
      "skipgram_150: eat, eats, find, finds: 0.08289657352440934\n",
      "skipgram_300: eat, eats, find, finds: 0.1310917767169901\n",
      "skipgram_50_dense: eat, eats, find, finds: 0.022223655143363493\n",
      "skipgram_150_dense: eat, eats, find, finds: 0.04586212657365139\n",
      "skipgram_300_dense: eat, eats, find, finds: 0.004353422652560424\n",
      "\n",
      "co-occurance: find, finds, say, says: 0.23988741456332002\n",
      "cbow_50: find, finds, say, says: 0.19636398876648298\n",
      "cbow_150: find, finds, say, says: 0.3493458745768275\n",
      "cbow_300: find, finds, say, says: 0.4225110412871306\n",
      "cbow_50_dense: find, finds, say, says: 0.10255216118966275\n",
      "cbow_150_dense: find, finds, say, says: 0.04139482654371349\n",
      "cbow_300_dense: find, finds, say, says: 0.09204581834643971\n",
      "skipgram_50: find, finds, say, says: 0.02189051838308856\n",
      "skipgram_150: find, finds, say, says: 0.11727715537439058\n",
      "skipgram_300: find, finds, say, says: 0.1485523068621352\n",
      "skipgram_50_dense: find, finds, say, says: 0.21955934322292522\n",
      "skipgram_150_dense: find, finds, say, says: 0.02131875144526285\n",
      "skipgram_300_dense: find, finds, say, says: 0.024942033757297807\n",
      "\n",
      "co-occurance: old, older, good, better: 0.30714575708258646\n",
      "cbow_50: old, older, good, better: 0.28356033517821916\n",
      "cbow_150: old, older, good, better: 0.3367662060157432\n",
      "cbow_300: old, older, good, better: 0.24294226160000545\n",
      "cbow_50_dense: old, older, good, better: 0.12562361925379575\n",
      "cbow_150_dense: old, older, good, better: 0.10944203217062437\n",
      "cbow_300_dense: old, older, good, better: 0.18656535061624072\n",
      "skipgram_50: old, older, good, better: 0.006747658278795679\n",
      "skipgram_150: old, older, good, better: 0.2613328446046628\n",
      "skipgram_300: old, older, good, better: 0.16584128942361212\n",
      "skipgram_50_dense: old, older, good, better: 0.006715441594898397\n",
      "skipgram_150_dense: old, older, good, better: 0.05311411308035306\n",
      "skipgram_300_dense: old, older, good, better: 0.05186729010261828\n",
      "\n",
      "co-occurance: large, larger, quick, quicker: 0.46126229661503876\n",
      "cbow_50: large, larger, quick, quicker: 0.15041247724164664\n",
      "cbow_150: large, larger, quick, quicker: 0.23806847996439426\n",
      "cbow_300: large, larger, quick, quicker: 0.04205617897711103\n",
      "cbow_50_dense: large, larger, quick, quicker: 0.14810958793009651\n",
      "cbow_150_dense: large, larger, quick, quicker: 0.12186104289525825\n",
      "cbow_300_dense: large, larger, quick, quicker: 0.09311372510784723\n",
      "skipgram_50: large, larger, quick, quicker: 0.08552472433803812\n",
      "skipgram_150: large, larger, quick, quicker: 0.12424542939530621\n",
      "skipgram_300: large, larger, quick, quicker: 0.06756714447400183\n",
      "skipgram_50_dense: large, larger, quick, quicker: 0.12221104436704669\n",
      "skipgram_150_dense: large, larger, quick, quicker: 0.053115179996420764\n",
      "skipgram_300_dense: large, larger, quick, quicker: 0.06817445995579048\n",
      "\n",
      "co-occurance: go, going, listen, listening: 0.17052103002986832\n",
      "cbow_50: go, going, listen, listening: 0.004348558915977116\n",
      "cbow_150: go, going, listen, listening: 0.04591844648923439\n",
      "cbow_300: go, going, listen, listening: 0.028175657728302012\n",
      "cbow_50_dense: go, going, listen, listening: 0.019190198412343568\n",
      "cbow_150_dense: go, going, listen, listening: 0.13541379022058453\n",
      "cbow_300_dense: go, going, listen, listening: 0.08877512926435754\n",
      "skipgram_50: go, going, listen, listening: 0.05539435165038242\n",
      "skipgram_150: go, going, listen, listening: 0.03247324062648229\n",
      "skipgram_300: go, going, listen, listening: 0.15185486231081524\n",
      "skipgram_50_dense: go, going, listen, listening: 0.14996689018468176\n",
      "skipgram_150_dense: go, going, listen, listening: 0.04243841588618983\n",
      "skipgram_300_dense: go, going, listen, listening: 0.010873228635317379\n",
      "\n",
      "co-occurance: run, running, walk, walking: 0.09035624609139908\n",
      "cbow_50: run, running, walk, walking: 0.43239444601331156\n",
      "cbow_150: run, running, walk, walking: 0.17316018462778576\n",
      "cbow_300: run, running, walk, walking: 0.06752979323171769\n",
      "cbow_50_dense: run, running, walk, walking: 0.19041077959930008\n",
      "cbow_150_dense: run, running, walk, walking: 0.08575569090759745\n",
      "cbow_300_dense: run, running, walk, walking: 0.13319373973395193\n",
      "skipgram_50: run, running, walk, walking: 0.05440431387771808\n",
      "skipgram_150: run, running, walk, walking: 0.08192690911244668\n",
      "skipgram_300: run, running, walk, walking: 0.10293102828061876\n",
      "skipgram_50_dense: run, running, walk, walking: 0.10158365041561519\n",
      "skipgram_150_dense: run, running, walk, walking: 0.03850630114665086\n",
      "skipgram_300_dense: run, running, walk, walking: 0.036897706755464\n",
      "\n",
      "co-occurance: run, running, think, thinking: 0.2779494787370918\n",
      "cbow_50: run, running, think, thinking: 0.12738615012738252\n",
      "cbow_150: run, running, think, thinking: 0.1885880627853949\n",
      "cbow_300: run, running, think, thinking: 0.13662853663187174\n",
      "cbow_50_dense: run, running, think, thinking: 0.09327913484627907\n",
      "cbow_150_dense: run, running, think, thinking: 0.09934669415267226\n",
      "cbow_300_dense: run, running, think, thinking: 0.013760378794701674\n",
      "skipgram_50: run, running, think, thinking: 0.0266290831646828\n",
      "skipgram_150: run, running, think, thinking: 0.08328285298530103\n",
      "skipgram_300: run, running, think, thinking: 0.06572295097742854\n",
      "skipgram_50_dense: run, running, think, thinking: 0.012145371455604355\n",
      "skipgram_150_dense: run, running, think, thinking: 0.06641353890075766\n",
      "skipgram_300_dense: run, running, think, thinking: 0.13502023716520042\n",
      "\n",
      "co-occurance: say, saying, sit, sitting: 0.15328841775286633\n",
      "cbow_50: say, saying, sit, sitting: 0.13290110049743256\n",
      "cbow_150: say, saying, sit, sitting: 0.13794787877818132\n",
      "cbow_300: say, saying, sit, sitting: 0.1255869428992714\n",
      "cbow_50_dense: say, saying, sit, sitting: 0.08854998828125173\n",
      "cbow_150_dense: say, saying, sit, sitting: 0.08481168346115567\n",
      "cbow_300_dense: say, saying, sit, sitting: 0.002778512915029485\n",
      "skipgram_50: say, saying, sit, sitting: 0.06671581439417851\n",
      "skipgram_150: say, saying, sit, sitting: 0.024395699928681472\n",
      "skipgram_300: say, saying, sit, sitting: 0.08653137863087766\n",
      "skipgram_50_dense: say, saying, sit, sitting: 0.2291511923882307\n",
      "skipgram_150_dense: say, saying, sit, sitting: 0.08249327141657764\n",
      "skipgram_300_dense: say, saying, sit, sitting: 0.031370623390230355\n",
      "\n",
      "co-occurance: alice, she, rabbit, he: 0.34414807845164874\n",
      "cbow_50: alice, she, rabbit, he: 0.3032260713980009\n",
      "cbow_150: alice, she, rabbit, he: 0.28750781874194553\n",
      "cbow_300: alice, she, rabbit, he: 0.23737374549441895\n",
      "cbow_50_dense: alice, she, rabbit, he: 0.37400362858646385\n",
      "cbow_150_dense: alice, she, rabbit, he: 0.2604214341177389\n",
      "cbow_300_dense: alice, she, rabbit, he: 0.22134533492778896\n",
      "skipgram_50: alice, she, rabbit, he: 0.3969428627541493\n",
      "skipgram_150: alice, she, rabbit, he: 0.26935194521993117\n",
      "skipgram_300: alice, she, rabbit, he: 0.1325306631609167\n",
      "skipgram_50_dense: alice, she, rabbit, he: 0.08122499625428377\n",
      "skipgram_150_dense: alice, she, rabbit, he: 0.19001593659421726\n",
      "skipgram_300_dense: alice, she, rabbit, he: 0.1196936498430301\n",
      "\n",
      "co-occurance: alice, her, rabbit, him: 0.32771434927105814\n",
      "cbow_50: alice, her, rabbit, him: 0.4245334730572496\n",
      "cbow_150: alice, her, rabbit, him: 0.3949279690641324\n",
      "cbow_300: alice, her, rabbit, him: 0.4694802520899805\n",
      "cbow_50_dense: alice, her, rabbit, him: 0.37489014507553303\n",
      "cbow_150_dense: alice, her, rabbit, him: 0.2922573512779353\n",
      "cbow_300_dense: alice, her, rabbit, him: 0.3085777141782657\n",
      "skipgram_50: alice, her, rabbit, him: 0.43744368034614123\n",
      "skipgram_150: alice, her, rabbit, him: 0.28236727353514146\n",
      "skipgram_300: alice, her, rabbit, him: 0.16623145761281516\n",
      "skipgram_50_dense: alice, her, rabbit, him: 0.003912821913825373\n",
      "skipgram_150_dense: alice, her, rabbit, him: 0.079360369362521\n",
      "skipgram_300_dense: alice, her, rabbit, him: 0.004352950260186055\n",
      "\n",
      "co-occurance: alice, girl, rabbit, sir: 0.09186016685209755\n",
      "cbow_50: alice, girl, rabbit, sir: 0.38352821418807104\n",
      "cbow_150: alice, girl, rabbit, sir: 0.3037741386102526\n",
      "cbow_300: alice, girl, rabbit, sir: 0.29111823565411055\n",
      "cbow_50_dense: alice, girl, rabbit, sir: 0.296456905787305\n",
      "cbow_150_dense: alice, girl, rabbit, sir: 0.18437463780691493\n",
      "cbow_300_dense: alice, girl, rabbit, sir: 0.17745145079999616\n",
      "skipgram_50: alice, girl, rabbit, sir: 0.37706869416324595\n",
      "skipgram_150: alice, girl, rabbit, sir: 0.2434311774890583\n",
      "skipgram_300: alice, girl, rabbit, sir: 0.013468505209538413\n",
      "skipgram_50_dense: alice, girl, rabbit, sir: 0.007664461700388371\n",
      "skipgram_150_dense: alice, girl, rabbit, sir: 0.013923791377918283\n",
      "skipgram_300_dense: alice, girl, rabbit, sir: 0.16162886469339285\n",
      "\n",
      "co-occurance: dinah, cat, alice, girl: 0.3292661488822022\n",
      "cbow_50: dinah, cat, alice, girl: 0.18871490618643927\n",
      "cbow_150: dinah, cat, alice, girl: 0.1988998323029214\n",
      "cbow_300: dinah, cat, alice, girl: 0.21994575208961464\n",
      "cbow_50_dense: dinah, cat, alice, girl: 0.01817282196713359\n",
      "cbow_150_dense: dinah, cat, alice, girl: 0.12974284936731623\n",
      "cbow_300_dense: dinah, cat, alice, girl: 0.0973591792683185\n",
      "skipgram_50: dinah, cat, alice, girl: 0.20264584206408742\n",
      "skipgram_150: dinah, cat, alice, girl: 0.23600359629142628\n",
      "skipgram_300: dinah, cat, alice, girl: 0.1798156827185624\n",
      "skipgram_50_dense: dinah, cat, alice, girl: 0.06226421184792411\n",
      "skipgram_150_dense: dinah, cat, alice, girl: 0.04952489944505424\n",
      "skipgram_300_dense: dinah, cat, alice, girl: 0.016715979149657174\n",
      "\n",
      "co-occurance: his, her, he, she: 0.7385962387549866\n",
      "cbow_50: his, her, he, she: 0.08099932963910215\n",
      "cbow_150: his, her, he, she: 0.03569783846020872\n",
      "cbow_300: his, her, he, she: 0.022474709476888687\n",
      "cbow_50_dense: his, her, he, she: 0.25305776920456663\n",
      "cbow_150_dense: his, her, he, she: 0.05257730241374489\n",
      "cbow_300_dense: his, her, he, she: 0.12253203367780965\n",
      "skipgram_50: his, her, he, she: 0.5350455025860693\n",
      "skipgram_150: his, her, he, she: 0.4214261528756635\n",
      "skipgram_300: his, her, he, she: 0.1928937824570437\n",
      "skipgram_50_dense: his, her, he, she: 0.2154861486119754\n",
      "skipgram_150_dense: his, her, he, she: 0.14655767256694316\n",
      "skipgram_300_dense: his, her, he, she: 0.1511302407262479\n",
      "\n",
      "co-occurance: long, longer, quick, quicker: 0.0754247233265651\n",
      "cbow_50: long, longer, quick, quicker: 0.4120102891993884\n",
      "cbow_150: long, longer, quick, quicker: 0.23017015273506933\n",
      "cbow_300: long, longer, quick, quicker: 0.09401260595447117\n",
      "cbow_50_dense: long, longer, quick, quicker: 0.01408052840685802\n",
      "cbow_150_dense: long, longer, quick, quicker: 0.007133586407366825\n",
      "cbow_300_dense: long, longer, quick, quicker: 0.07831883522036924\n",
      "skipgram_50: long, longer, quick, quicker: 0.02151832074829586\n",
      "skipgram_150: long, longer, quick, quicker: 0.09068842882436388\n",
      "skipgram_300: long, longer, quick, quicker: 0.07102139535964663\n",
      "skipgram_50_dense: long, longer, quick, quicker: 0.05400072789551662\n",
      "skipgram_150_dense: long, longer, quick, quicker: 0.11150849188104847\n",
      "skipgram_300_dense: long, longer, quick, quicker: 0.03754801662507641\n",
      "\n",
      "co-occurance: long, longer, small, smaller: 0.08908306380621506\n",
      "cbow_50: long, longer, small, smaller: 0.4318003131750905\n",
      "cbow_150: long, longer, small, smaller: 0.3554968324347603\n",
      "cbow_300: long, longer, small, smaller: 0.19269746490298645\n",
      "cbow_50_dense: long, longer, small, smaller: 0.5372986667713919\n",
      "cbow_150_dense: long, longer, small, smaller: 0.3725341328264276\n",
      "cbow_300_dense: long, longer, small, smaller: 0.35016791043829654\n",
      "skipgram_50: long, longer, small, smaller: 0.21398489733806456\n",
      "skipgram_150: long, longer, small, smaller: 0.1640505580848037\n",
      "skipgram_300: long, longer, small, smaller: 0.21245308466171794\n",
      "skipgram_50_dense: long, longer, small, smaller: 0.06976419471060234\n",
      "skipgram_150_dense: long, longer, small, smaller: 0.008430045436527846\n",
      "skipgram_300_dense: long, longer, small, smaller: 0.02207475087097485\n",
      "\n",
      "co-occurance: long, longer, bad, worse: 0.12267116321986311\n",
      "cbow_50: long, longer, bad, worse: 0.3260491473042464\n",
      "cbow_150: long, longer, bad, worse: 0.15212735080104456\n",
      "cbow_300: long, longer, bad, worse: 0.20373219592586617\n",
      "cbow_50_dense: long, longer, bad, worse: 0.08853810932159445\n",
      "cbow_150_dense: long, longer, bad, worse: 0.02362576370261302\n",
      "cbow_300_dense: long, longer, bad, worse: 0.02967005557613777\n",
      "skipgram_50: long, longer, bad, worse: 0.09991521837069943\n",
      "skipgram_150: long, longer, bad, worse: 0.04688277512539548\n",
      "skipgram_300: long, longer, bad, worse: 0.04225910785783235\n",
      "skipgram_50_dense: long, longer, bad, worse: 0.0591265043266381\n",
      "skipgram_150_dense: long, longer, bad, worse: 0.026776340215094604\n",
      "skipgram_300_dense: long, longer, bad, worse: 0.0009287152378468827\n",
      "\n",
      "co-occurance: go, going, look, looking: 0.5257224725382912\n",
      "cbow_50: go, going, look, looking: 0.04482878540457188\n",
      "cbow_150: go, going, look, looking: 0.13521208123901596\n",
      "cbow_300: go, going, look, looking: 0.11739576262876612\n",
      "cbow_50_dense: go, going, look, looking: 0.2275989682841857\n",
      "cbow_150_dense: go, going, look, looking: 0.08095648478867602\n",
      "cbow_300_dense: go, going, look, looking: 0.014954370905789528\n",
      "skipgram_50: go, going, look, looking: 0.04897776970140745\n",
      "skipgram_150: go, going, look, looking: 0.3108869698881552\n",
      "skipgram_300: go, going, look, looking: 0.1897161720304399\n",
      "skipgram_50_dense: go, going, look, looking: 0.14061684371374158\n",
      "skipgram_150_dense: go, going, look, looking: 0.14720249473774485\n",
      "skipgram_300_dense: go, going, look, looking: 0.002864495321771528\n",
      "\n",
      "co-occurance: listen, listening, look, looking: 0.26481698509308443\n",
      "cbow_50: listen, listening, look, looking: 0.3802069701610734\n",
      "cbow_150: listen, listening, look, looking: 0.36921053308958424\n",
      "cbow_300: listen, listening, look, looking: 0.23802999618462123\n",
      "cbow_50_dense: listen, listening, look, looking: 0.03956834867672034\n",
      "cbow_150_dense: listen, listening, look, looking: 0.025226025836383444\n",
      "cbow_300_dense: listen, listening, look, looking: 0.08170528413458206\n",
      "skipgram_50: listen, listening, look, looking: 0.21922497121328843\n",
      "skipgram_150: listen, listening, look, looking: 0.11884336654412271\n",
      "skipgram_300: listen, listening, look, looking: 0.012053642266116044\n",
      "skipgram_50_dense: listen, listening, look, looking: 0.3328211143150717\n",
      "skipgram_150_dense: listen, listening, look, looking: 0.0595487007636639\n",
      "skipgram_300_dense: listen, listening, look, looking: 0.0406596642434014\n",
      "\n",
      "co-occurance: swim, swimming, sit, sitting: 0.02995723447576391\n",
      "cbow_50: swim, swimming, sit, sitting: 0.48978575850663114\n",
      "cbow_150: swim, swimming, sit, sitting: 0.22129192423968272\n",
      "cbow_300: swim, swimming, sit, sitting: 0.04745686624994828\n",
      "cbow_50_dense: swim, swimming, sit, sitting: 0.021958860917220397\n",
      "cbow_150_dense: swim, swimming, sit, sitting: 0.17068327726846955\n",
      "cbow_300_dense: swim, swimming, sit, sitting: 0.03918166245483594\n",
      "skipgram_50: swim, swimming, sit, sitting: 0.2045576159267067\n",
      "skipgram_150: swim, swimming, sit, sitting: 0.02695449005542896\n",
      "skipgram_300: swim, swimming, sit, sitting: 0.0759698816019391\n",
      "skipgram_50_dense: swim, swimming, sit, sitting: 0.03028533116032402\n",
      "skipgram_150_dense: swim, swimming, sit, sitting: 0.05055787779525484\n",
      "skipgram_300_dense: swim, swimming, sit, sitting: 0.03563140413128219\n",
      "\n",
      "co-occurance: run, running, listen, listening: 0.13591085134405553\n",
      "cbow_50: run, running, listen, listening: 0.7591559036884049\n",
      "cbow_150: run, running, listen, listening: 0.500506534222073\n",
      "cbow_300: run, running, listen, listening: 0.2172115315370583\n",
      "cbow_50_dense: run, running, listen, listening: 0.1839417128743973\n",
      "cbow_150_dense: run, running, listen, listening: 0.22631221236606874\n",
      "cbow_300_dense: run, running, listen, listening: 0.16730155288174092\n",
      "skipgram_50: run, running, listen, listening: 0.008977071763193276\n",
      "skipgram_150: run, running, listen, listening: 0.06712680136774937\n",
      "skipgram_300: run, running, listen, listening: 0.05989072385340193\n",
      "skipgram_50_dense: run, running, listen, listening: 0.0398748541017174\n",
      "skipgram_150_dense: run, running, listen, listening: 0.012654900797069137\n",
      "skipgram_300_dense: run, running, listen, listening: 0.052294495200113054\n",
      "\n",
      "co-occurance: think, thinking, read, reading: 0.307303933969022\n",
      "cbow_50: think, thinking, read, reading: 0.2990498498151042\n",
      "cbow_150: think, thinking, read, reading: 0.2330940450897781\n",
      "cbow_300: think, thinking, read, reading: 0.16911559484697625\n",
      "cbow_50_dense: think, thinking, read, reading: 0.3787095492702201\n",
      "cbow_150_dense: think, thinking, read, reading: 0.3078049519115134\n",
      "cbow_300_dense: think, thinking, read, reading: 0.08962903058811725\n",
      "skipgram_50: think, thinking, read, reading: 0.06297131665063069\n",
      "skipgram_150: think, thinking, read, reading: 0.0061040761486036025\n",
      "skipgram_300: think, thinking, read, reading: 0.022228808308668864\n",
      "skipgram_50_dense: think, thinking, read, reading: 0.126542806632079\n",
      "skipgram_150_dense: think, thinking, read, reading: 0.0181158051746606\n",
      "skipgram_300_dense: think, thinking, read, reading: 0.03892256124563785\n",
      "\n",
      "co-occurance: up, down, close, far: 0.28084517529031744\n",
      "cbow_50: up, down, close, far: 0.36010716857066855\n",
      "cbow_150: up, down, close, far: 0.36598875609203435\n",
      "cbow_300: up, down, close, far: 0.21333871878277946\n",
      "cbow_50_dense: up, down, close, far: 0.19196383523652996\n",
      "cbow_150_dense: up, down, close, far: 0.009307886939470968\n",
      "cbow_300_dense: up, down, close, far: 0.007063529840594001\n",
      "skipgram_50: up, down, close, far: 0.006113836150702873\n",
      "skipgram_150: up, down, close, far: 0.16539584160054252\n",
      "skipgram_300: up, down, close, far: 0.1783465178663802\n",
      "skipgram_50_dense: up, down, close, far: 0.04473971846960458\n",
      "skipgram_150_dense: up, down, close, far: 0.14023607002769808\n",
      "skipgram_300_dense: up, down, close, far: 0.018702310370623847\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#coocurrence analogy performance\n",
    "cbow50analogylist=[]\n",
    "cbow50denseanalogylist=[]\n",
    "cbow150analogylist=[]\n",
    "cbow150denseanalogylist=[]\n",
    "cbow300analogylist=[]\n",
    "cbow300denseanalogylist=[]\n",
    "skipgram50analogylist=[]\n",
    "skipgram50denseanalogylist=[]\n",
    "skipgram150analogylist=[]\n",
    "skipgram150denseanalogylist=[]\n",
    "skipgram300analogylist=[]\n",
    "skipgram300denseanalogylist=[]\n",
    "co_occurrencelist=[]\n",
    "\n",
    "\n",
    "for analogy in analogy_list:\n",
    "    if(analogy[0] in tokenizer.word_index and analogy[1] in tokenizer.word_index and analogy[2] in tokenizer.word_index and analogy[3] in tokenizer.word_index):\n",
    "        try:\n",
    "            co_occurrenceanalogy=analogy_check(analogy,tf_cooc, tokenizer.word_index )\n",
    "            cbow50analogy=analogy_check(analogy,embed_cbow_50, tokenizer.word_index )\n",
    "            cbow150analogy=analogy_check(analogy,embed_cbow_150, tokenizer.word_index )\n",
    "            cbow300analogy=analogy_check(analogy,embed_cbow_300, tokenizer.word_index )\n",
    "            cbow50denseanalogy=analogy_check(analogy,embed_cbow_50_dense, tokenizer.word_index )\n",
    "            cbow150denseanalogy=analogy_check(analogy,embed_cbow_150_dense, tokenizer.word_index )\n",
    "            cbow300denseanalogy=analogy_check(analogy,embed_cbow_300_dense, tokenizer.word_index )\n",
    "            skipgram50analogy=analogy_check(analogy,embed_skipgram_50, tokenizer.word_index )\n",
    "            skipgram150analogy=analogy_check(analogy,embed_skipgram_150, tokenizer.word_index )\n",
    "            skipgram300analogy=analogy_check(analogy,embed_skipgram_300, tokenizer.word_index )\n",
    "            skipgram50denseanalogy=analogy_check(analogy,embed_skipgram_50_dense, tokenizer.word_index )\n",
    "            skipgram150denseanalogy=analogy_check(analogy,embed_skipgram_150_dense, tokenizer.word_index )\n",
    "            skipgram300denseanalogy=analogy_check(analogy,embed_skipgram_300_dense, tokenizer.word_index )\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(\"co-occurance: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],co_occurrenceanalogy))\n",
    "            print(\"cbow_50: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow50analogy))\n",
    "            print(\"cbow_150: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow150analogy))\n",
    "            print(\"cbow_300: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow300analogy))\n",
    "            print(\"cbow_50_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow50denseanalogy))\n",
    "            print(\"cbow_150_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow150denseanalogy))\n",
    "            print(\"cbow_300_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow300denseanalogy))\n",
    "            print(\"skipgram_50: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram50analogy))\n",
    "            print(\"skipgram_150: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram150analogy))\n",
    "            print(\"skipgram_300: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram300analogy))\n",
    "            print(\"skipgram_50_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram50denseanalogy))\n",
    "            print(\"skipgram_150_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram150denseanalogy))\n",
    "            print(\"skipgram_300_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram300denseanalogy))\n",
    "            \n",
    "            \n",
    "            co_occurrencelist.append(co_occurrenceanalogy)\n",
    "            cbow50analogylist.append(cbow50analogy)\n",
    "            cbow150analogylist.append(cbow150analogy)\n",
    "            cbow300analogylist.append(cbow300analogy)\n",
    "            cbow50denseanalogylist.append(cbow50denseanalogy)\n",
    "            cbow150denseanalogylist.append(cbow150denseanalogy)\n",
    "            cbow300denseanalogylist.append(cbow300denseanalogy)\n",
    "            skipgram50analogylist.append(skipgram50analogy)\n",
    "            skipgram150analogylist.append(skipgram150analogy)\n",
    "            skipgram300analogylist.append(skipgram300analogy)\n",
    "            skipgram50denseanalogylist.append(skipgram50denseanalogy)\n",
    "            skipgram150denseanalogylist.append(skipgram150denseanalogy)\n",
    "            skipgram300denseanalogylist.append(skipgram300denseanalogy)\n",
    "            \n",
    "            \n",
    "            print()\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "co-occurance: sudden, suddenly, usual, usually: are\n",
      "cbow_50: sudden, suddenly, usual, usually: come\n",
      "cbow_150: sudden, suddenly, usual, usually: come\n",
      "cbow_300: sudden, suddenly, usual, usually: come\n",
      "cbow_50_dense: sudden, suddenly, usual, usually: so\n",
      "cbow_150_dense: sudden, suddenly, usual, usually: so\n",
      "cbow_300_dense: sudden, suddenly, usual, usually: so\n",
      "skipgram_50: sudden, suddenly, usual, usually: air\n",
      "skipgram_150: sudden, suddenly, usual, usually: he\n",
      "skipgram_300: sudden, suddenly, usual, usually: shall\n",
      "skipgram_50_dense: sudden, suddenly, usual, usually: ringlets\n",
      "skipgram_150_dense: sudden, suddenly, usual, usually: offer\n",
      "skipgram_300_dense: sudden, suddenly, usual, usually: which\n",
      "\n",
      "co-occurance: bad, worse, good, better: declare\n",
      "cbow_50: bad, worse, good, better: now\n",
      "cbow_150: bad, worse, good, better: thump\n",
      "cbow_300: bad, worse, good, better: the\n",
      "cbow_50_dense: bad, worse, good, better: shore\n",
      "cbow_150_dense: bad, worse, good, better: girl\n",
      "cbow_300_dense: bad, worse, good, better: the\n",
      "skipgram_50: bad, worse, good, better: miles\n",
      "skipgram_150: bad, worse, good, better: question\n",
      "skipgram_300: bad, worse, good, better: throw\n",
      "skipgram_50_dense: bad, worse, good, better: waited\n",
      "skipgram_150_dense: bad, worse, good, better: find\n",
      "skipgram_300_dense: bad, worse, good, better: splendidly\n",
      "\n",
      "co-occurance: go, going, look, looking: mouse\n",
      "cbow_50: go, going, look, looking: found\n",
      "cbow_150: go, going, look, looking: found\n",
      "cbow_300: go, going, look, looking: have\n",
      "cbow_50_dense: go, going, look, looking: fancy\n",
      "cbow_150_dense: go, going, look, looking: why\n",
      "cbow_300_dense: go, going, look, looking: have\n",
      "skipgram_50: go, going, look, looking: on\n",
      "skipgram_150: go, going, look, looking: her\n",
      "skipgram_300: go, going, look, looking: thing\n",
      "skipgram_50_dense: go, going, look, looking: her\n",
      "skipgram_150_dense: go, going, look, looking: cunning\n",
      "skipgram_300_dense: go, going, look, looking: avoid\n",
      "\n",
      "co-occurance: he, she, his, her: up\n",
      "cbow_50: he, she, his, her: off\n",
      "cbow_150: he, she, his, her: off\n",
      "cbow_300: he, she, his, her: off\n",
      "cbow_50_dense: he, she, his, her: off\n",
      "cbow_150_dense: he, she, his, her: off\n",
      "cbow_300_dense: he, she, his, her: off\n",
      "skipgram_50: he, she, his, her: it\n",
      "skipgram_150: he, she, his, her: it\n",
      "skipgram_300: he, she, his, her: it\n",
      "skipgram_50_dense: he, she, his, her: bank\n",
      "skipgram_150_dense: he, she, his, her: idea\n",
      "skipgram_300_dense: he, she, his, her: alice\n",
      "\n",
      "co-occurance: brother, sister, his, her: toffee\n",
      "cbow_50: brother, sister, his, her: ask\n",
      "cbow_150: brother, sister, his, her: ask\n",
      "cbow_300: brother, sister, his, her: away\n",
      "cbow_50_dense: brother, sister, his, her: leave\n",
      "cbow_150_dense: brother, sister, his, her: sure\n",
      "cbow_300_dense: brother, sister, his, her: was\n",
      "skipgram_50: brother, sister, his, her: pardon\n",
      "skipgram_150: brother, sister, his, her: through\n",
      "skipgram_300: brother, sister, his, her: shoulders\n",
      "skipgram_50_dense: brother, sister, his, her: seen\n",
      "skipgram_150_dense: brother, sister, his, her: throat\n",
      "skipgram_300_dense: brother, sister, his, her: come\n",
      "\n",
      "co-occurance: listen, listening, look, looking: cunning\n",
      "cbow_50: listen, listening, look, looking: filled\n",
      "cbow_150: listen, listening, look, looking: filled\n",
      "cbow_300: listen, listening, look, looking: its\n",
      "cbow_50_dense: listen, listening, look, looking: girl\n",
      "cbow_150_dense: listen, listening, look, looking: currants\n",
      "cbow_300_dense: listen, listening, look, looking: into\n",
      "skipgram_50: listen, listening, look, looking: pair\n",
      "skipgram_150: listen, listening, look, looking: crab\n",
      "skipgram_300: listen, listening, look, looking: dull\n",
      "skipgram_50_dense: listen, listening, look, looking: water\n",
      "skipgram_150_dense: listen, listening, look, looking: won\n",
      "skipgram_300_dense: listen, listening, look, looking: calling\n",
      "\n",
      "co-occurance: saying, said, thinking, thought: in\n",
      "cbow_50: saying, said, thinking, thought: quite\n",
      "cbow_150: saying, said, thinking, thought: quite\n",
      "cbow_300: saying, said, thinking, thought: quite\n",
      "cbow_50_dense: saying, said, thinking, thought: quite\n",
      "cbow_150_dense: saying, said, thinking, thought: quite\n",
      "cbow_300_dense: saying, said, thinking, thought: quite\n",
      "skipgram_50: saying, said, thinking, thought: or\n",
      "skipgram_150: saying, said, thinking, thought: with\n",
      "skipgram_300: saying, said, thinking, thought: s\n",
      "skipgram_50_dense: saying, said, thinking, thought: usually\n",
      "skipgram_150_dense: saying, said, thinking, thought: maps\n",
      "skipgram_300_dense: saying, said, thinking, thought: had\n",
      "\n",
      "co-occurance: bird, birds, cat, cats: not\n",
      "cbow_50: bird, birds, cat, cats: our\n",
      "cbow_150: bird, birds, cat, cats: our\n",
      "cbow_300: bird, birds, cat, cats: our\n",
      "cbow_50_dense: bird, birds, cat, cats: see\n",
      "cbow_150_dense: bird, birds, cat, cats: our\n",
      "cbow_300_dense: bird, birds, cat, cats: see\n",
      "skipgram_50: bird, birds, cat, cats: said\n",
      "skipgram_150: bird, birds, cat, cats: up\n",
      "skipgram_300: bird, birds, cat, cats: high\n",
      "skipgram_50_dense: bird, birds, cat, cats: tidy\n",
      "skipgram_150_dense: bird, birds, cat, cats: skurried\n",
      "skipgram_300_dense: bird, birds, cat, cats: improve\n",
      "\n",
      "co-occurance: good, better, old, older: which\n",
      "cbow_50: good, better, old, older: never\n",
      "cbow_150: good, better, old, older: coming\n",
      "cbow_300: good, better, old, older: no\n",
      "cbow_50_dense: good, better, old, older: never\n",
      "cbow_150_dense: good, better, old, older: never\n",
      "cbow_300_dense: good, better, old, older: never\n",
      "skipgram_50: good, better, old, older: after\n",
      "skipgram_150: good, better, old, older: despair\n",
      "skipgram_300: good, better, old, older: have\n",
      "skipgram_50_dense: good, better, old, older: your\n",
      "skipgram_150_dense: good, better, old, older: absurd\n",
      "skipgram_300_dense: good, better, old, older: mice\n",
      "\n",
      "co-occurance: good, better, quick, quicker: which\n",
      "cbow_50: good, better, quick, quicker: never\n",
      "cbow_150: good, better, quick, quicker: coming\n",
      "cbow_300: good, better, quick, quicker: no\n",
      "cbow_50_dense: good, better, quick, quicker: never\n",
      "cbow_150_dense: good, better, quick, quicker: never\n",
      "cbow_300_dense: good, better, quick, quicker: never\n",
      "skipgram_50: good, better, quick, quicker: after\n",
      "skipgram_150: good, better, quick, quicker: despair\n",
      "skipgram_300: good, better, quick, quicker: have\n",
      "skipgram_50_dense: good, better, quick, quicker: your\n",
      "skipgram_150_dense: good, better, quick, quicker: absurd\n",
      "skipgram_300_dense: good, better, quick, quicker: mice\n",
      "\n",
      "co-occurance: large, largest, good, best: bye\n",
      "cbow_50: large, largest, good, best: rules\n",
      "cbow_150: large, largest, good, best: rules\n",
      "cbow_300: large, largest, good, best: slowly\n",
      "cbow_50_dense: large, largest, good, best: have\n",
      "cbow_150_dense: large, largest, good, best: his\n",
      "cbow_300_dense: large, largest, good, best: rules\n",
      "skipgram_50: large, largest, good, best: door\n",
      "skipgram_150: large, largest, good, best: cool\n",
      "skipgram_300: large, largest, good, best: rabbit\n",
      "skipgram_50_dense: large, largest, good, best: dripping\n",
      "skipgram_150_dense: large, largest, good, best: deep\n",
      "skipgram_300_dense: large, largest, good, best: reach\n",
      "\n",
      "co-occurance: falling, fell, knowing, knew: completely\n",
      "cbow_50: falling, fell, knowing, knew: trouble\n",
      "cbow_150: falling, fell, knowing, knew: trouble\n",
      "cbow_300: falling, fell, knowing, knew: small\n",
      "cbow_50_dense: falling, fell, knowing, knew: small\n",
      "cbow_150_dense: falling, fell, knowing, knew: small\n",
      "cbow_300_dense: falling, fell, knowing, knew: looked\n",
      "skipgram_50: falling, fell, knowing, knew: hour\n",
      "skipgram_150: falling, fell, knowing, knew: engraved\n",
      "skipgram_300: falling, fell, knowing, knew: bed\n",
      "skipgram_50_dense: falling, fell, knowing, knew: open\n",
      "skipgram_150_dense: falling, fell, knowing, knew: confused\n",
      "skipgram_300_dense: falling, fell, knowing, knew: or\n",
      "\n",
      "co-occurance: walk, walking, think, thinking: bit\n",
      "cbow_50: walk, walking, think, thinking: almost\n",
      "cbow_150: walk, walking, think, thinking: almost\n",
      "cbow_300: walk, walking, think, thinking: into\n",
      "cbow_50_dense: walk, walking, think, thinking: into\n",
      "cbow_150_dense: walk, walking, think, thinking: gloves\n",
      "cbow_300_dense: walk, walking, think, thinking: head\n",
      "skipgram_50: walk, walking, think, thinking: fountains\n",
      "skipgram_150: walk, walking, think, thinking: poky\n",
      "skipgram_300: walk, walking, think, thinking: hair\n",
      "skipgram_50_dense: walk, walking, think, thinking: fall\n",
      "skipgram_150_dense: walk, walking, think, thinking: history\n",
      "skipgram_300_dense: walk, walking, think, thinking: them\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "co-occurance: child, children, cat, cats: enough\n",
      "cbow_50: child, children, cat, cats: mixed\n",
      "cbow_150: child, children, cat, cats: door\n",
      "cbow_300: child, children, cat, cats: find\n",
      "cbow_50_dense: child, children, cat, cats: morning\n",
      "cbow_150_dense: child, children, cat, cats: histories\n",
      "cbow_300_dense: child, children, cat, cats: know\n",
      "skipgram_50: child, children, cat, cats: refused\n",
      "skipgram_150: child, children, cat, cats: more\n",
      "skipgram_300: child, children, cat, cats: over\n",
      "skipgram_50_dense: child, children, cat, cats: wondered\n",
      "skipgram_150_dense: child, children, cat, cats: solid\n",
      "skipgram_300_dense: child, children, cat, cats: caused\n",
      "\n",
      "co-occurance: dog, dogs, eye, eyes: who\n",
      "cbow_50: dog, dogs, eye, eyes: started\n",
      "cbow_150: dog, dogs, eye, eyes: who\n",
      "cbow_300: dog, dogs, eye, eyes: who\n",
      "cbow_50_dense: dog, dogs, eye, eyes: lory\n",
      "cbow_150_dense: dog, dogs, eye, eyes: another\n",
      "cbow_300_dense: dog, dogs, eye, eyes: grow\n",
      "skipgram_50: dog, dogs, eye, eyes: people\n",
      "skipgram_150: dog, dogs, eye, eyes: sort\n",
      "skipgram_300: dog, dogs, eye, eyes: one\n",
      "skipgram_50_dense: dog, dogs, eye, eyes: ugh\n",
      "skipgram_150_dense: dog, dogs, eye, eyes: lest\n",
      "skipgram_300_dense: dog, dogs, eye, eyes: houses\n",
      "\n",
      "co-occurance: hand, hands, rat, rats: doth\n",
      "cbow_50: hand, hands, rat, rats: daisy\n",
      "cbow_150: hand, hands, rat, rats: daisy\n",
      "cbow_300: hand, hands, rat, rats: have\n",
      "cbow_50_dense: hand, hands, rat, rats: more\n",
      "cbow_150_dense: hand, hands, rat, rats: shall\n",
      "cbow_300_dense: hand, hands, rat, rats: shall\n",
      "skipgram_50: hand, hands, rat, rats: always\n",
      "skipgram_150: hand, hands, rat, rats: reach\n",
      "skipgram_300: hand, hands, rat, rats: whiskers\n",
      "skipgram_50_dense: hand, hands, rat, rats: whether\n",
      "skipgram_150_dense: hand, hands, rat, rats: window\n",
      "skipgram_300_dense: hand, hands, rat, rats: sister\n",
      "\n",
      "co-occurance: eat, eats, find, finds: ii\n",
      "cbow_50: eat, eats, find, finds: room\n",
      "cbow_150: eat, eats, find, finds: face\n",
      "cbow_300: eat, eats, find, finds: getting\n",
      "cbow_50_dense: eat, eats, find, finds: foot\n",
      "cbow_150_dense: eat, eats, find, finds: ve\n",
      "cbow_300_dense: eat, eats, find, finds: ve\n",
      "skipgram_50: eat, eats, find, finds: narrow\n",
      "skipgram_150: eat, eats, find, finds: violently\n",
      "skipgram_300: eat, eats, find, finds: dipped\n",
      "skipgram_50_dense: eat, eats, find, finds: call\n",
      "skipgram_150_dense: eat, eats, find, finds: happen\n",
      "skipgram_300_dense: eat, eats, find, finds: alas\n",
      "\n",
      "co-occurance: find, finds, say, says: eaglet\n",
      "cbow_50: find, finds, say, says: while\n",
      "cbow_150: find, finds, say, says: morning\n",
      "cbow_300: find, finds, say, says: yes\n",
      "cbow_50_dense: find, finds, say, says: middle\n",
      "cbow_150_dense: find, finds, say, says: up\n",
      "cbow_300_dense: find, finds, say, says: fell\n",
      "skipgram_50: find, finds, say, says: left\n",
      "skipgram_150: find, finds, say, says: pardon\n",
      "skipgram_300: find, finds, say, says: then\n",
      "skipgram_50_dense: find, finds, say, says: tidy\n",
      "skipgram_150_dense: find, finds, say, says: pity\n",
      "skipgram_300_dense: find, finds, say, says: natural\n",
      "\n",
      "co-occurance: old, older, good, better: soothing\n",
      "cbow_50: old, older, good, better: cold\n",
      "cbow_150: old, older, good, better: perhaps\n",
      "cbow_300: old, older, good, better: its\n",
      "cbow_50_dense: old, older, good, better: something\n",
      "cbow_150_dense: old, older, good, better: don\n",
      "cbow_300_dense: old, older, good, better: don\n",
      "skipgram_50: old, older, good, better: grand\n",
      "skipgram_150: old, older, good, better: presented\n",
      "skipgram_300: old, older, good, better: than\n",
      "skipgram_50_dense: old, older, good, better: allow\n",
      "skipgram_150_dense: old, older, good, better: patriotic\n",
      "skipgram_300_dense: old, older, good, better: face\n",
      "\n",
      "co-occurance: large, larger, quick, quicker: say\n",
      "cbow_50: large, larger, quick, quicker: speed\n",
      "cbow_150: large, larger, quick, quicker: nasty\n",
      "cbow_300: large, larger, quick, quicker: altogether\n",
      "cbow_50_dense: large, larger, quick, quicker: particular\n",
      "cbow_150_dense: large, larger, quick, quicker: seemed\n",
      "cbow_300_dense: large, larger, quick, quicker: your\n",
      "skipgram_50: large, larger, quick, quicker: saw\n",
      "skipgram_150: large, larger, quick, quicker: eat\n",
      "skipgram_300: large, larger, quick, quicker: upon\n",
      "skipgram_50_dense: large, larger, quick, quicker: voices\n",
      "skipgram_150_dense: large, larger, quick, quicker: fall\n",
      "skipgram_300_dense: large, larger, quick, quicker: authority\n",
      "\n",
      "co-occurance: go, going, listen, listening: mouse\n",
      "cbow_50: go, going, listen, listening: found\n",
      "cbow_150: go, going, listen, listening: found\n",
      "cbow_300: go, going, listen, listening: have\n",
      "cbow_50_dense: go, going, listen, listening: fancy\n",
      "cbow_150_dense: go, going, listen, listening: why\n",
      "cbow_300_dense: go, going, listen, listening: have\n",
      "skipgram_50: go, going, listen, listening: on\n",
      "skipgram_150: go, going, listen, listening: her\n",
      "skipgram_300: go, going, listen, listening: thing\n",
      "skipgram_50_dense: go, going, listen, listening: her\n",
      "skipgram_150_dense: go, going, listen, listening: cunning\n",
      "skipgram_300_dense: go, going, listen, listening: avoid\n",
      "\n",
      "co-occurance: run, running, walk, walking: they\n",
      "cbow_50: run, running, walk, walking: us\n",
      "cbow_150: run, running, walk, walking: moment\n",
      "cbow_300: run, running, walk, walking: than\n",
      "cbow_50_dense: run, running, walk, walking: tunnel\n",
      "cbow_150_dense: run, running, walk, walking: used\n",
      "cbow_300_dense: run, running, walk, walking: beds\n",
      "skipgram_50: run, running, walk, walking: happens\n",
      "skipgram_150: run, running, walk, walking: latin\n",
      "skipgram_300: run, running, walk, walking: our\n",
      "skipgram_50_dense: run, running, walk, walking: splashing\n",
      "skipgram_150_dense: run, running, walk, walking: eat\n",
      "skipgram_300_dense: run, running, walk, walking: her\n",
      "\n",
      "co-occurance: run, running, think, thinking: they\n",
      "cbow_50: run, running, think, thinking: us\n",
      "cbow_150: run, running, think, thinking: moment\n",
      "cbow_300: run, running, think, thinking: than\n",
      "cbow_50_dense: run, running, think, thinking: tunnel\n",
      "cbow_150_dense: run, running, think, thinking: used\n",
      "cbow_300_dense: run, running, think, thinking: beds\n",
      "skipgram_50: run, running, think, thinking: happens\n",
      "skipgram_150: run, running, think, thinking: latin\n",
      "skipgram_300: run, running, think, thinking: our\n",
      "skipgram_50_dense: run, running, think, thinking: splashing\n",
      "skipgram_150_dense: run, running, think, thinking: eat\n",
      "skipgram_300_dense: run, running, think, thinking: her\n",
      "\n",
      "co-occurance: say, saying, sit, sitting: box\n",
      "cbow_50: say, saying, sit, sitting: see\n",
      "cbow_150: say, saying, sit, sitting: having\n",
      "cbow_300: say, saying, sit, sitting: ever\n",
      "cbow_50_dense: say, saying, sit, sitting: sooner\n",
      "cbow_150_dense: say, saying, sit, sitting: white\n",
      "cbow_300_dense: say, saying, sit, sitting: herself\n",
      "skipgram_50: say, saying, sit, sitting: enough\n",
      "skipgram_150: say, saying, sit, sitting: them\n",
      "skipgram_300: say, saying, sit, sitting: her\n",
      "skipgram_50_dense: say, saying, sit, sitting: sitting\n",
      "skipgram_150_dense: say, saying, sit, sitting: explain\n",
      "skipgram_300_dense: say, saying, sit, sitting: young\n",
      "\n",
      "co-occurance: alice, she, rabbit, he: up\n",
      "cbow_50: alice, she, rabbit, he: off\n",
      "cbow_150: alice, she, rabbit, he: off\n",
      "cbow_300: alice, she, rabbit, he: off\n",
      "cbow_50_dense: alice, she, rabbit, he: off\n",
      "cbow_150_dense: alice, she, rabbit, he: off\n",
      "cbow_300_dense: alice, she, rabbit, he: off\n",
      "skipgram_50: alice, she, rabbit, he: it\n",
      "skipgram_150: alice, she, rabbit, he: it\n",
      "skipgram_300: alice, she, rabbit, he: it\n",
      "skipgram_50_dense: alice, she, rabbit, he: bank\n",
      "skipgram_150_dense: alice, she, rabbit, he: he\n",
      "skipgram_300_dense: alice, she, rabbit, he: it\n",
      "\n",
      "co-occurance: alice, her, rabbit, him: sight\n",
      "cbow_50: alice, her, rabbit, him: sat\n",
      "cbow_150: alice, her, rabbit, him: pocket\n",
      "cbow_300: alice, her, rabbit, him: out\n",
      "cbow_50_dense: alice, her, rabbit, him: pocket\n",
      "cbow_150_dense: alice, her, rabbit, him: over\n",
      "cbow_300_dense: alice, her, rabbit, him: over\n",
      "skipgram_50: alice, her, rabbit, him: herself\n",
      "skipgram_150: alice, her, rabbit, him: herself\n",
      "skipgram_300: alice, her, rabbit, him: this\n",
      "skipgram_50_dense: alice, her, rabbit, him: declare\n",
      "skipgram_150_dense: alice, her, rabbit, him: burn\n",
      "skipgram_300_dense: alice, her, rabbit, him: notion\n",
      "\n",
      "co-occurance: alice, girl, rabbit, sir: asking\n",
      "cbow_50: alice, girl, rabbit, sir: worth\n",
      "cbow_150: alice, girl, rabbit, sir: next\n",
      "cbow_300: alice, girl, rabbit, sir: made\n",
      "cbow_50_dense: alice, girl, rabbit, sir: off\n",
      "cbow_150_dense: alice, girl, rabbit, sir: off\n",
      "cbow_300_dense: alice, girl, rabbit, sir: off\n",
      "skipgram_50: alice, girl, rabbit, sir: ate\n",
      "skipgram_150: alice, girl, rabbit, sir: milk\n",
      "skipgram_300: alice, girl, rabbit, sir: too\n",
      "skipgram_50_dense: alice, girl, rabbit, sir: delight\n",
      "skipgram_150_dense: alice, girl, rabbit, sir: dreamy\n",
      "skipgram_300_dense: alice, girl, rabbit, sir: wonder\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "co-occurance: dinah, cat, alice, girl: afraid\n",
      "cbow_50: dinah, cat, alice, girl: william\n",
      "cbow_150: dinah, cat, alice, girl: william\n",
      "cbow_300: dinah, cat, alice, girl: are\n",
      "cbow_50_dense: dinah, cat, alice, girl: are\n",
      "cbow_150_dense: dinah, cat, alice, girl: are\n",
      "cbow_300_dense: dinah, cat, alice, girl: william\n",
      "skipgram_50: dinah, cat, alice, girl: live\n",
      "skipgram_150: dinah, cat, alice, girl: from\n",
      "skipgram_300: dinah, cat, alice, girl: come\n",
      "skipgram_50_dense: dinah, cat, alice, girl: bottle\n",
      "skipgram_150_dense: dinah, cat, alice, girl: sooner\n",
      "skipgram_300_dense: dinah, cat, alice, girl: love\n",
      "\n",
      "co-occurance: his, her, he, she: sight\n",
      "cbow_50: his, her, he, she: sat\n",
      "cbow_150: his, her, he, she: pocket\n",
      "cbow_300: his, her, he, she: out\n",
      "cbow_50_dense: his, her, he, she: pocket\n",
      "cbow_150_dense: his, her, he, she: over\n",
      "cbow_300_dense: his, her, he, she: over\n",
      "skipgram_50: his, her, he, she: herself\n",
      "skipgram_150: his, her, he, she: herself\n",
      "skipgram_300: his, her, he, she: this\n",
      "skipgram_50_dense: his, her, he, she: declare\n",
      "skipgram_150_dense: his, her, he, she: burn\n",
      "skipgram_300_dense: his, her, he, she: notion\n",
      "\n",
      "co-occurance: long, longer, quick, quicker: labelled\n",
      "cbow_50: long, longer, quick, quicker: am\n",
      "cbow_150: long, longer, quick, quicker: am\n",
      "cbow_300: long, longer, quick, quicker: say\n",
      "cbow_50_dense: long, longer, quick, quicker: shall\n",
      "cbow_150_dense: long, longer, quick, quicker: gave\n",
      "cbow_300_dense: long, longer, quick, quicker: noticed\n",
      "skipgram_50: long, longer, quick, quicker: declared\n",
      "skipgram_150: long, longer, quick, quicker: glad\n",
      "skipgram_300: long, longer, quick, quicker: making\n",
      "skipgram_50_dense: long, longer, quick, quicker: reach\n",
      "skipgram_150_dense: long, longer, quick, quicker: sulky\n",
      "skipgram_300_dense: long, longer, quick, quicker: pale\n",
      "\n",
      "co-occurance: long, longer, small, smaller: labelled\n",
      "cbow_50: long, longer, small, smaller: am\n",
      "cbow_150: long, longer, small, smaller: am\n",
      "cbow_300: long, longer, small, smaller: say\n",
      "cbow_50_dense: long, longer, small, smaller: shall\n",
      "cbow_150_dense: long, longer, small, smaller: gave\n",
      "cbow_300_dense: long, longer, small, smaller: noticed\n",
      "skipgram_50: long, longer, small, smaller: declared\n",
      "skipgram_150: long, longer, small, smaller: glad\n",
      "skipgram_300: long, longer, small, smaller: making\n",
      "skipgram_50_dense: long, longer, small, smaller: reach\n",
      "skipgram_150_dense: long, longer, small, smaller: sulky\n",
      "skipgram_300_dense: long, longer, small, smaller: pale\n",
      "\n",
      "co-occurance: long, longer, bad, worse: labelled\n",
      "cbow_50: long, longer, bad, worse: am\n",
      "cbow_150: long, longer, bad, worse: am\n",
      "cbow_300: long, longer, bad, worse: say\n",
      "cbow_50_dense: long, longer, bad, worse: shall\n",
      "cbow_150_dense: long, longer, bad, worse: gave\n",
      "cbow_300_dense: long, longer, bad, worse: noticed\n",
      "skipgram_50: long, longer, bad, worse: declared\n",
      "skipgram_150: long, longer, bad, worse: glad\n",
      "skipgram_300: long, longer, bad, worse: making\n",
      "skipgram_50_dense: long, longer, bad, worse: reach\n",
      "skipgram_150_dense: long, longer, bad, worse: sulky\n",
      "skipgram_300_dense: long, longer, bad, worse: pale\n",
      "\n",
      "co-occurance: go, going, look, looking: mouse\n",
      "cbow_50: go, going, look, looking: found\n",
      "cbow_150: go, going, look, looking: found\n",
      "cbow_300: go, going, look, looking: have\n",
      "cbow_50_dense: go, going, look, looking: fancy\n",
      "cbow_150_dense: go, going, look, looking: why\n",
      "cbow_300_dense: go, going, look, looking: have\n",
      "skipgram_50: go, going, look, looking: on\n",
      "skipgram_150: go, going, look, looking: her\n",
      "skipgram_300: go, going, look, looking: thing\n",
      "skipgram_50_dense: go, going, look, looking: her\n",
      "skipgram_150_dense: go, going, look, looking: cunning\n",
      "skipgram_300_dense: go, going, look, looking: avoid\n",
      "\n",
      "co-occurance: listen, listening, look, looking: cunning\n",
      "cbow_50: listen, listening, look, looking: filled\n",
      "cbow_150: listen, listening, look, looking: filled\n",
      "cbow_300: listen, listening, look, looking: its\n",
      "cbow_50_dense: listen, listening, look, looking: girl\n",
      "cbow_150_dense: listen, listening, look, looking: currants\n",
      "cbow_300_dense: listen, listening, look, looking: into\n",
      "skipgram_50: listen, listening, look, looking: pair\n",
      "skipgram_150: listen, listening, look, looking: crab\n",
      "skipgram_300: listen, listening, look, looking: dull\n",
      "skipgram_50_dense: listen, listening, look, looking: water\n",
      "skipgram_150_dense: listen, listening, look, looking: won\n",
      "skipgram_300_dense: listen, listening, look, looking: calling\n",
      "\n",
      "co-occurance: swim, swimming, sit, sitting: suppose\n",
      "cbow_50: swim, swimming, sit, sitting: re\n",
      "cbow_150: swim, swimming, sit, sitting: re\n",
      "cbow_300: swim, swimming, sit, sitting: things\n",
      "cbow_50_dense: swim, swimming, sit, sitting: up\n",
      "cbow_150_dense: swim, swimming, sit, sitting: was\n",
      "cbow_300_dense: swim, swimming, sit, sitting: was\n",
      "skipgram_50: swim, swimming, sit, sitting: rabbit\n",
      "skipgram_150: swim, swimming, sit, sitting: world\n",
      "skipgram_300: swim, swimming, sit, sitting: herself\n",
      "skipgram_50_dense: swim, swimming, sit, sitting: noticed\n",
      "skipgram_150_dense: swim, swimming, sit, sitting: desperate\n",
      "skipgram_300_dense: swim, swimming, sit, sitting: sticks\n",
      "\n",
      "co-occurance: run, running, listen, listening: they\n",
      "cbow_50: run, running, listen, listening: us\n",
      "cbow_150: run, running, listen, listening: moment\n",
      "cbow_300: run, running, listen, listening: than\n",
      "cbow_50_dense: run, running, listen, listening: tunnel\n",
      "cbow_150_dense: run, running, listen, listening: used\n",
      "cbow_300_dense: run, running, listen, listening: beds\n",
      "skipgram_50: run, running, listen, listening: happens\n",
      "skipgram_150: run, running, listen, listening: latin\n",
      "skipgram_300: run, running, listen, listening: our\n",
      "skipgram_50_dense: run, running, listen, listening: splashing\n",
      "skipgram_150_dense: run, running, listen, listening: eat\n",
      "skipgram_300_dense: run, running, listen, listening: her\n",
      "\n",
      "co-occurance: think, thinking, read, reading: ada\n",
      "cbow_50: think, thinking, read, reading: change\n",
      "cbow_150: think, thinking, read, reading: re\n",
      "cbow_300: think, thinking, read, reading: avoid\n",
      "cbow_50_dense: think, thinking, read, reading: tired\n",
      "cbow_150_dense: think, thinking, read, reading: doing\n",
      "cbow_300_dense: think, thinking, read, reading: was\n",
      "skipgram_50: think, thinking, read, reading: puzzle\n",
      "skipgram_150: think, thinking, read, reading: dry\n",
      "skipgram_300: think, thinking, read, reading: remembered\n",
      "skipgram_50_dense: think, thinking, read, reading: play\n",
      "skipgram_150_dense: think, thinking, read, reading: somewhere\n",
      "skipgram_300_dense: think, thinking, read, reading: half\n",
      "\n",
      "co-occurance: up, down, close, far: say\n",
      "cbow_50: up, down, close, far: however\n",
      "cbow_150: up, down, close, far: however\n",
      "cbow_300: up, down, close, far: at\n",
      "cbow_50_dense: up, down, close, far: at\n",
      "cbow_150_dense: up, down, close, far: at\n",
      "cbow_300_dense: up, down, close, far: however\n",
      "skipgram_50: up, down, close, far: not\n",
      "skipgram_150: up, down, close, far: me\n",
      "skipgram_300: up, down, close, far: s\n",
      "skipgram_50_dense: up, down, close, far: again\n",
      "skipgram_150_dense: up, down, close, far: locked\n",
      "skipgram_300_dense: up, down, close, far: calling\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#co occurance analogy word guessing, take the first three of analogy, and guess the fourth\n",
    "cbow50analogylist=[]\n",
    "cbow50denseanalogylist=[]\n",
    "cbow150analogylist=[]\n",
    "cbow150denseanalogylist=[]\n",
    "cbow300analogylist=[]\n",
    "cbow300denseanalogylist=[]\n",
    "skipgram50analogylist=[]\n",
    "skipgram50denseanalogylist=[]\n",
    "skipgram150analogylist=[]\n",
    "skipgram150denseanalogylist=[]\n",
    "skipgram300analogylist=[]\n",
    "skipgram300denseanalogylist=[]\n",
    "co_occurrencelist=[]\n",
    "\n",
    "\n",
    "for analogy in analogy_list:\n",
    "    if(analogy[0] in tokenizer.word_index and analogy[1] in tokenizer.word_index and analogy[2] in tokenizer.word_index and analogy[3] in tokenizer.word_index):\n",
    "        try:\n",
    "            co_occurrenceanalogy=analogy_predict(analogy,tf_cooc, tokenizer.word_index )\n",
    "            cbow50analogy=analogy_predict(analogy,embed_cbow_50, tokenizer.word_index )\n",
    "            cbow150analogy=analogy_predict(analogy,embed_cbow_150, tokenizer.word_index )\n",
    "            cbow300analogy=analogy_predict(analogy,embed_cbow_300, tokenizer.word_index )\n",
    "            cbow50denseanalogy=analogy_predict(analogy,embed_cbow_50_dense, tokenizer.word_index )\n",
    "            cbow150denseanalogy=analogy_predict(analogy,embed_cbow_150_dense, tokenizer.word_index )\n",
    "            cbow300denseanalogy=analogy_predict(analogy,embed_cbow_300_dense, tokenizer.word_index )\n",
    "            skipgram50analogy=analogy_predict(analogy,embed_skipgram_50, tokenizer.word_index )\n",
    "            skipgram150analogy=analogy_predict(analogy,embed_skipgram_150, tokenizer.word_index )\n",
    "            skipgram300analogy=analogy_predict(analogy,embed_skipgram_300, tokenizer.word_index )\n",
    "            skipgram50denseanalogy=analogy_predict(analogy,embed_skipgram_50_dense, tokenizer.word_index )\n",
    "            skipgram150denseanalogy=analogy_predict(analogy,embed_skipgram_150_dense, tokenizer.word_index )\n",
    "            skipgram300denseanalogy=analogy_predict(analogy,embed_skipgram_300_dense, tokenizer.word_index )\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(\"co-occurance: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],co_occurrenceanalogy))\n",
    "            print(\"cbow_50: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow50analogy))\n",
    "            print(\"cbow_150: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow150analogy))\n",
    "            print(\"cbow_300: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow300analogy))\n",
    "            print(\"cbow_50_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow50denseanalogy))\n",
    "            print(\"cbow_150_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow150denseanalogy))\n",
    "            print(\"cbow_300_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbow300denseanalogy))\n",
    "            print(\"skipgram_50: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram50analogy))\n",
    "            print(\"skipgram_150: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram150analogy))\n",
    "            print(\"skipgram_300: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram300analogy))\n",
    "            print(\"skipgram_50_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram50denseanalogy))\n",
    "            print(\"skipgram_150_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram150denseanalogy))\n",
    "            print(\"skipgram_300_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgram300denseanalogy))\n",
    "            \n",
    "            \n",
    "            co_occurrencelist.append(co_occurrenceanalogy)\n",
    "            cbow50analogylist.append(cbow50analogy)\n",
    "            cbow150analogylist.append(cbow150analogy)\n",
    "            cbow300analogylist.append(cbow300analogy)\n",
    "            cbow50denseanalogylist.append(cbow50denseanalogy)\n",
    "            cbow150denseanalogylist.append(cbow150denseanalogy)\n",
    "            cbow300denseanalogylist.append(cbow300denseanalogy)\n",
    "            skipgram50analogylist.append(skipgram50analogy)\n",
    "            skipgram150analogylist.append(skipgram150analogy)\n",
    "            skipgram300analogylist.append(skipgram300analogy)\n",
    "            skipgram50denseanalogylist.append(skipgram50denseanalogy)\n",
    "            skipgram150denseanalogylist.append(skipgram150denseanalogy)\n",
    "            skipgram300denseanalogylist.append(skipgram300denseanalogy)\n",
    "            \n",
    "            \n",
    "            print()\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation results of the visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20e4b7019e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brother' 'sister' 'his' 'her']\n"
     ]
    }
   ],
   "source": [
    "#co_occurrence (tf normalized)\n",
    "\n",
    "w2visualize=analogy_list[5]\n",
    "embedlist=[]\n",
    "for i in range(4):\n",
    "    #embedlist.append(word2vec[analogy_list[1][i]])\n",
    "    embedlist.append(tf_cooc[tokenizer.word_index[w2visualize[i]]-1])\n",
    "plt.title(\"Co-occurrence (tf normalized)\")\n",
    "draw_word_vecs(embedlist,w2visualize)    \n",
    "print(w2visualize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "Using tf-normalized co-occurrence matrix as the embedding matrix, we can see that there are some analogy that has high similarity eventhough it has unrelated word structure (eg: by only adding -er or -ing). For example: (brother, sister, his, her) that has value of 0.61. This is happened because (brother, his) and (sister, her) are often closely located within each other in alice text.  \n",
    "\n",
    "In general, there are not a single vector representation that classifies all of the analogy with high similairty value. In some cases, for example (his, her, he, she), are represented highly similar (0.738) using co-occurrence because it often appeared closely with each other in the alice.txt. In another cases, (run, running, listen, listening) are represented highly similar (0.759) using cbow_50, because it is very rare to appear in the alixe.txt. Another analogy: (saying, said, thinking, thought) are highly similar (0.565) using skipgram_50 representation. This is because there are 462 'said' word in alice.txt, thus it is a common word.\n",
    "\n",
    "Having co-occurrence as embedding vector is memory consuming but it has relatively faster time to construct compared to cbow or skip. Meanwhile, cbow and skip are using less memory compared to co-occurrence but has more time to construct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 \n",
    "### Discussion of the advantages of CBOW and Skipgram, the advantages of negative sampling and drawbacks of CBOW and Skipgram\n",
    "\n",
    "CBOW tries to predict a word by context, it sees the context and maximizes the probability of the target word.\n",
    "This means CBOW is good at predicting frequent words. To train CBOW a reasonably low amount of data is sufficient.\n",
    "The drawback of CBOW is that whilst it will preform well at predicting frequent words it will have low accuracy for less frequent words.\n",
    "this is because some words compete in the sense that they are a valid target for the same context.\n",
    "The more frequent word will then be predicted.\n",
    "\n",
    "In negative sampling we choose random words to pair with the target and have an output of 0. \n",
    "The updating of the weights is then performed on these K samples, which reduces the computational requirements.\n",
    "The model does not need all observations but simply only the K sampled pairs (context + target).\n",
    "\n",
    "Skip gram is designed to predict context. It sees the target and tries to find the context around the word. \n",
    "Skip gram is rather well suited even for rare words. Thake the example delightfull, it will try to predict something like yesterday was a day.\n",
    "Whilst if CBOw would have gotten this context delightfull would have never been predicted it would have chosen more frequent words like good.\n",
    "The drawback for skip gram is that it requires a large amount of data to train. This is because if we for example look at the delightfull word it will have context.\n",
    "Similar nice will also have a context, delightfull day and nice day are 2 independant sets. In cbow this use of nice and delightfull would be competing since the context day has both \n",
    "delightfull and nice as targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7\n",
    "### Load pre-trained embeddings on large corpuses (see the pdf file). You only have to consider the word embeddings with an embedding size of 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pretrained word embeddings of word2vec\n",
    "\n",
    "path_word2vec = \"tes\\GoogleNews-vectors-negative300.bin\"\n",
    "\n",
    "word2vec = KeyedVectors.load_word2vec_format(path_word2vec, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pretraind word embeddings of Glove\n",
    "import gensim\n",
    "#path = \"tes\\glove.6B\\glove.6B.300d_converted.txt\"\n",
    "path = \"tes\\glove.6B.300d.txt\"\n",
    "\n",
    "#convert GloVe into word2vec format\n",
    "gensim.scripts.glove2word2vec.get_glove_info(path)\n",
    "gensim.scripts.glove2word2vec.glove2word2vec(path, \"glove_converted.txt\")\n",
    "\n",
    "glove = KeyedVectors.load_word2vec_format(\"glove_converted.txt\", binary=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v: sudden, suddenly, usual, usually: 0.22255026056670402\n",
      "glove: sudden, suddenly, usual, usually: 0.3100777731068751\n",
      "cbow: sudden, suddenly, usual, usually: 0.04262983580543956\n",
      "cbow_dense: sudden, suddenly, usual, usually: 0.057512587300851306\n",
      "skipgram: sudden, suddenly, usual, usually: 0.12027916002446541\n",
      "skipgram_dense: sudden, suddenly, usual, usually: 0.0379434827632857\n",
      "\n",
      "w2v: bad, worse, good, better: 0.6724906513772779\n",
      "glove: bad, worse, good, better: 0.6565830036364912\n",
      "cbow: bad, worse, good, better: 0.08364212988123694\n",
      "cbow_dense: bad, worse, good, better: 0.022567480791767187\n",
      "skipgram: bad, worse, good, better: 0.05282783225651509\n",
      "skipgram_dense: bad, worse, good, better: 0.06542767465641082\n",
      "\n",
      "w2v: go, going, look, looking: 0.4437767197062708\n",
      "glove: go, going, look, looking: 0.6695781772903449\n",
      "cbow: go, going, look, looking: 0.11739576262876612\n",
      "cbow_dense: go, going, look, looking: 0.014954370905789528\n",
      "skipgram: go, going, look, looking: 0.2300817760171532\n",
      "skipgram_dense: go, going, look, looking: 0.002864495321771528\n",
      "\n",
      "w2v: he, she, his, her: 0.661601926269319\n",
      "glove: he, she, his, her: 0.7343965200095653\n",
      "cbow: he, she, his, her: 0.022474709476888687\n",
      "cbow_dense: he, she, his, her: 0.12253203367780965\n",
      "skipgram: he, she, his, her: 0.21834270821319915\n",
      "skipgram_dense: he, she, his, her: 0.1511302407262479\n",
      "\n",
      "w2v: brother, sister, his, her: 0.29478371779476814\n",
      "glove: brother, sister, his, her: 0.565070276491166\n",
      "cbow: brother, sister, his, her: 0.07589060484117083\n",
      "cbow_dense: brother, sister, his, her: 0.010614877330893632\n",
      "skipgram: brother, sister, his, her: 0.017768418713980348\n",
      "skipgram_dense: brother, sister, his, her: 0.10670694926142113\n",
      "\n",
      "w2v: listen, listening, look, looking: 0.21896109979844153\n",
      "glove: listen, listening, look, looking: 0.4071841107300849\n",
      "cbow: listen, listening, look, looking: 0.23802999618462123\n",
      "cbow_dense: listen, listening, look, looking: 0.08170528413458206\n",
      "skipgram: listen, listening, look, looking: 0.028332544949943285\n",
      "skipgram_dense: listen, listening, look, looking: 0.0406596642434014\n",
      "\n",
      "w2v: saying, said, thinking, thought: 0.40956290213903407\n",
      "glove: saying, said, thinking, thought: 0.49768632598408674\n",
      "cbow: saying, said, thinking, thought: 0.3385169623849108\n",
      "cbow_dense: saying, said, thinking, thought: 0.12383424063284779\n",
      "skipgram: saying, said, thinking, thought: 0.3447016003046785\n",
      "skipgram_dense: saying, said, thinking, thought: 0.08585073444779104\n",
      "\n",
      "w2v: bird, birds, cat, cats: 0.548314343723498\n",
      "glove: bird, birds, cat, cats: 0.48856988240789534\n",
      "cbow: bird, birds, cat, cats: 0.1781694964528609\n",
      "cbow_dense: bird, birds, cat, cats: 0.14467242053834647\n",
      "skipgram: bird, birds, cat, cats: 0.12625871403801467\n",
      "skipgram_dense: bird, birds, cat, cats: 0.05631322940932175\n",
      "\n",
      "w2v: good, better, old, older: 0.21694786651491343\n",
      "glove: good, better, old, older: 0.40961181661362545\n",
      "cbow: good, better, old, older: 0.24294226160000545\n",
      "cbow_dense: good, better, old, older: 0.18656535061624072\n",
      "skipgram: good, better, old, older: 0.14252044931840813\n",
      "skipgram_dense: good, better, old, older: 0.05186729010261828\n",
      "\n",
      "w2v: good, better, quick, quicker: 0.5330237925619995\n",
      "glove: good, better, quick, quicker: 0.5328881245927063\n",
      "cbow: good, better, quick, quicker: 0.03208647290314115\n",
      "cbow_dense: good, better, quick, quicker: 0.051326262550663464\n",
      "skipgram: good, better, quick, quicker: 0.013046449432128392\n",
      "skipgram_dense: good, better, quick, quicker: 0.0796093389770551\n",
      "\n",
      "w2v: large, largest, good, best: 0.21683160333463167\n",
      "glove: large, largest, good, best: 0.2652648164246623\n",
      "cbow: large, largest, good, best: 0.13627840091820803\n",
      "cbow_dense: large, largest, good, best: 0.05309922636686337\n",
      "skipgram: large, largest, good, best: 0.16575460309601556\n",
      "skipgram_dense: large, largest, good, best: 0.053627787932685286\n",
      "\n",
      "w2v: falling, fell, knowing, knew: 0.14287526113350987\n",
      "glove: falling, fell, knowing, knew: 0.15409427727346053\n",
      "cbow: falling, fell, knowing, knew: 0.01912836021160874\n",
      "cbow_dense: falling, fell, knowing, knew: 0.037205425222480805\n",
      "skipgram: falling, fell, knowing, knew: 0.018869195113530815\n",
      "skipgram_dense: falling, fell, knowing, knew: 0.03872969424142178\n",
      "\n",
      "w2v: walk, walking, think, thinking: 0.25107561442774934\n",
      "glove: walk, walking, think, thinking: 0.4035633827468627\n",
      "cbow: walk, walking, think, thinking: 0.1371422823556235\n",
      "cbow_dense: walk, walking, think, thinking: 0.25241882965411033\n",
      "skipgram: walk, walking, think, thinking: 0.042193790238127006\n",
      "skipgram_dense: walk, walking, think, thinking: 0.020751693251079326\n",
      "\n",
      "w2v: child, children, cat, cats: 0.36624447596308296\n",
      "glove: child, children, cat, cats: 0.28044855781310063\n",
      "cbow: child, children, cat, cats: 0.4224878099785585\n",
      "cbow_dense: child, children, cat, cats: 0.15971883179637444\n",
      "skipgram: child, children, cat, cats: 0.19210569119480972\n",
      "skipgram_dense: child, children, cat, cats: 0.08558659954598827\n",
      "\n",
      "w2v: dog, dogs, eye, eyes: 0.13321162577935888\n",
      "glove: dog, dogs, eye, eyes: 0.3071176163860798\n",
      "cbow: dog, dogs, eye, eyes: 0.08293971404713851\n",
      "cbow_dense: dog, dogs, eye, eyes: 0.04959143883742041\n",
      "skipgram: dog, dogs, eye, eyes: 0.11077085600100203\n",
      "skipgram_dense: dog, dogs, eye, eyes: 0.09854696917931136\n",
      "\n",
      "w2v: hand, hands, rat, rats: 0.04862699542761563\n",
      "glove: hand, hands, rat, rats: 0.05072466972752036\n",
      "cbow: hand, hands, rat, rats: 0.06167524716738153\n",
      "cbow_dense: hand, hands, rat, rats: 0.21763028239299223\n",
      "skipgram: hand, hands, rat, rats: 0.04039324863447219\n",
      "skipgram_dense: hand, hands, rat, rats: 0.07454463081175015\n",
      "\n",
      "w2v: eat, eats, find, finds: 0.2830192036624857\n",
      "glove: eat, eats, find, finds: 0.30765008316898457\n",
      "cbow: eat, eats, find, finds: 0.38332741252697833\n",
      "cbow_dense: eat, eats, find, finds: 0.02799474581397439\n",
      "skipgram: eat, eats, find, finds: 0.06159956716563862\n",
      "skipgram_dense: eat, eats, find, finds: 0.004353422652560424\n",
      "\n",
      "w2v: find, finds, say, says: 0.38303518154481636\n",
      "glove: find, finds, say, says: 0.4858085924624003\n",
      "cbow: find, finds, say, says: 0.4225110412871306\n",
      "cbow_dense: find, finds, say, says: 0.09204581834643971\n",
      "skipgram: find, finds, say, says: 0.2117274946468136\n",
      "skipgram_dense: find, finds, say, says: 0.024942033757297807\n",
      "\n",
      "w2v: old, older, good, better: 0.21694786651491343\n",
      "glove: old, older, good, better: 0.40961181661362545\n",
      "cbow: old, older, good, better: 0.24294226160000545\n",
      "cbow_dense: old, older, good, better: 0.18656535061624072\n",
      "skipgram: old, older, good, better: 0.14252044931840813\n",
      "skipgram_dense: old, older, good, better: 0.05186729010261828\n",
      "\n",
      "w2v: large, larger, quick, quicker: 0.22521266715730429\n",
      "glove: large, larger, quick, quicker: 0.22567543578240246\n",
      "cbow: large, larger, quick, quicker: 0.04205617897711103\n",
      "cbow_dense: large, larger, quick, quicker: 0.09311372510784723\n",
      "skipgram: large, larger, quick, quicker: 0.02962600187265431\n",
      "skipgram_dense: large, larger, quick, quicker: 0.06817445995579048\n",
      "\n",
      "w2v: go, going, listen, listening: 0.23913213804946878\n",
      "glove: go, going, listen, listening: 0.42662491131551733\n",
      "cbow: go, going, listen, listening: 0.028175657728302012\n",
      "cbow_dense: go, going, listen, listening: 0.08877512926435754\n",
      "skipgram: go, going, listen, listening: 0.03259419484187035\n",
      "skipgram_dense: go, going, listen, listening: 0.010873228635317379\n",
      "\n",
      "w2v: run, running, walk, walking: 0.4228847541114353\n",
      "glove: run, running, walk, walking: 0.47095163467027384\n",
      "cbow: run, running, walk, walking: 0.06752979323171769\n",
      "cbow_dense: run, running, walk, walking: 0.13319373973395193\n",
      "skipgram: run, running, walk, walking: 0.027382636632413446\n",
      "skipgram_dense: run, running, walk, walking: 0.036897706755464\n",
      "\n",
      "w2v: run, running, think, thinking: 0.24565625385619846\n",
      "glove: run, running, think, thinking: 0.3926802350946642\n",
      "cbow: run, running, think, thinking: 0.13662853663187174\n",
      "cbow_dense: run, running, think, thinking: 0.013760378794701674\n",
      "skipgram: run, running, think, thinking: 0.11307505983692813\n",
      "skipgram_dense: run, running, think, thinking: 0.13502023716520042\n",
      "\n",
      "w2v: say, saying, sit, sitting: 0.19387733146836375\n",
      "glove: say, saying, sit, sitting: 0.33033972016602986\n",
      "cbow: say, saying, sit, sitting: 0.1255869428992714\n",
      "cbow_dense: say, saying, sit, sitting: 0.002778512915029485\n",
      "skipgram: say, saying, sit, sitting: 0.022278989764921892\n",
      "skipgram_dense: say, saying, sit, sitting: 0.031370623390230355\n",
      "\n",
      "w2v: alice, she, rabbit, he: 0.4352757480653299\n",
      "glove: alice, she, rabbit, he: 0.4769463106145698\n",
      "cbow: alice, she, rabbit, he: 0.23737374549441895\n",
      "cbow_dense: alice, she, rabbit, he: 0.22134533492778896\n",
      "skipgram: alice, she, rabbit, he: 0.10919359344013549\n",
      "skipgram_dense: alice, she, rabbit, he: 0.1196936498430301\n",
      "\n",
      "w2v: alice, her, rabbit, him: 0.4179929072878149\n",
      "glove: alice, her, rabbit, him: 0.4330083526998539\n",
      "cbow: alice, her, rabbit, him: 0.4694802520899805\n",
      "cbow_dense: alice, her, rabbit, him: 0.3085777141782657\n",
      "skipgram: alice, her, rabbit, him: 0.1471057818985327\n",
      "skipgram_dense: alice, her, rabbit, him: 0.004352950260186055\n",
      "\n",
      "w2v: alice, girl, rabbit, sir: 0.391360154857756\n",
      "glove: alice, girl, rabbit, sir: 0.3090358756196289\n",
      "cbow: alice, girl, rabbit, sir: 0.29111823565411055\n",
      "cbow_dense: alice, girl, rabbit, sir: 0.17745145079999616\n",
      "skipgram: alice, girl, rabbit, sir: 0.043377803272707655\n",
      "skipgram_dense: alice, girl, rabbit, sir: 0.16162886469339285\n",
      "\n",
      "w2v: his, her, he, she: 0.661601926269319\n",
      "glove: his, her, he, she: 0.7343965200095653\n",
      "cbow: his, her, he, she: 0.022474709476888687\n",
      "cbow_dense: his, her, he, she: 0.12253203367780965\n",
      "skipgram: his, her, he, she: 0.21834270821319915\n",
      "skipgram_dense: his, her, he, she: 0.1511302407262479\n",
      "\n",
      "w2v: long, longer, quick, quicker: 0.27729260342003326\n",
      "glove: long, longer, quick, quicker: 0.3099571305282724\n",
      "cbow: long, longer, quick, quicker: 0.09401260595447117\n",
      "cbow_dense: long, longer, quick, quicker: 0.07831883522036924\n",
      "skipgram: long, longer, quick, quicker: 0.03475701071170782\n",
      "skipgram_dense: long, longer, quick, quicker: 0.03754801662507641\n",
      "\n",
      "w2v: long, longer, small, smaller: 0.2388453687212515\n",
      "glove: long, longer, small, smaller: 0.45009013669954157\n",
      "cbow: long, longer, small, smaller: 0.19269746490298645\n",
      "cbow_dense: long, longer, small, smaller: 0.35016791043829654\n",
      "skipgram: long, longer, small, smaller: 0.17801511863882985\n",
      "skipgram_dense: long, longer, small, smaller: 0.02207475087097485\n",
      "\n",
      "w2v: long, longer, bad, worse: 0.2819685717087468\n",
      "glove: long, longer, bad, worse: 0.40626429575998596\n",
      "cbow: long, longer, bad, worse: 0.20373219592586617\n",
      "cbow_dense: long, longer, bad, worse: 0.02967005557613777\n",
      "skipgram: long, longer, bad, worse: 0.10039588396824377\n",
      "skipgram_dense: long, longer, bad, worse: 0.0009287152378468827\n",
      "\n",
      "w2v: go, going, look, looking: 0.4437767197062708\n",
      "glove: go, going, look, looking: 0.6695781772903449\n",
      "cbow: go, going, look, looking: 0.11739576262876612\n",
      "cbow_dense: go, going, look, looking: 0.014954370905789528\n",
      "skipgram: go, going, look, looking: 0.2300817760171532\n",
      "skipgram_dense: go, going, look, looking: 0.002864495321771528\n",
      "\n",
      "w2v: listen, listening, look, looking: 0.21896109979844153\n",
      "glove: listen, listening, look, looking: 0.4071841107300849\n",
      "cbow: listen, listening, look, looking: 0.23802999618462123\n",
      "cbow_dense: listen, listening, look, looking: 0.08170528413458206\n",
      "skipgram: listen, listening, look, looking: 0.028332544949943285\n",
      "skipgram_dense: listen, listening, look, looking: 0.0406596642434014\n",
      "\n",
      "w2v: swim, swimming, sit, sitting: 0.15879369259853693\n",
      "glove: swim, swimming, sit, sitting: 0.24853629762099705\n",
      "cbow: swim, swimming, sit, sitting: 0.04745686624994828\n",
      "cbow_dense: swim, swimming, sit, sitting: 0.03918166245483594\n",
      "skipgram: swim, swimming, sit, sitting: 0.013933906731029667\n",
      "skipgram_dense: swim, swimming, sit, sitting: 0.03563140413128219\n",
      "\n",
      "w2v: run, running, listen, listening: 0.09999018014940893\n",
      "glove: run, running, listen, listening: 0.15729225189857585\n",
      "cbow: run, running, listen, listening: 0.2172115315370583\n",
      "cbow_dense: run, running, listen, listening: 0.16730155288174092\n",
      "skipgram: run, running, listen, listening: 0.005648185183561339\n",
      "skipgram_dense: run, running, listen, listening: 0.052294495200113054\n",
      "\n",
      "w2v: think, thinking, read, reading: 0.3014273799197356\n",
      "glove: think, thinking, read, reading: 0.411297884485633\n",
      "cbow: think, thinking, read, reading: 0.16911559484697625\n",
      "cbow_dense: think, thinking, read, reading: 0.08962903058811725\n",
      "skipgram: think, thinking, read, reading: 0.04166652322420212\n",
      "skipgram_dense: think, thinking, read, reading: 0.03892256124563785\n",
      "\n",
      "w2v: up, down, close, far: 0.31230518986077627\n",
      "glove: up, down, close, far: 0.6523693175355175\n",
      "cbow: up, down, close, far: 0.21333871878277946\n",
      "cbow_dense: up, down, close, far: 0.007063529840594001\n",
      "skipgram: up, down, close, far: 0.10413951869465775\n",
      "skipgram_dense: up, down, close, far: 0.018702310370623847\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#w2v and glove analogy performance\n",
    "w2vanalogylist=[]\n",
    "gloveanalogylist=[]\n",
    "cbowanalogylist=[]\n",
    "cbowdenseanalogylist=[]\n",
    "skipgramanalogylist=[]\n",
    "skipgramdenseanalogylist=[]\n",
    "\n",
    "for analogy in analogy_list:\n",
    "    if(analogy[0] in tokenizer.word_index and analogy[1] in tokenizer.word_index and analogy[2] in tokenizer.word_index and analogy[3] in tokenizer.word_index):\n",
    "        try:\n",
    "            w2vanalogy=word2vec.n_similarity([analogy[0],analogy[1]],[analogy[2],analogy[3]])\n",
    "            gloveanalogy=glove.n_similarity([analogy[0],analogy[1]],[analogy[2],analogy[3]])\n",
    "            cbowanalogy=analogy_check(analogy,embed_cbow_300, tokenizer.word_index )\n",
    "            cbowdenseanalogy=analogy_check(analogy,embed_cbow_300_dense, tokenizer.word_index )\n",
    "            skipgramanalogy=analogy_check(analogy,embed_skipgram_300, tokenizer.word_index )\n",
    "            skipgramdenseanalogy=analogy_check(analogy,embed_skipgram_300_dense, tokenizer.word_index )\n",
    "            \n",
    "            print(\"w2v: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],w2vanalogy))\n",
    "            print(\"glove: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],gloveanalogy))\n",
    "            print(\"cbow: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbowanalogy))\n",
    "            print(\"cbow_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],cbowdenseanalogy))\n",
    "            print(\"skipgram: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgramanalogy))\n",
    "            print(\"skipgram_dense: {}, {}, {}, {}: {}\".format(analogy[0],analogy[1],analogy[2],analogy[3],skipgramdenseanalogy))\n",
    "            \n",
    "            \n",
    "            w2vanalogylist.append(w2vanalogy)\n",
    "            gloveanalogylist.append(gloveanalogy)\n",
    "            cbowanalogylist.append(cbowanalogy)\n",
    "            cbowdenseanalogylist.append(cbowdenseanalogy)\n",
    "            skipgramanalogylist.append(skipgramanalogy)\n",
    "            skipgramdenseanalogylist.append(skipgramdenseanalogy)\n",
    "            \n",
    "            \n",
    "            print()\n",
    "        except KeyError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20e4ac6a160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['find' 'finds' 'say' 'says']\n"
     ]
    }
   ],
   "source": [
    "#Visualize the pre-trained word embeddings\n",
    "\n",
    "w2visualize=analogy_list[19]\n",
    "embedlist=[]\n",
    "for i in range(4):\n",
    "    embedlist.append(word2vec[w2visualize[i]])\n",
    "    #embedlist.append(embed_skipgram_300[tokenizer.word_index[w2visualize[i]]-1])\n",
    "len(embedlist)\n",
    "plt.title(\"Word2Vec\")\n",
    "draw_word_vecs(embedlist,w2visualize)    \n",
    "print(w2visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3Xl8FHW67/HPwxpEBASUTQgw4jEDDGLEgx7EAQQEY8DtyngUwaR17ngGZxxHHK/KMMe5OioMOoqnKoSA7EtYJKjsKiJi2EE2QZaQyCrIkiAJz/0jHW6AIEm6O9VJP+/XK69U/7q66unq5Jtffl39K1FVjDHGVHyVvC7AGGNM2bDAN8aYCGGBb4wxEcIC3xhjIoQFvjHGRAgLfGOMiRAW+Mb4iUiKiPy313UYEyoW+CaiiMjDIvKViJwUkQP+5f8tIuJ1bcaEmgW+iRgi8iwwEngDaAhcCzwF3A5U87A0Y8qEBb6JCCJSGxgG/G9Vna6qxzXfGlV9RFVPF/GYRBH5VkSOiMgcEWnsb39fRN68YN3ZIvJH/3JjEZkhIgdF5DsR+X1ZPEdjLscC30SKTkB1YHZxVhaRrsD/BR4CGgG7gcn+uycC/6tgGEhE6gI9gMkiUgn4EFgHNAG6Ac+ISM/gPRVjSscC30SK+sAhVc0taBCR5SJyVESyReSOC9Z/BEhW1dX+3v8LQCcRiQY+BxTo7F/3AeBLVc0EbgEaqOowVf1JVXcCLvBwKJ+cMcVhgW8ixWGgvohUKWhQ1dtUtY7/vgt/FxqT36svWPeEf70mmj/j4GSgv//u3wAT/MvNgcb+PyRHReQo8Bfy3y8wxlMW+CZSfAmcBuKLuX4m+eENgIjUBOoB+/xNk4AHRKQ5cCsww9++F/hOVesU+qqlqr2D8SSMCYQFvokIqnoU+Cvwnog8ICJXikglEWkP1CziIROBgSLSXkSqA38HvlLVXf7trQEOAknAJ/7tA6wEfhSR50WkhohUFpE2InJLiJ+iMZdlgW8ihqr+A/gj8GfgALAf+B/geWD5BesuAl4iv+eeBbTi4nH4SUB38v84FDwuD4gD2gPfAYfI/6NQO+hPyJgSErsAijHGRAbr4RtjTISwwDfGmAhhgW+MMRHCAt8YYyJElcuvkk9EkoF7gAOq2sbfNhRIJP/0NIC/qOo8/30vAE8AecDvVfWTy+2jfv36Gh0dXZL6jTEm4q1ateqQqja43HrFDnwgBfgXMO6C9hGqeuFEUjHkn8L2S/I/sbhQRFr7T1m7pOjoaNLT00tQkjHGGBHZffm1SjCko6qfAUeKuXo8MFlVT6vqd8C3QMfi7ssYY0zwBWMM/2kRWS8iyf5ZAyF/lsC9hdbJ8LddRER8IpIuIukHDx4sahVjjDFBEGjgjyL/E4jtyf804lv+9qKuHlTkJ7xU1VHVWFWNbdDgskNQxhhjSqkkY/gXUdX9Bcsi4gJz/TczgOsKrdqU/MmojDEmqM6cOUNGRgY5OTlelxJyUVFRNG3alKpVq5bq8QEFvog0UtUs/81+wEb/8hxgoogMJ/9N2+vJn1TKGGOCKiMjg1q1ahEdHU1FvjSxqnL48GEyMjJo0aJFqbZRktMyJwF3kj+neAbwCnCnf7ZBBXYBT/oL2yQiU4FvgFzgd5c7Q8cYUwzrp8KiYXAsA2o3hW4vQ7uHvK7KUzk5ORU+7AFEhHr16hHIe53FDnxV7V9E8+ifWf9V4NXSFGWMKcL6qfDh7+FMdv7tY3vzb0PEh35FD/sCgT5P+6StMeXFomH/P+wLnMnObzemGCzwjQlD69atY8SIEYwfP5758+ezdu1a9u/bU/TKxzLKtjhzkbfffpsbb7yRunXr8tprr5XosY8//jjTp08PUWXnC+hNW2NMaOTm5rJ7926+/PJLNm7cyLZt26hVTfnhz1devHLtpmVfoDnPe++9x0cffVTqN1PLivXwjQlT2dnZLFiwgNq1a1OrVi2Wjf8HVK1x/kpVa+S/cWuKbdaafdz+2mJaDEnj9tcWM2vNvss/6Gc89dRT7Ny5k3vvvZcRI0bw9NNPA/k999///vfcdttttGzZ8lwvXlV5+umniYmJoU+fPhw4cCDg51RcFvjGhIkff/yR999/nw4dOnD//ffTrFkzJk2axI4dO0hLS+OX9z0LcW9D7esAyf8e93bEv2FbErPW7OOF1A3sO5qNAvuOZvNC6oaAQv/999+ncePGLFmyhLp16553X1ZWFsuWLWPu3LkMGTIEgJkzZ7J161Y2bNiA67osX768qM2GhA3pGOMhVWXlypU4jkNqairdunXjtddeo3v37qgqzZs3x3VdbrvttvwHtHvIAj4Ab3yylewz558hnn0mjzc+2Urfm4qc/SUgffv2pVKlSsTExLB/f/7nVD/77DP69+9P5cqVady4MV27dg36fi/FAt8YDxw9epTx48fjui4nT54kMTGRLVu2cO2115633tdff02jRo08qrLiyTyaXaL2QFWvXv3ccuHrh3t1GqkN6RhTRlSVL774gscff5zo6GiWLVvGiBEj2LZtG88///xFYQ9Y2AdZ4zo1StQeCnfccQeTJ08mLy+PrKwslixZUmb7th6+MSF25MgRPvjgAxzHITc3l8TERN544w1sssCy91zPG3ghdcN5wzo1qlbmuZ43lFkN/fr1Y/HixbRt25bWrVvTpUuXMtu3FP43w2uxsbFqF0AxFYGq8vnnn+M4DnPnzuWee+4hMTGRO+64I2I+FVpWNm/ezI033ljs9Wet2ccbn2wl82g2jevU4LmeN4Rk/D5Uinq+IrJKVWMv91jr4RsTRIcOHWLs2LG4rkulSpXw+XyMHDmSevXqeV2a8et7U5NyFfDBZIFvTIDOnj3L0qVLcRyHjz/+mPj4eEaPHs1tt91mvXkTVizwjSml/fv3k5KSQlJSEjVq1MDn8zFq1KiLzsU2JlxY4BtTAmfPnmXRokU4jsPChQu57777GD9+PB07drTevAl7FvjGFENWVhZjxowhKSmJ2rVr8+STT55bNqa8sMA35hLy8vKYP38+juOwdOlSHnroIaZOncrNN99svXlTLtkHr4y5QEZGBsOGDaNly5a88sor9O7dmz179vA///M/xMbGWtibi1S46ZFFJBm4Bzigqm38bW8AccBPwA5goKoeFZFoYDOw1f/wFar6VBDrNiaocnNz+eijj3Achy+++IKHH36YWbNmcdNNN3ldmikHKuL0yClArwvaFgBtVLUdsA14odB9O1S1vf/Lwt6EpT179vDKK68QHR3N3//+d+677z727t3Le++9Z2FfUa2fCiPawNA6+d/XTw1oc8GcHnnIkCHExMTQrl07/vSnPwVUV1FKck3bz/w998Jt8wvdXAE8EJyyjAmdM2fOkJaWhuM4fPXVVzzyyCN89NFHtG3b1uvSTKiF4LrA77//Ph9//DFLlixh7ty5591XMD3yli1buPfee3nggQfOmx55//79xMTEMGjQII4cOcLMmTPZsmULIsLRo0cDeaZFCuYY/iDgo0K3W4jIGhH5VEQ6X+pBIuITkXQRSQ/kauzGXM53333Hiy++SPPmzXnrrbfo378/GRkZvP322xb2kaKMrwtckumRr7rqKqKiokhISCA1NZUrrrgi6PUEJfBF5EUgF5jgb8oCmqnqTcAfgYkiclVRj1VVR1VjVTXWJpMywfbTTz8xffp0evToQceOHcnOzmbhwoV8/vnnPProo9SoUXazJJowcKnr/4bousAlmR65SpUqrFy5kvvvv59Zs2bRq9eFI+iBCzjwRWQA+W/mPqL+Z6Sqp1X1sH95Fflv6LYOdF/GFNe3337L888/T7NmzXj33XcZOHAge/fuZfjw4cTExHhdnvHKpa7/W4bXBb7U9MgnTpzg2LFj9O7dm3/+85+sXbs26PsO6Dx8EekFPA90UdVThdobAEdUNU9EWgLXAzsDqtSYyzh9+jQzZ87EdV02btzIY489xqeffsoNN5Td1LcmzHV7+fwxfCjz6wJfanrk48ePEx8fT05ODqrKiBEjgr7vYk+PLCKTgDuB+sB+4BXyz8qpDhz2r7ZCVZ8SkfuBYeQP8+QBr6jqh5fbh02PbEpj69atuK7LuHHjaNeuHT6fj/j4+PP+nTYVV0mnR2b91Pwx+2MZ+T37bi+Xq8tGlsn0yKrav4jm0ZdYdwYwo7jbNqakcnJymDFjBo7jsHXrVgYOHMiXX35Jq1atvC7NhLsIvi6wTa1gypVNmzbhui7jx48nNjaWwYMHExcXR9WqVb0uzZiwZ4Fvwt6pU6eYNm0ajuOwa9cuBg0aRHp6OtHR0V6XZky5YoFvwtb69etxHIdJkybRqVMn/vznP9OnTx+qVLEfW2NKw35zTFg5efIkU6ZMwXEc9u3bR0JCAmvXruW6667zujRjyj0LfBMWVq9ejeu6TJkyhc6dO/PSSy/Rq1cvKleu7HVpxlQYFvjGM8ePH2fSpEk4jsOhQ4dISEhgw4YNNGkSmReYNibULPBNmVJV0tPTcRyHGTNm8Otf/5pXX32V7t27W2/emBCzC6CYMnHs2DHee+89OnTowMMPP0yrVq345ptvmDFjBj179rSwN2UmbWcaPab3oN3YdvSY3oO0nWkBbe/kyZP06dOHX/3qV7Rp04YpU6YwbNgwbrnlFtq0aYPP50NV2bFjBx06dDj3uO3bt3PzzTcH+nRKxALfhIyq8uWXXzJo0CCio6P59NNPeeONN9i+fTtDhgyhYcOGXpdoIkzazjSGLh9K1sksFCXrZBZDlw8NKPQ//vhjGjduzLp169i4cSO9evXi6aef5uuvv2bjxo1kZ2czd+5cWrVqRe3atc/NkTNmzBgef/zxID2z4rHAN0H3ww8/8M4779CuXTsGDBhATEwMW7duZcqUKXTv3p1KlezHznhj5OqR5OTlnNeWk5fDyNUjS73Ntm3bsnDhQp5//nk+//xzateuzZIlS7j11ltp27YtixcvZtOmTQAkJCQwZswY8vLymDJlCr/5zW8Cej4lZWP4JihUlS+++ALHcZgzZw59+vThnXfeoUuXLnYNWBM2vj/5fYnai6N169asWrWKefPm8cILL9CjRw/effdd0tPTue666xg6dCg5Ofl/ZO6//37++te/0rVrV26++Wbq1atX6v2WhgW+Ccjhw4cZN24crusCkJiYyPDhw6lfv77HlRlzsYY1G5J1MqvI9tLKzMzk6quv5j//8z+58sorSUlJAaB+/fqcOHGC6dOn88AD+RcDjIqKomfPnvz2t79l9OgipyILKQt8U2KqyqefforrusybN4+4uDgcx+H222+33rwJa4M7DGbo8qHnDetEVY5icIfBpd7mhg0beO6556hUqRJVq1Zl1KhRzJo1i7Zt2xIdHc0tt9xy3vqPPPIIqamp9OjRo9T7LC0LfFNsBw4cYOzYsSQlJVGtWjV8Ph//+te/qFu3rtelGVMsfVr2AfLH8r8/+T0NazZkcIfB59pLo2fPnvTs2fO8ttjYWP77v/+7yPWXLVvGoEGDPDkzzQLf/KyzZ8+yePFiXNdl/vz59OvXj7Fjx3Lrrbdab96US31a9gko4APRr18/duzYweLFiz3ZvwW+KdL3339PSkoKrutSq1YtnnzySRzHoXbt2l6XZky5NXPmTE/3b4Fvzjl79iwLFizAcRwWL17Mgw8+yOTJk4mNjbXevDEVgAW+ITMzk+TkZJKSkqhfvz4+n4+UlBRq1arldWnGmCAq0SdgRCRZRA6IyMZCbVeLyAIR2e7/XtffLiLytoh8KyLrRaTDpbdsylpeXh5paWnEx8fTpk0b9u3bR2pqKunp6fh8Pgt7Yyqgkn7kMQXodUHbEGCRql4PLPLfBrgbuN7/5QNGlb5MEyx79+5l6NChtGjRgr/97W/Ex8ezZ88eRo0add48H8aYiqdEga+qnwFHLmiOB8b6l8cCfQu1j9N8K4A6ItIokGJN6eTm5jJ79mzuuece2rdvz+HDh5k7dy4rVqxg0KBBXHnllV6XaIwpA8EYw79WVbMAVDVLRK7xtzcB9hZaL8Pfdt7H3ETER/5/ADRr1iwI5ZgCu3btYvTo0SQnJ9OiRQsSExOZOnUqV1xxhdelGWM8EMpZrIo6rUMvalB1VDVWVWMbNGgQwnIiw5kzZ0hNTaVXr17ExsZy/Phx5s+fz7JlyxgwYICFvYl4xz78kO1du7H5xhi2d+3GsQ8/DGh7wZgeeciQIcTExNCuXTv+9Kc/BVTPzwlGD3+/iDTy9+4bAQf87RlA4QuRNgUyg7A/U4QdO3aQlJRESkoKrVu3xufzMWvWLKKiorwuzZiwcezDD8l66WXUP5lZbmYmWS+9DEDtuLhSbbNgeuS0tPwplo8dO8Zdd93Fyy/nb/fRRx9l7ty5xMXFnZseuX379uemRz5y5AgzZ85ky5YtiAhHjx4NwjMtWjB6+HOAAf7lAcDsQu2P+c/W+XfgWMHQjwmOn376ialTp9K9e3c6derEmTNnWLJkCZ9++imPPPKIhb0xFzgw4p/nwr6A5uRwYMQ/S73NQKdHvuqqq4iKiiIhIYHU1NSQ/hdeoh6+iEwC7gTqi0gG8ArwGjBVRJ4A9gAP+lefB/QGvgVOAQODVHPE27ZtG67rMm7cuHP/Mvbt25fq1at7XZoxYS03q+g+56XaiyMY0yOvXLmSRYsWMXnyZP71r3+FbOqFEgW+qva/xF3dilhXgd+VpihzsZycHFJTU3Fdl82bN/P444/zxRdf8Itf/MLr0owpN6o0akRu5sUjy1Ualf4EwkCnRz5x4gSnTp2id+/e/Pu//3tIf6ftk7ZhbvPmzbiuywcffECHDh343e9+x7333ku1atW8Ls2YcueaPzxz3hg+gERFcc0fnin1NgOdHvn48ePEx8eTk5ODqjJixIhS13I5FvhhKDs7m+nTp+M4Dt9++y2DBg3iq6++omXLll6XZky5VvDG7IER/yQ3K4sqjRpxzR+eKfUbthD49MiNGjVi5cqVpd5/SVjgh5ENGzbgui4TJ06kY8eOPPvss/Tp04eqVat6XZoxFUbtuLiAAj4QNj1yhDt58iRTp07FcRz27t3LE088wapVq2jevLnXpRljgsymR45Qa9euxXEcpkyZwu23385f/vIX7r77bqpUsZfEmJJS1YiYwjv/XJjSs3QpQ8ePH2fy5Mm4rsv+/ft54oknWLduHU2bNvW6NGPKraioKA4fPky9evUqdOirKocPHw7o8zUW+GVg1apVOI7DtGnT6NKlC3/961/p0aOHJ9e0NKaiadq0KRkZGRw8eNDrUkIuKioqoA6iBX6I/Pjjj0ycOBHHcfjhhx9ITExk06ZNNArgfF9jzMWqVq1KixYtvC6jXLDADyJVZeXKlTiOQ2pqKt27d+f111+nW7duVKoUynnqjDHm8izwg+Do0aOMHz8e13U5deoUiYmJbNmyhWuvvdbr0owx5hwL/FJSVZYvX47jOMyePZu7776bESNGcOedd1pv3hgTlizwS+jIkSOMGzcO13XJy8sjMTGRN998E5vL3xgT7izwi0FV+eyzz3Bdl7lz53LPPfcwatQoOnfuXKFPAzPGVCwW+D/j0KFDjB07Ftd1qVy5Mj6fj7fffpurr77a69KMMabELPAvcPbsWZYuXYrjOHz88cf07duX5ORkOnXqZL15Y0y5ZoHvt3//flJSUnBdlyuuuAKfz8eoUaOoW7eu16UZY0xQRHTgnz17loULF+I4DosWLeK+++5jwoQJdOzY0XrzxpgKJ+DAF5EbgCmFmloCLwN1gESg4PPOf1HVeYHuLxgyMzMZM2YMo0ePpk6dOvh8PpKTk7nqqqu8Ls0YY0Im4MBX1a1AewARqQzsA2aSfw3bEar6ZqD7CIa8vDw++eQTXNdl6dKlPPTQQ0ybNo2bb77Z69KMMaZMBHtIpxuwQ1V3h8uQSEZGBsnJySQlJdGwYUMSExMZN24ctWrV8ro0Y4wpU8EO/IeBSYVuPy0ijwHpwLOq+sOFDxARH+ADaNasWal2OmvNPt74ZCuZR7NpXKcGf+zWimrfr8dxHL744gv69+/PnDlzaN++fam2b4wxFYEEOqH+uQ2JVAMygV+q6n4RuRY4BCjwN6CRqg76uW3ExsZqenp6ifY7a80+XkjdQPaZPFTPcuzLqZxc+xGtWkTz/DO/46GHHqJmzZqle1LGGFMOiMgqVY293HrB7OHfDaxW1f0ABd/9xbjA3CDu65w3PtlK9pm8c7elchUaPPhX6l1/IwMHdg3FLo0xplwKZuD3p9Bwjog0UtUs/81+wMYg7uuczKPZ55ZFKlH71gcuajfGGBOkwBeRK4C7gCcLNf9DRNqTP6Sz64L7gqZxnRrsKyLcG9epEYrdGWNMuRWUeXxV9ZSq1lPVY4XaHlXVtqraTlXvLdTbD6rnet5AjarnXyqwRtXKPNfzhlDszhhjyq1y/0nbvjc1ATjvLJ3net5wrt0YY0y+ch/4kB/6FvDGGPPz7NJMxhgTISzwjTEmQljgG2NMhLDAN8aYCGGBb4wxEcIC3xhjIoQFvjHGRAgLfGOMiRAW+MYYEyEs8I0xJkJY4BtjTISwwDfGmAhhgW+MMRHCAt8YYyKEBb4xxkQIC3xjjIkQQbsAiojsAo4DeUCuqsaKyNXAFCCa/OvaPqSqPwRrn8YYY4ov2D38X6tqe1WN9d8eAixS1euBRf7bxhhjPBDqIZ14YKx/eSzQN8T7M8YYcwnBDHwF5ovIKhHx+duuVdUsAP/3ay58kIj4RCRdRNIPHjwYxHKMMcYUFsyLmN+uqpkicg2wQES2FOdBquoADkBsbKwGsR5jjDGFBK2Hr6qZ/u8HgJlAR2C/iDQC8H8/EKz9GWOMKZmgBL6I1BSRWgXLQA9gIzAHGOBfbQAwOxj7M8YYU3LBGtK5FpgpIgXbnKiqH4vI18BUEXkC2AM8GKT9GWOMKaGgBL6q7gR+VUT7YaBbMPZhjDEmMPZJW2OMiRAW+MYYEyEs8I0xJkJY4BtjTISwwDfGmAhhgW+MMRHCAt8YYyKEBb4xxkQIC3xjjIkQFvjGGBMhLPCNMSZCWOAbY0yEsMA3xpgIYYFvjDERwgLfGGM8cOzDD9netRubb4xhe9duHPvww5DvM5jXtDXGGFMMxz78kKyXXkZzcgDIzcwk66WXAagdFxey/VoP3xhjytiBEf88F/YFNCeHAyP+GdL9BtzDF5HrgHFAQ+As4KjqSBEZCiQCB/2r/kVV5wW6P2OMKU9mzZrFd999xzXXXEODBg24+uqryd27l9qVK1+0bm5WVkhrCcaQTi7wrKqu9l/IfJWILPDfN0JV3wzCPowxplxSVXbv3s3SpUtZv349u3bt4tY6dRhzbcOL1q3SqFFIawl4SEdVs1R1tX/5OLAZaBLodo0xprw7c+YMANu2bWPZsmXUr1+fNm3akOo4SFTUeetKVBTX/OGZkNYT1DF8EYkGbgK+8jc9LSLrRSRZROoGc1/GGBOuvvvuO1588UWaN2/O8OHD6d+/Py+//DLHjh1j8eLFNH7wQRr9bRhVGjcGEao0bkyjvw0L6Ru2AKKqwdmQyJXAp8CrqpoqItcChwAF/gY0UtVBRTzOB/gAmjVrdvPu3buDUo8xxpSln376iTlz5uA4DmvWrOHRRx8lISGBmJgYNm7cSM+ePfn8889p2bJl0PctIqtUNfay6wUj8EWkKjAX+ERVhxdxfzQwV1Xb/Nx2YmNjNT09PeB6jDGmrGzfvp2kpCRSUlKIiYnB5/PRr18/ogoN2eTl5XH06FHq1asXkhqKG/jBOEtHgNHA5sJhLyKNVLXgLed+wMZA92WMMeHg9OnTzJw5E8dx2LRpE4899hifffYZN9xwQ5HrV65cOWRhXxLBOEvnduBRYIOIrPW3/QXoLyLtyR/S2QU8GYR9GWOMZ7Zs2YLrunzwwQe0a9eOp556ivj4eKpXr+51acUScOCr6jJAirjLzrk3xpR72dnZzJgxA9d12bp1KwMHDuTLL7+kVatWXpdWYja1gjHGFGHTpk24rsv48eOJjY1l8ODBxMXFUbVqVa9LKzULfGOM8Tt16hTTpk3DcRx27drFoEGDSE9PJzo62uvSgsIC3xgT8datW4frukyaNIlOnTrx5z//mT59+lClSsWKyIr1bIwxpphOnDjBlClTcByHzMxMEhISWLt2Ldddd53XpYWMBb4xJqKsXr0ax3GYOnUqnTt35uWXX6ZXr15ULmIys4rGAt8YU+H9+OOPTJo0Cdd1OXToEAkJCWzYsIEmTSJr2i8LfGNMhaSqpKen4zgO06dPp2vXrrz66qt07949InrzRbHAN8ZUKMeOHWPChAk4jsPx48dJTExk8+bNNGx48XTEkcYC3xhT7qkqK1aswHEcZs6cSc+ePXnzzTfp2rUrlSrZhf0KWOAbY8qtH374gQ8++ADXdTl9+jQ+n4/XX3+da665xuvSwpIFvjGmXFFVli1bhuu6zJkzh969e/POO+/QpUsX8udyNJdigW+MKRcOHz7MuHHjcBwHESExMZHhw4dTv359r0srNyzwjTFhS1VZunQprusyb9487r33XlzX5fbbb7fefClY4Btjws6BAwcYO3YsrutSvXp1fD4f7777LnXr2pVSA2GBb4wJC2fPnmXx4sU4jsOCBQvo168f48aN49Zbb7XefJBY4BtjPPX9998zZswYkpKSqFWrFj6fD9d1qV27ttelVTgW+MaYMpeXl8eCBQtwXZfFixfz4IMPMnnyZGJjY603H0IW+MaYMrNv3z6Sk5MZPXo09evXx+fzkZKSQq1atbwuLSKE/CNoItJLRLaKyLciMiTU+zPGhJe8vDzS0tKIj4+nbdu2ZGZmkpqaSnp6Oj6fz8K+DIW0hy8ilYF3gbuADOBrEZmjqt+Ecr/GGO/t2bPnXG++SZMm+Hw+JkyYwJVXXul1aREr1EM6HYFvVXUngIhMBuIBC3xjKqDc3FzS0tJwHIcVK1bwm9/8hrS0NNq1a+d1aYbQB34TYG+h2xnArYVXEBEf4ANo1qxZiMsxxoTCrl27SEpKYsyYMbRo0YLExESmTZvGFVdc4XVpppBQj+EX9XZGPgNkAAANwUlEQVS7nndD1VHVWFWNbdCgQYjLMcYEy5kzZ5gxYwa9evUiNjaWEydOMH/+fJYtW8aAAQMs7MNQqHv4GUDhC0Q2BTJDvE9jTAjt2LGDpKQkUlJSaN26NT6fj1mzZhEVFeV1aeYyQh34XwPXi0gLYB/wMPCbEO/TGBNkp0+fZvbs2TiOw/r163nsscdYsmQJ//Zv/+Z1aaYEQhr4qporIk8DnwCVgWRV3RTKfRpjgmfbtm24rsvYsWNp27YtPp+Pvn37Ur16da9LM6UQ8g9eqeo8YF6o92OMCY6cnBxSU1NxHIctW7bw+OOPs3z5cn7xi194XZoJkH3S1hgDwDfffIPruowfP54OHTrwX//1X8TFxVGtWjWvSzNBYoFvTATLzs5m2rRpuK7Ljh07GDRoECtXrqRFixZel2ZCwALfmAi0YcMGXNdl4sSJdOzYkWeffZY+ffpQtWpVr0szIWSBb0yEOHnyJFOnTsVxHPbu3csTTzzBqlWraN68udelmTJigW9MBbd27Vocx2Hy5Mn8x3/8By+++CK9evWiShX79Y809oobUwEdP36cyZMn4zgOBw4cICEhgfXr19O0aVOvSzMessA3poJQVVatWoXjOEyfPp0777yTYcOG0aNHDypXrux1eSYMWOAbU84dO3aMiRMn4rouR48eJSEhgU2bNtGoUSOvSzNhxgLfmHJIVVm5ciWO45Camkr37t15/fXX6datG5Uqhfy6RqacssA3phw5evQo48ePx3EcsrOzSUxMZMuWLVx77bVel2bKAQt8Y8KcqrJ8+XIcx2H27NncfffdjBw5ki5dulhv3pSIBb4xYerw4cN88MEHuK5LXl4ePp+Pt956i/r163tdmimnLPCNCSOqymeffYbjOKSlpREXF8eoUaPo3LkzIkVdT8iY4rPANyYMHDx4kHHjxuE4DlWqVMHn8/HOO+9w9dVXe12aqUAs8I3xyNmzZ1myZAmu6/LJJ58QHx/PmDFj6NSpk/XmTUhY4BtTxvbv309KSgqu61KzZk18Ph/vv/8+derU8bo0U8FZ4BtTBs6ePcvChQtxHIdFixZx//33M3HiRG655RbrzZsyE1Dgi8gbQBzwE7ADGKiqR0UkGtgMbPWvukJVnwpkX8aUR5mZmYwZM4akpCTq1q3Lk08+SXJyMldddZXXpZkIFOhJvAuANqraDtgGvFDovh2q2t7/ZWFvIkZeXh7z5s2jb9++tGnThj179jB9+nRWr17Nk08+aWFvPBNQD19V5xe6uQJ4ILByjCm/9u7dS3JyMqNHj6Zhw4b4fD7Gjx/PlVde6XVpxgCB9/ALGwR8VOh2CxFZIyKfikjnIO7HmLCRm5vLnDlziIuL41e/+hUHDhxgzpw5rFy5koSEBAt7E1Yu28MXkYVAwyLuelFVZ/vXeRHIBSb478sCmqnqYRG5GZglIr9U1R+L2L4P8AE0a9asdM/CmDK2e/duRo8eTXJyMs2aNcPn8zF58mRq1qzpdWnGXNJlA19Vu//c/SIyALgH6Kaq6n/MaeC0f3mViOwAWgPpRWzfARyA2NhYLekTMKasnDlzhrlz5+I4Dl9//TWPPPIIH3/8MW3atPG6NGOKJdCzdHoBzwNdVPVUofYGwBFVzRORlsD1wM6AKjXGIzt37iQpKYkxY8Zw/fXXk5iYSGpqKjVq1PC6NGNKJNDz8P8FVAcW+M8lLjj98g5gmIjkAnnAU6p6JMB9GVNmfvrpJ2bPno3ruqxZs4ZHH32UxYsXc+ONN3pdmjGlFuhZOr+4RPsMYEYg2zbGC9u3b8d1XcaOHUtMTAw+n485c+YQFRXldWnGBMw+aWsi3unTp5k5cyaO47Bp0yYGDBjA559/TuvWrb0uzZigssA3EWvLli24rsu4ceNo3749v/3tb4mPj6datWpel2ZMSFjgm4iSnZ3NjBkzcByH7du3M3DgQFasWEGrVq28Ls2YkLPANxFh48aNuK7LhAkTuOWWW3jmmWeIi4ujatWqXpdmTJmxwDcV1qlTp5g6dSqO47B7924GDRpEeno60dHRXpdmjCcs8E2Fs27dOlzXZdKkSXTq1IkhQ4bQu3dvqlSxH3cT2ew3wFQIJ06cYPLkybiuS2ZmJgkJCaxdu5brrrvO69KMCRsW+KZcW716NY7jMHXqVO644w5eeeUVevbsSeXKlb0uzZiwY4Fvyp0ff/yRSZMm4TgOhw8fJiEhgQ0bNtCkSROvSzMmrFngm3JBVfn6669xHIcZM2bQrVs3/v73v3PXXXdRqVIwZ/k2puKywDdhI21nGiNXj+T7k9/TsGZDBncYzO1X386ECRNwHIcTJ06QmJjI5s2badiwqBm7jTE/xwLfhIW0nWkMXT6UnLwcAPbu38uAxweQsy6HPr36MHz4cH79619bb96YAFjgm7AwcvXIc2EPoGeUas2r0WZAG6Y8McXDyoypOCzwTVj4/uT3592uWrcq9brX4wg2q7YxwWL/H5uw0LBm0WPyl2o3xpScBb4JC4M7DCaq8vlzzkdVjmJwh8EeVWRMxWNDOiYs9GnZB+Cis3QK2o0xgbPAN2GjT8s+FvDGhFBAQzoiMlRE9onIWv9X70L3vSAi34rIVhHpGXipxhhjAhGMHv4IVX2zcIOIxAAPA78EGgMLRaS1quYFYX/GGGNKIVRv2sYDk1X1tKp+B3wLdAzRvowxxhRDMAL/aRFZLyLJIlLX39YE2FtonQx/20VExCci6SKSfvDgwSCUY4wxpiiXDXwRWSgiG4v4igdGAa2A9kAW8FbBw4rYlBa1fVV1VDVWVWMbNGhQyqdhjDHmci47hq+q3YuzIRFxgbn+mxlA4StPNAUyS1ydMcaYoBHVIjvexXuwSCNVzfIv/wG4VVUfFpFfAhPJH7dvDCwCrr/cm7YichA4CRwqdVGhV5/wrg+sxmCxGoMj3GsM9/rg8jU2V9XLDpEEepbOP0SkPfnDNbuAJwFUdZOITAW+AXKB3xXnDB1VbSAi6aoaG2BdIRPu9YHVGCxWY3CEe43hXh8Er8aAAl9VH/2Z+14FXg1k+8YYY4LH5tIxxpgIEY6B73hdwGWEe31gNQaL1Rgc4V5juNcHQaoxoDdtjTHGlB/h2MM3xhgTAhb4xhgTITwLfBF5UEQ2ichZEYkt1H6XiKwSkQ3+710L3bfUP/tmweyc13hRo/++ImcDFZFe/rZvRWRIKOsrot4phY7NLhFZ62+PFpHsQve9X5Z1XVBjWM+wKiJviMgW/3QhM0Wkjr89bI6hvx7Pfs4uRUSuE5ElIrLZ/3sz2N9+ydfcozp3+fNlrYik+9uuFpEFIrLd/73u5bYTwvpuKHSs1orIjyLyTFCOo6p68gXcCNwALAViC7XfBDT2L7cB9hW677x1PawxBlgHVAdaADuAyv6vHUBLoJp/nRiPju9bwMv+5Whgo1ev9QV1DQX+VER7kcfUg/p6AFX8y68Dr4fhMQybn7ML6moEdPAv1wK2+V/XIl9zD+vcBdS/oO0fwBD/8pCC193rL/9r/T3QPBjH0bMevqpuVtWtRbSvUdWCaRg2AVEiUr1sqztXS5E1cunZQDsC36rqTlX9CZjsX7dMiYgADwGTynrfAQiLGVZVdb6q5vpvriB/WpBwExY/ZxdS1SxVXe1fPg5s5hKTJoaheGCsf3ks0NfDWgrrBuxQ1d3B2Fi4j+HfD6xR1dOF2sb4/515yR9sXrjUbKDFniU0xDoD+1V1e6G2FiKyRkQ+FZHOHtRUWEAzrJahQcBHhW6HyzEMx2N1HhGJJv+/9a/8TUW95l5RYL5/yNjnb7tW/dPE+L+HdLi4BB7m/I5bQMcxpIEvPz/T5uUe+0vy/6V+slDzI6ralvxA6wxc8pO+Ia7xUrOBFnuW0NIqZr39Of+HJAtopqo3AX8EJorIVcGsqwQ1BjzDaojrK1jnRfKnBZngbyrTY3gZZXasSkNErgRmAM+o6o9c+jX3yu2q2gG4G/idiNzhcT1FEpFqwL3ANH9TwMcxpNe01WLOtHkhEWkKzAQeU9Udhba3z//9uIgUTM42zoMaf2420JDOEnq5ekWkCnAfcHOhx5wGTvuXV4nIDqA1kB7M2opbYwHxaIbVYhzDAcA9QDf1D6SW9TG8jLCdjVZEqpIf9hNUNRVAVfcXur/wa+6JgiFjVT0gIjPJz5H94p8MUkQaAQe8rNHvbmB1wfELxnEMuyEd/1kRacALqvpFofYqIlLfv1yV/F/Ijd5UyRzgYRGpLiItgOuBlcDXwPUi0sL/1/lh/7plqTuwRVUzChpEpIGIVPYvt/TXu7OM6yqopVGhm/34/6/hpY5pWdfXC3geuFdVTxVqD5tjSHj8nF3EP8Q6GtisqsMLtV/qNS9zIlJTRGoVLJP/Jv1G8o/fAP9qA4DZ3lR4nvP+Uw/KcfTw3ed+5PdUTgP7gU/87f+H/CmS1xb6ugaoCawC1pP/Zu5IQnwWx6Vq9N/3IvlnSmwF7i7U3pv8sxN2AC96cFxTgKcuaLvff8zWAauBOA9f9w+ADf7XcQ7Q6HLHtIzr+5b88fGCn733w+0YhsPP2SVq+g/yh5bWFzp+vX/uNfegxpb+13Cd//V80d9ej/xp3Lf7v1/t8bG8AjgM1C7UFvBxtKkVjDEmQoTdkI4xxpjQsMA3xpgIYYFvjDERwgLfGGMihAW+McZECAt8Y4yJEBb4xhgTIf4fayT/sY+z5nYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20e4ac6a198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['find' 'finds' 'say' 'says']\n"
     ]
    }
   ],
   "source": [
    "#Visualize the pre-trained word embeddings\n",
    "    \n",
    "embedlist=[]\n",
    "for i in range(4):\n",
    "    embedlist.append(glove[w2visualize[i]])\n",
    "    #embedlist.append(embed_skipgram_300[tokenizer.word_index[w2visualize[i]]-1])\n",
    "len(embedlist)\n",
    "plt.title(\"Glove\")\n",
    "draw_word_vecs(embedlist,w2visualize)    \n",
    "print(w2visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20e4aec3fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['find' 'finds' 'say' 'says']\n"
     ]
    }
   ],
   "source": [
    "#Visualize the pre-trained word embeddings\n",
    "    \n",
    "embedlist=[]\n",
    "for i in range(4):\n",
    "    #embedlist.append(word2vec[analogy_list[1][i]])\n",
    "    embedlist.append(embed_cbow_300[tokenizer.word_index[w2visualize[i]]-1])\n",
    "len(embedlist)\n",
    "plt.title(\"CBOW 300\")\n",
    "draw_word_vecs(embedlist,w2visualize)    \n",
    "print(w2visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20e4b03cf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['find' 'finds' 'say' 'says']\n"
     ]
    }
   ],
   "source": [
    "#Visualize the pre-trained word embeddings\n",
    "    \n",
    "embedlist=[]\n",
    "for i in range(4):\n",
    "    #embedlist.append(word2vec[analogy_list[1][i]])\n",
    "    embedlist.append(embed_cbow_300_dense[tokenizer.word_index[w2visualize[i]]-1])\n",
    "len(embedlist)\n",
    "plt.title(\"CBOW 300 Dense\")\n",
    "draw_word_vecs(embedlist,w2visualize)    \n",
    "print(w2visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20e4b13bd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['find' 'finds' 'say' 'says']\n"
     ]
    }
   ],
   "source": [
    "#Visualize the pre-trained word embeddings\n",
    "    \n",
    "embedlist=[]\n",
    "for i in range(4):\n",
    "    #embedlist.append(word2vec[analogy_list[1][i]])\n",
    "    embedlist.append(embed_skipgram_300[tokenizer.word_index[w2visualize[i]]-1])\n",
    "len(embedlist)\n",
    "plt.title(\"Skipgram 300\")\n",
    "draw_word_vecs(embedlist,w2visualize)    \n",
    "print(w2visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20e4b3b6128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['find' 'finds' 'say' 'says']\n"
     ]
    }
   ],
   "source": [
    "#Visualize the pre-trained word embeddings\n",
    "    \n",
    "embedlist=[]\n",
    "for i in range(4):\n",
    "    #embedlist.append(word2vec[analogy_list[1][i]])\n",
    "    embedlist.append(embed_skipgram_300_dense[tokenizer.word_index[w2visualize[i]]-1])\n",
    "len(embedlist)\n",
    "plt.title(\"Skipgram 300 Dense\")\n",
    "draw_word_vecs(embedlist,w2visualize)    \n",
    "print(w2visualize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "The glove embedding seems to be constantly outperforming all the other embeddings.\n",
    "On words which frequently arise the performance of distance seems to be comparable to word2vec.\n",
    "Having said that w2v is more consistent. \n",
    "The actual predictions of CBOW and skip gram are horrible and clearly are off by a large margin.\n",
    "All in all it seems that more training data and possibly more elaborate architectures are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['happy', 'unhappy', 'pleasant', 'unpleasant'], dtype='<U10'),\n",
       " array(['sudden', 'suddenly', 'usual', 'usually'], dtype='<U8'),\n",
       " array(['bad', 'worse', 'good', 'better'], dtype='<U6'),\n",
       " array(['go', 'going', 'look', 'looking'], dtype='<U7'),\n",
       " array(['he', 'she', 'his', 'her'], dtype='<U3'),\n",
       " array(['brother', 'sister', 'his', 'her'], dtype='<U7'),\n",
       " array(['listen', 'listening', 'look', 'looking'], dtype='<U9'),\n",
       " array(['saying', 'said', 'thinking', 'thought'], dtype='<U8'),\n",
       " array(['bird', 'birds', 'cat', 'cats'], dtype='<U5'),\n",
       " array(['good', 'better', 'old', 'older'], dtype='<U6'),\n",
       " array(['good', 'better', 'quick', 'quicker'], dtype='<U7'),\n",
       " array(['large', 'largest', 'good', 'best'], dtype='<U7'),\n",
       " array(['happy', 'unhappy', 'comfortable', 'uncomfortable'], dtype='<U13'),\n",
       " array(['falling', 'fell', 'knowing', 'knew'], dtype='<U7'),\n",
       " array(['walk', 'walking', 'think', 'thinking'], dtype='<U8'),\n",
       " array(['child', 'children', 'cat', 'cats'], dtype='<U8'),\n",
       " array(['dog', 'dogs', 'eye', 'eyes'], dtype='<U4'),\n",
       " array(['hand', 'hands', 'rat', 'rats'], dtype='<U5'),\n",
       " array(['eat', 'eats', 'find', 'finds'], dtype='<U5'),\n",
       " array(['find', 'finds', 'say', 'says'], dtype='<U5'),\n",
       " array(['old', 'older', 'good', 'better'], dtype='<U6'),\n",
       " array(['large', 'larger', 'quick', 'quicker'], dtype='<U7'),\n",
       " array(['go', 'going', 'listen', 'listening'], dtype='<U9'),\n",
       " array(['run', 'running', 'walk', 'walking'], dtype='<U7'),\n",
       " array(['run', 'running', 'think', 'thinking'], dtype='<U8'),\n",
       " array(['pleasant', 'pleasanter', 'large', 'larger'], dtype='<U10'),\n",
       " array(['say', 'saying', 'sit', 'sitting'], dtype='<U7'),\n",
       " array(['wrong', 'true', 'happy', 'unhappy'], dtype='<U7'),\n",
       " array(['alice', 'she', 'rabbit', 'he'], dtype='<U6'),\n",
       " array(['alice', 'her', 'rabbit', 'him'], dtype='<U6'),\n",
       " array(['alice', 'girl', 'rabbit', 'sir'], dtype='<U6'),\n",
       " array(['uneasily', 'easily', 'sudden', 'suddenly'], dtype='<U8'),\n",
       " array(['uneasily', 'easily', 'calmly', 'angrily', ''], dtype='<U8'),\n",
       " array(['dinah', 'cat', 'alice', 'girl'], dtype='<U5'),\n",
       " array(['never', 'always', 'happy', 'unhappy'], dtype='<U7'),\n",
       " array(['his', 'her', 'he', 'she'], dtype='<U3'),\n",
       " array(['long', 'longer', 'quick', 'quicker'], dtype='<U7'),\n",
       " array(['long', 'longer', 'small', 'smaller'], dtype='<U7'),\n",
       " array(['long', 'longer', 'bad', 'worse'], dtype='<U6'),\n",
       " array(['go', 'going', 'look', 'looking'], dtype='<U7'),\n",
       " array(['listen', 'listening', 'look', 'looking'], dtype='<U9'),\n",
       " array(['swim', 'swimming', 'sit', 'sitting'], dtype='<U8'),\n",
       " array(['run', 'running', 'listen', 'listening'], dtype='<U9'),\n",
       " array(['think', 'thinking', 'read', 'reading'], dtype='<U8'),\n",
       " array(['up', 'down', 'close', 'far'], dtype='<U5'),\n",
       " array(['queen', 'woman', 'king', 'man'], dtype='<U5'),\n",
       " array(['boy', 'girl', 'man', 'woman'], dtype='<U5')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy_list\n",
    "#print(len(analogy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'and': 2,\n",
       " 'to': 3,\n",
       " 'she': 4,\n",
       " 'a': 5,\n",
       " 'i': 6,\n",
       " 'it': 7,\n",
       " 'of': 8,\n",
       " 'was': 9,\n",
       " 'in': 10,\n",
       " 'alice': 11,\n",
       " 'you': 12,\n",
       " 'that': 13,\n",
       " 'her': 14,\n",
       " 'as': 15,\n",
       " 'said': 16,\n",
       " 'had': 17,\n",
       " 'for': 18,\n",
       " 'but': 19,\n",
       " 'be': 20,\n",
       " 'on': 21,\n",
       " 'all': 22,\n",
       " 'with': 23,\n",
       " 'little': 24,\n",
       " 'mouse': 25,\n",
       " 'down': 26,\n",
       " 'very': 27,\n",
       " 'this': 28,\n",
       " 'not': 29,\n",
       " 'so': 30,\n",
       " 'out': 31,\n",
       " 'if': 32,\n",
       " 'is': 33,\n",
       " 'at': 34,\n",
       " 't': 35,\n",
       " 's': 36,\n",
       " 'll': 37,\n",
       " 'how': 38,\n",
       " 'they': 39,\n",
       " 'about': 40,\n",
       " 'herself': 41,\n",
       " 'me': 42,\n",
       " 'up': 43,\n",
       " 'what': 44,\n",
       " 'way': 45,\n",
       " 'when': 46,\n",
       " 'like': 47,\n",
       " 'one': 48,\n",
       " 'do': 49,\n",
       " 'no': 50,\n",
       " 'oh': 51,\n",
       " 'went': 52,\n",
       " 'thought': 53,\n",
       " 'again': 54,\n",
       " 'there': 55,\n",
       " 'see': 56,\n",
       " 'or': 57,\n",
       " 'could': 58,\n",
       " 'would': 59,\n",
       " 'think': 60,\n",
       " 'them': 61,\n",
       " 'know': 62,\n",
       " 'rabbit': 63,\n",
       " 'dear': 64,\n",
       " 'were': 65,\n",
       " 'time': 66,\n",
       " 'get': 67,\n",
       " 'here': 68,\n",
       " 'must': 69,\n",
       " 'my': 70,\n",
       " 'by': 71,\n",
       " 'into': 72,\n",
       " 'found': 73,\n",
       " 'such': 74,\n",
       " 'began': 75,\n",
       " 'soon': 76,\n",
       " 'm': 77,\n",
       " 'quite': 78,\n",
       " 'then': 79,\n",
       " 'off': 80,\n",
       " 'now': 81,\n",
       " 'go': 82,\n",
       " 'say': 83,\n",
       " 'have': 84,\n",
       " 'which': 85,\n",
       " 'come': 86,\n",
       " 'dinah': 87,\n",
       " 'your': 88,\n",
       " 'thing': 89,\n",
       " 'dodo': 90,\n",
       " 'much': 91,\n",
       " 'shall': 92,\n",
       " 'things': 93,\n",
       " 'long': 94,\n",
       " 'door': 95,\n",
       " 'who': 96,\n",
       " 'can': 97,\n",
       " 'once': 98,\n",
       " 'did': 99,\n",
       " 'over': 100,\n",
       " 'feet': 101,\n",
       " 'after': 102,\n",
       " 'wonder': 103,\n",
       " 'first': 104,\n",
       " 'let': 105,\n",
       " 'are': 106,\n",
       " 'cats': 107,\n",
       " 'round': 108,\n",
       " 'poor': 109,\n",
       " 'back': 110,\n",
       " 'he': 111,\n",
       " 'nothing': 112,\n",
       " 'seemed': 113,\n",
       " 'its': 114,\n",
       " 'never': 115,\n",
       " 'going': 116,\n",
       " 'great': 117,\n",
       " 'got': 118,\n",
       " 'ever': 119,\n",
       " 'table': 120,\n",
       " 'any': 121,\n",
       " 'only': 122,\n",
       " 'more': 123,\n",
       " 'cried': 124,\n",
       " 'gloves': 125,\n",
       " 'fan': 126,\n",
       " 'well': 127,\n",
       " 'white': 128,\n",
       " 'looked': 129,\n",
       " 'before': 130,\n",
       " 'moment': 131,\n",
       " 'why': 132,\n",
       " 'an': 133,\n",
       " 'eat': 134,\n",
       " 'however': 135,\n",
       " 'sure': 136,\n",
       " 'pool': 137,\n",
       " 'getting': 138,\n",
       " 'took': 139,\n",
       " 'either': 140,\n",
       " 'just': 141,\n",
       " 'upon': 142,\n",
       " 've': 143,\n",
       " 'through': 144,\n",
       " 'wish': 145,\n",
       " 'tell': 146,\n",
       " 'hall': 147,\n",
       " 'key': 148,\n",
       " 'half': 149,\n",
       " 'find': 150,\n",
       " 'his': 151,\n",
       " 'use': 152,\n",
       " 'large': 153,\n",
       " 'look': 154,\n",
       " 'too': 155,\n",
       " 'house': 156,\n",
       " 'good': 157,\n",
       " 'right': 158,\n",
       " 'words': 159,\n",
       " 'am': 160,\n",
       " 'might': 161,\n",
       " 'question': 162,\n",
       " 'came': 163,\n",
       " 'dry': 164,\n",
       " 'away': 165,\n",
       " 'been': 166,\n",
       " 'small': 167,\n",
       " 'high': 168,\n",
       " 'garden': 169,\n",
       " 'tears': 170,\n",
       " 'don': 171,\n",
       " 'won': 172,\n",
       " 'doesn': 173,\n",
       " 'without': 174,\n",
       " 'suddenly': 175,\n",
       " 'eyes': 176,\n",
       " 'some': 177,\n",
       " 'put': 178,\n",
       " 'sort': 179,\n",
       " 'their': 180,\n",
       " 'rather': 181,\n",
       " 'talking': 182,\n",
       " 'saying': 183,\n",
       " 'felt': 184,\n",
       " 'hand': 185,\n",
       " 'low': 186,\n",
       " 'trying': 187,\n",
       " 'golden': 188,\n",
       " 'head': 189,\n",
       " 'indeed': 190,\n",
       " 'will': 191,\n",
       " 'while': 192,\n",
       " 'same': 193,\n",
       " 'try': 194,\n",
       " 'beg': 195,\n",
       " 'tone': 196,\n",
       " 'our': 197,\n",
       " 'd': 198,\n",
       " 'called': 199,\n",
       " 'birds': 200,\n",
       " 'lory': 201,\n",
       " 'race': 202,\n",
       " 'looking': 203,\n",
       " 'course': 204,\n",
       " 'book': 205,\n",
       " 'made': 206,\n",
       " 'ran': 207,\n",
       " 'seen': 208,\n",
       " 'fell': 209,\n",
       " 'next': 210,\n",
       " 'tried': 211,\n",
       " 'make': 212,\n",
       " 'anything': 213,\n",
       " 'four': 214,\n",
       " 'nice': 215,\n",
       " 'people': 216,\n",
       " 'please': 217,\n",
       " 'should': 218,\n",
       " 'remember': 219,\n",
       " 'turned': 220,\n",
       " 'other': 221,\n",
       " 'glass': 222,\n",
       " 'than': 223,\n",
       " 'marked': 224,\n",
       " 'best': 225,\n",
       " 'sat': 226,\n",
       " 'two': 227,\n",
       " 'english': 228,\n",
       " 'pair': 229,\n",
       " 'heard': 230,\n",
       " 'kid': 231,\n",
       " 'ready': 232,\n",
       " 'voice': 233,\n",
       " 'queer': 234,\n",
       " 'changed': 235,\n",
       " 'swam': 236,\n",
       " 'talk': 237,\n",
       " 'offended': 238,\n",
       " 'we': 239,\n",
       " 'party': 240,\n",
       " 'prizes': 241,\n",
       " 'chapter': 242,\n",
       " 'hole': 243,\n",
       " 'tired': 244,\n",
       " 'having': 245,\n",
       " 'pictures': 246,\n",
       " 'own': 247,\n",
       " 'mind': 248,\n",
       " 'hot': 249,\n",
       " 'day': 250,\n",
       " 'pocket': 251,\n",
       " 'hurried': 252,\n",
       " 'take': 253,\n",
       " 'another': 254,\n",
       " 'coming': 255,\n",
       " 'from': 256,\n",
       " 'fall': 257,\n",
       " 'even': 258,\n",
       " 'near': 259,\n",
       " 'idea': 260,\n",
       " 'among': 261,\n",
       " 'didn': 262,\n",
       " 'ask': 263,\n",
       " 'air': 264,\n",
       " 'perhaps': 265,\n",
       " 'else': 266,\n",
       " 'cat': 267,\n",
       " 'afraid': 268,\n",
       " 'bats': 269,\n",
       " 'rate': 270,\n",
       " 'those': 271,\n",
       " 'really': 272,\n",
       " 'bottle': 273,\n",
       " 'children': 274,\n",
       " 'enough': 275,\n",
       " 'anxiously': 276,\n",
       " 'surprised': 277,\n",
       " 'speak': 278,\n",
       " 'hastily': 279,\n",
       " 'duchess': 280,\n",
       " 'kept': 281,\n",
       " 'everything': 282,\n",
       " 'mabel': 283,\n",
       " 'capital': 284,\n",
       " 'tail': 285,\n",
       " 'something': 286,\n",
       " 'william': 287,\n",
       " 'pardon': 288,\n",
       " 'crowded': 289,\n",
       " 'whole': 290,\n",
       " 'last': 291,\n",
       " 'old': 292,\n",
       " 'him': 293,\n",
       " 'thimble': 294,\n",
       " 'close': 295,\n",
       " 'hear': 296,\n",
       " 'itself': 297,\n",
       " 'late': 298,\n",
       " 'ought': 299,\n",
       " 'under': 300,\n",
       " 'world': 301,\n",
       " 'deep': 302,\n",
       " 'slowly': 303,\n",
       " 'happen': 304,\n",
       " 'dark': 305,\n",
       " 'noticed': 306,\n",
       " 'somebody': 307,\n",
       " 'home': 308,\n",
       " 'end': 309,\n",
       " 'many': 310,\n",
       " 'fallen': 311,\n",
       " 'several': 312,\n",
       " 'lessons': 313,\n",
       " 'still': 314,\n",
       " 'distance': 315,\n",
       " 'seem': 316,\n",
       " 'walk': 317,\n",
       " 'heads': 318,\n",
       " 'name': 319,\n",
       " 'ma': 320,\n",
       " 'fancy': 321,\n",
       " 're': 322,\n",
       " 'manage': 323,\n",
       " 'night': 324,\n",
       " 'mice': 325,\n",
       " 'answer': 326,\n",
       " 'passage': 327,\n",
       " 'sight': 328,\n",
       " 'behind': 329,\n",
       " 'every': 330,\n",
       " 'three': 331,\n",
       " 'alas': 332,\n",
       " 'inches': 333,\n",
       " 'along': 334,\n",
       " 'bright': 335,\n",
       " 'happened': 336,\n",
       " 'few': 337,\n",
       " 'drink': 338,\n",
       " 'hurry': 339,\n",
       " 'poison': 340,\n",
       " 'finger': 341,\n",
       " 'almost': 342,\n",
       " 'certain': 343,\n",
       " 'finished': 344,\n",
       " 'curious': 345,\n",
       " 'face': 346,\n",
       " 'candle': 347,\n",
       " 'generally': 348,\n",
       " 'remembered': 349,\n",
       " 'box': 350,\n",
       " 'left': 351,\n",
       " 'person': 352,\n",
       " 'eye': 353,\n",
       " 'lying': 354,\n",
       " 'cake': 355,\n",
       " 'life': 356,\n",
       " 'deal': 357,\n",
       " 'dropped': 358,\n",
       " 'times': 359,\n",
       " 'seems': 360,\n",
       " 'stay': 361,\n",
       " 'being': 362,\n",
       " 'sudden': 363,\n",
       " 'cause': 364,\n",
       " 'water': 365,\n",
       " 'o': 366,\n",
       " 'history': 367,\n",
       " 'trembling': 368,\n",
       " 'always': 369,\n",
       " 'dogs': 370,\n",
       " 'eagerly': 371,\n",
       " 'fetch': 372,\n",
       " 'us': 373,\n",
       " 'duck': 374,\n",
       " 'eaglet': 375,\n",
       " 'caucus': 376,\n",
       " 'tale': 377,\n",
       " 'replied': 378,\n",
       " 'turning': 379,\n",
       " 'sister': 380,\n",
       " 'bank': 381,\n",
       " 'considering': 382,\n",
       " 'feel': 383,\n",
       " 'sleepy': 384,\n",
       " 'stupid': 385,\n",
       " 'whether': 386,\n",
       " 'making': 387,\n",
       " 'worth': 388,\n",
       " 'trouble': 389,\n",
       " 'remarkable': 390,\n",
       " 'natural': 391,\n",
       " 'watch': 392,\n",
       " 'waistcoat': 393,\n",
       " 'started': 394,\n",
       " 'across': 395,\n",
       " 'falling': 396,\n",
       " 'filled': 397,\n",
       " 'cupboards': 398,\n",
       " 'shelves': 399,\n",
       " 'saw': 400,\n",
       " 'jar': 401,\n",
       " 'fear': 402,\n",
       " 'managed': 403,\n",
       " 'wouldn': 404,\n",
       " 'top': 405,\n",
       " 'likely': 406,\n",
       " 'miles': 407,\n",
       " 'aloud': 408,\n",
       " 'somewhere': 409,\n",
       " 'earth': 410,\n",
       " 'though': 411,\n",
       " 'opportunity': 412,\n",
       " 'knowledge': 413,\n",
       " 'listen': 414,\n",
       " 'yes': 415,\n",
       " 'latitude': 416,\n",
       " 'longitude': 417,\n",
       " 'funny': 418,\n",
       " 'glad': 419,\n",
       " 'new': 420,\n",
       " 'spoke': 421,\n",
       " 'girl': 422,\n",
       " 'asking': 423,\n",
       " 'miss': 424,\n",
       " 'catch': 425,\n",
       " 'bat': 426,\n",
       " 'sometimes': 427,\n",
       " 'matter': 428,\n",
       " 'begun': 429,\n",
       " 'walking': 430,\n",
       " 'thump': 431,\n",
       " 'bit': 432,\n",
       " 'hurt': 433,\n",
       " 'lost': 434,\n",
       " 'corner': 435,\n",
       " 'ears': 436,\n",
       " 'whiskers': 437,\n",
       " 'row': 438,\n",
       " 'roof': 439,\n",
       " 'doors': 440,\n",
       " 'side': 441,\n",
       " 'walked': 442,\n",
       " 'sadly': 443,\n",
       " 'middle': 444,\n",
       " 'tiny': 445,\n",
       " 'opened': 446,\n",
       " 'led': 447,\n",
       " 'larger': 448,\n",
       " 'shut': 449,\n",
       " 'telescope': 450,\n",
       " 'knew': 451,\n",
       " 'waiting': 452,\n",
       " 'hoping': 453,\n",
       " 'rules': 454,\n",
       " 'shutting': 455,\n",
       " 'certainly': 456,\n",
       " 'beautifully': 457,\n",
       " 'hold': 458,\n",
       " 'usually': 459,\n",
       " 'forgotten': 460,\n",
       " 'taste': 461,\n",
       " 'finding': 462,\n",
       " 'fact': 463,\n",
       " 'feeling': 464,\n",
       " 'size': 465,\n",
       " 'waited': 466,\n",
       " 'minutes': 467,\n",
       " 'altogether': 468,\n",
       " 'reach': 469,\n",
       " 'crying': 470,\n",
       " 'sharply': 471,\n",
       " 'leave': 472,\n",
       " 'minute': 473,\n",
       " 'gave': 474,\n",
       " 'severely': 475,\n",
       " 'against': 476,\n",
       " 'child': 477,\n",
       " 'fond': 478,\n",
       " 'makes': 479,\n",
       " 'grow': 480,\n",
       " 'happens': 481,\n",
       " 'holding': 482,\n",
       " 'growing': 483,\n",
       " 'curiouser': 484,\n",
       " 'forgot': 485,\n",
       " 'far': 486,\n",
       " 'dears': 487,\n",
       " 'give': 488,\n",
       " 'sending': 489,\n",
       " 'foot': 490,\n",
       " 'nonsense': 491,\n",
       " 'nine': 492,\n",
       " 'cry': 493,\n",
       " 'yourself': 494,\n",
       " 'stop': 495,\n",
       " 'pattering': 496,\n",
       " 'trotting': 497,\n",
       " 'muttering': 498,\n",
       " 'help': 499,\n",
       " 'sir': 500,\n",
       " 'hard': 501,\n",
       " 'morning': 502,\n",
       " 'ah': 503,\n",
       " 'age': 504,\n",
       " 'hair': 505,\n",
       " 'ringlets': 506,\n",
       " 'mine': 507,\n",
       " 'sorts': 508,\n",
       " 'puzzling': 509,\n",
       " 'used': 510,\n",
       " 'paris': 511,\n",
       " 'rome': 512,\n",
       " 'doth': 513,\n",
       " 'hands': 514,\n",
       " 'alone': 515,\n",
       " 'done': 516,\n",
       " 'shrinking': 517,\n",
       " 'frightened': 518,\n",
       " 'change': 519,\n",
       " 'bad': 520,\n",
       " 'slipped': 521,\n",
       " 'salt': 522,\n",
       " 'sea': 523,\n",
       " 'case': 524,\n",
       " 'railway': 525,\n",
       " 'hadn': 526,\n",
       " 'suppose': 527,\n",
       " 'swimming': 528,\n",
       " 'speaking': 529,\n",
       " 'understand': 530,\n",
       " 'french': 531,\n",
       " 'conqueror': 532,\n",
       " 'lesson': 533,\n",
       " 'angry': 534,\n",
       " 'show': 535,\n",
       " 'paws': 536,\n",
       " 'nurse': 537,\n",
       " 'catching': 538,\n",
       " 'subject': 539,\n",
       " 'sit': 540,\n",
       " 'says': 541,\n",
       " 'useful': 542,\n",
       " 'shore': 543,\n",
       " 'hate': 544,\n",
       " 'animals': 545,\n",
       " 'fur': 546,\n",
       " 'wet': 547,\n",
       " 'better': 548,\n",
       " 'ring': 549,\n",
       " 'silence': 550,\n",
       " 'wanted': 551,\n",
       " 'edwin': 552,\n",
       " 'morcar': 553,\n",
       " 'earls': 554,\n",
       " 'mercia': 555,\n",
       " 'northumbria': 556,\n",
       " 'advisable': 557,\n",
       " 'meet': 558,\n",
       " 'melancholy': 559,\n",
       " 'solemnly': 560,\n",
       " 'explain': 561,\n",
       " 'running': 562,\n",
       " 'liked': 563,\n",
       " 'has': 564,\n",
       " 'chorus': 565,\n",
       " 'comfits': 566,\n",
       " 'speech': 567,\n",
       " 'caused': 568,\n",
       " 'sad': 569,\n",
       " 'fury': 570,\n",
       " 'trial': 571,\n",
       " 'jury': 572,\n",
       " 'judge': 573,\n",
       " 'finish': 574,\n",
       " 'story': 575,\n",
       " 'crab': 576,\n",
       " 'nobody': 577,\n",
       " 'ferrets': 578,\n",
       " 'hunting': 579,\n",
       " 'mary': 580,\n",
       " 'ann': 581,\n",
       " 'messages': 582,\n",
       " 'room': 583,\n",
       " 'beginning': 584,\n",
       " 'sitting': 585,\n",
       " 'twice': 586,\n",
       " 'peeped': 587,\n",
       " 'reading': 588,\n",
       " 'conversations': 589,\n",
       " 'pleasure': 590,\n",
       " 'daisy': 591,\n",
       " 'chain': 592,\n",
       " 'picking': 593,\n",
       " 'daisies': 594,\n",
       " 'pink': 595,\n",
       " 'nor': 596,\n",
       " 'afterwards': 597,\n",
       " 'occurred': 598,\n",
       " 'wondered': 599,\n",
       " 'actually': 600,\n",
       " 'flashed': 601,\n",
       " 'burning': 602,\n",
       " 'curiosity': 603,\n",
       " 'field': 604,\n",
       " 'fortunately': 605,\n",
       " 'pop': 606,\n",
       " 'hedge': 607,\n",
       " 'straight': 608,\n",
       " 'tunnel': 609,\n",
       " 'dipped': 610,\n",
       " 'stopping': 611,\n",
       " 'plenty': 612,\n",
       " 'sides': 613,\n",
       " 'maps': 614,\n",
       " 'hung': 615,\n",
       " 'pegs': 616,\n",
       " 'passed': 617,\n",
       " 'labelled': 618,\n",
       " 'orange': 619,\n",
       " 'marmalade': 620,\n",
       " 'disappointment': 621,\n",
       " 'empty': 622,\n",
       " 'drop': 623,\n",
       " 'killing': 624,\n",
       " 'past': 625,\n",
       " 'tumbling': 626,\n",
       " 'stairs': 627,\n",
       " 'brave': 628,\n",
       " 'true': 629,\n",
       " 'centre': 630,\n",
       " 'thousand': 631,\n",
       " 'learnt': 632,\n",
       " 'schoolroom': 633,\n",
       " 'showing': 634,\n",
       " 'practice': 635,\n",
       " 'grand': 636,\n",
       " 'presently': 637,\n",
       " 'downward': 638,\n",
       " 'antipathies': 639,\n",
       " 'listening': 640,\n",
       " 'sound': 641,\n",
       " 'word': 642,\n",
       " 'country': 643,\n",
       " 'zealand': 644,\n",
       " 'australia': 645,\n",
       " 'curtsey': 646,\n",
       " 'curtseying': 647,\n",
       " 'ignorant': 648,\n",
       " 'written': 649,\n",
       " 'hope': 650,\n",
       " 'saucer': 651,\n",
       " 'milk': 652,\n",
       " 'tea': 653,\n",
       " 'dreamy': 654,\n",
       " 'couldn': 655,\n",
       " 'dozing': 656,\n",
       " 'dream': 657,\n",
       " 'earnestly': 658,\n",
       " 'truth': 659,\n",
       " 'heap': 660,\n",
       " 'sticks': 661,\n",
       " 'leaves': 662,\n",
       " 'jumped': 663,\n",
       " 'overhead': 664,\n",
       " 'hurrying': 665,\n",
       " 'wind': 666,\n",
       " 'longer': 667,\n",
       " 'lit': 668,\n",
       " 'lamps': 669,\n",
       " 'hanging': 670,\n",
       " 'locked': 671,\n",
       " 'wondering': 672,\n",
       " 'legged': 673,\n",
       " 'solid': 674,\n",
       " 'except': 675,\n",
       " 'belong': 676,\n",
       " 'locks': 677,\n",
       " 'open': 678,\n",
       " 'second': 679,\n",
       " 'curtain': 680,\n",
       " 'fifteen': 681,\n",
       " 'lock': 682,\n",
       " 'delight': 683,\n",
       " 'fitted': 684,\n",
       " 'rat': 685,\n",
       " 'knelt': 686,\n",
       " 'loveliest': 687,\n",
       " 'longed': 688,\n",
       " 'wander': 689,\n",
       " 'beds': 690,\n",
       " 'flowers': 691,\n",
       " 'cool': 692,\n",
       " 'fountains': 693,\n",
       " 'doorway': 694,\n",
       " 'shoulders': 695,\n",
       " 'begin': 696,\n",
       " 'lately': 697,\n",
       " 'telescopes': 698,\n",
       " 'neck': 699,\n",
       " 'paper': 700,\n",
       " 'label': 701,\n",
       " 'printed': 702,\n",
       " 'wise': 703,\n",
       " 'read': 704,\n",
       " 'histories': 705,\n",
       " 'burnt': 706,\n",
       " 'eaten': 707,\n",
       " 'wild': 708,\n",
       " 'beasts': 709,\n",
       " 'unpleasant': 710,\n",
       " 'because': 711,\n",
       " 'simple': 712,\n",
       " 'friends': 713,\n",
       " 'taught': 714,\n",
       " 'red': 715,\n",
       " 'poker': 716,\n",
       " 'burn': 717,\n",
       " 'cut': 718,\n",
       " 'deeply': 719,\n",
       " 'knife': 720,\n",
       " 'bleeds': 721,\n",
       " 'disagree': 722,\n",
       " 'sooner': 723,\n",
       " 'later': 724,\n",
       " 'ventured': 725,\n",
       " 'mixed': 726,\n",
       " 'flavour': 727,\n",
       " 'cherry': 728,\n",
       " 'tart': 729,\n",
       " 'custard': 730,\n",
       " 'pine': 731,\n",
       " 'apple': 732,\n",
       " 'roast': 733,\n",
       " 'turkey': 734,\n",
       " 'toffee': 735,\n",
       " 'buttered': 736,\n",
       " 'toast': 737,\n",
       " 'ten': 738,\n",
       " 'brightened': 739,\n",
       " 'lovely': 740,\n",
       " 'shrink': 741,\n",
       " 'further': 742,\n",
       " 'nervous': 743,\n",
       " 'flame': 744,\n",
       " 'blown': 745,\n",
       " 'decided': 746,\n",
       " 'possibly': 747,\n",
       " 'plainly': 748,\n",
       " 'climb': 749,\n",
       " 'legs': 750,\n",
       " 'slippery': 751,\n",
       " 'advise': 752,\n",
       " 'advice': 753,\n",
       " 'seldom': 754,\n",
       " 'followed': 755,\n",
       " 'scolded': 756,\n",
       " 'bring': 757,\n",
       " 'cheated': 758,\n",
       " 'game': 759,\n",
       " 'croquet': 760,\n",
       " 'playing': 761,\n",
       " 'pretending': 762,\n",
       " 'pretend': 763,\n",
       " 'hardly': 764,\n",
       " 'respectable': 765,\n",
       " 'currants': 766,\n",
       " 'smaller': 767,\n",
       " 'creep': 768,\n",
       " 'care': 769,\n",
       " 'ate': 770,\n",
       " 'remained': 771,\n",
       " 'eats': 772,\n",
       " 'expecting': 773,\n",
       " 'dull': 774,\n",
       " 'common': 775,\n",
       " 'set': 776,\n",
       " 'work': 777,\n",
       " 'ii': 778,\n",
       " 'opening': 779,\n",
       " 'largest': 780,\n",
       " 'bye': 781,\n",
       " 'shoes': 782,\n",
       " 'stockings': 783,\n",
       " 'shan': 784,\n",
       " 'able': 785,\n",
       " 'myself': 786,\n",
       " 'kind': 787,\n",
       " 'want': 788,\n",
       " 'boots': 789,\n",
       " 'christmas': 790,\n",
       " 'planning': 791,\n",
       " 'carrier': 792,\n",
       " 'presents': 793,\n",
       " 'odd': 794,\n",
       " 'directions': 795,\n",
       " 'esq': 796,\n",
       " 'hearthrug': 797,\n",
       " 'fender': 798,\n",
       " 'love': 799,\n",
       " 'struck': 800,\n",
       " 'hopeless': 801,\n",
       " 'ashamed': 802,\n",
       " 'shedding': 803,\n",
       " 'gallons': 804,\n",
       " 'until': 805,\n",
       " 'reaching': 806,\n",
       " 'dried': 807,\n",
       " 'returning': 808,\n",
       " 'splendidly': 809,\n",
       " 'dressed': 810,\n",
       " 'himself': 811,\n",
       " 'savage': 812,\n",
       " 'desperate': 813,\n",
       " 'timid': 814,\n",
       " 'violently': 815,\n",
       " 'skurried': 816,\n",
       " 'darkness': 817,\n",
       " 'fanning': 818,\n",
       " 'yesterday': 819,\n",
       " 'usual': 820,\n",
       " 'different': 821,\n",
       " 'puzzle': 822,\n",
       " 'thinking': 823,\n",
       " 'ada': 824,\n",
       " 'goes': 825,\n",
       " 'knows': 826,\n",
       " 'besides': 827,\n",
       " 'five': 828,\n",
       " 'twelve': 829,\n",
       " 'six': 830,\n",
       " 'thirteen': 831,\n",
       " 'seven': 832,\n",
       " 'twenty': 833,\n",
       " 'multiplication': 834,\n",
       " 'signify': 835,\n",
       " 'geography': 836,\n",
       " 'london': 837,\n",
       " 'wrong': 838,\n",
       " 'crossed': 839,\n",
       " 'lap': 840,\n",
       " 'repeat': 841,\n",
       " 'sounded': 842,\n",
       " 'hoarse': 843,\n",
       " 'strange': 844,\n",
       " 'crocodile': 845,\n",
       " 'improve': 846,\n",
       " 'shining': 847,\n",
       " 'pour': 848,\n",
       " 'waters': 849,\n",
       " 'nile': 850,\n",
       " 'scale': 851,\n",
       " 'cheerfully': 852,\n",
       " 'grin': 853,\n",
       " 'neatly': 854,\n",
       " 'spread': 855,\n",
       " 'claws': 856,\n",
       " 'welcome': 857,\n",
       " 'fishes': 858,\n",
       " 'gently': 859,\n",
       " 'smiling': 860,\n",
       " 'jaws': 861,\n",
       " 'live': 862,\n",
       " 'poky': 863,\n",
       " 'toys': 864,\n",
       " 'play': 865,\n",
       " 'learn': 866,\n",
       " 'putting': 867,\n",
       " 'till': 868,\n",
       " 'burst': 869,\n",
       " 'measure': 870,\n",
       " 'nearly': 871,\n",
       " 'guess': 872,\n",
       " 'rapidly': 873,\n",
       " 'avoid': 874,\n",
       " 'narrow': 875,\n",
       " 'escape': 876,\n",
       " 'existence': 877,\n",
       " 'speed': 878,\n",
       " 'worse': 879,\n",
       " 'declare': 880,\n",
       " 'these': 881,\n",
       " 'splash': 882,\n",
       " 'chin': 883,\n",
       " 'somehow': 884,\n",
       " 'seaside': 885,\n",
       " 'general': 886,\n",
       " 'conclusion': 887,\n",
       " 'wherever': 888,\n",
       " 'coast': 889,\n",
       " 'number': 890,\n",
       " 'bathing': 891,\n",
       " 'machines': 892,\n",
       " 'digging': 893,\n",
       " 'sand': 894,\n",
       " 'wooden': 895,\n",
       " 'spades': 896,\n",
       " 'lodging': 897,\n",
       " 'houses': 898,\n",
       " 'station': 899,\n",
       " 'wept': 900,\n",
       " 'punished': 901,\n",
       " 'drowned': 902,\n",
       " 'splashing': 903,\n",
       " 'nearer': 904,\n",
       " 'walrus': 905,\n",
       " 'hippopotamus': 906,\n",
       " 'harm': 907,\n",
       " 'brother': 908,\n",
       " 'latin': 909,\n",
       " 'grammar': 910,\n",
       " 'inquisitively': 911,\n",
       " 'wink': 912,\n",
       " 'daresay': 913,\n",
       " 'clear': 914,\n",
       " 'notion': 915,\n",
       " 'ago': 916,\n",
       " 'ou': 917,\n",
       " 'est': 918,\n",
       " 'chatte': 919,\n",
       " 'sentence': 920,\n",
       " 'leap': 921,\n",
       " 'quiver': 922,\n",
       " 'fright': 923,\n",
       " 'animal': 924,\n",
       " 'feelings': 925,\n",
       " 'shrill': 926,\n",
       " 'passionate': 927,\n",
       " 'soothing': 928,\n",
       " 'yet': 929,\n",
       " 'quiet': 930,\n",
       " 'lazily': 931,\n",
       " 'sits': 932,\n",
       " 'purring': 933,\n",
       " 'nicely': 934,\n",
       " 'fire': 935,\n",
       " 'licking': 936,\n",
       " 'washing': 937,\n",
       " 'soft': 938,\n",
       " 'bristling': 939,\n",
       " 'family': 940,\n",
       " 'hated': 941,\n",
       " 'nasty': 942,\n",
       " 'vulgar': 943,\n",
       " 'conversation': 944,\n",
       " 'dog': 945,\n",
       " 'eyed': 946,\n",
       " 'terrier': 947,\n",
       " 'curly': 948,\n",
       " 'brown': 949,\n",
       " 'throw': 950,\n",
       " 'dinner': 951,\n",
       " 'belongs': 952,\n",
       " 'farmer': 953,\n",
       " 'hundred': 954,\n",
       " 'pounds': 955,\n",
       " 'kills': 956,\n",
       " 'rats': 957,\n",
       " 'sorrowful': 958,\n",
       " 'commotion': 959,\n",
       " 'softly': 960,\n",
       " 'pale': 961,\n",
       " 'passion': 962,\n",
       " 'creatures': 963,\n",
       " 'iii': 964,\n",
       " 'assembled': 965,\n",
       " 'draggled': 966,\n",
       " 'feathers': 967,\n",
       " 'clinging': 968,\n",
       " 'dripping': 969,\n",
       " 'cross': 970,\n",
       " 'uncomfortable': 971,\n",
       " 'consultation': 972,\n",
       " 'familiarly': 973,\n",
       " 'known': 974,\n",
       " 'argument': 975,\n",
       " 'sulky': 976,\n",
       " 'older': 977,\n",
       " 'allow': 978,\n",
       " 'knowing': 979,\n",
       " 'positively': 980,\n",
       " 'refused': 981,\n",
       " 'authority': 982,\n",
       " 'fixed': 983,\n",
       " 'cold': 984,\n",
       " 'ahem': 985,\n",
       " 'important': 986,\n",
       " 'driest': 987,\n",
       " 'whose': 988,\n",
       " 'favoured': 989,\n",
       " 'pope': 990,\n",
       " 'submitted': 991,\n",
       " 'leaders': 992,\n",
       " 'accustomed': 993,\n",
       " 'usurpation': 994,\n",
       " 'conquest': 995,\n",
       " 'ugh': 996,\n",
       " 'shiver': 997,\n",
       " 'frowning': 998,\n",
       " 'politely': 999,\n",
       " 'proceed': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
